<!DOCTYPE html>
<html lang=zh>
<head>
    <meta charset="utf-8">
    
    <title>kafka API使用方法 | aychao</title>
    
    
        <meta name="keywords" content="kafka" />
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <meta name="description" content="Produce流程图 1.一个正常的生产逻辑需要具备以下几个步骤(1)配置生产者客户端参数及创建相应的生产者实例(2)构建待发送的消息(3)发送消息(4)关闭生产者实例Producer java api首先,引入 maven 依赖    org.apache.kafka    kafka-clients    2.0.0采用默认分区方式将消息散列的发送到各个分区当中import org.apach">
<meta property="og:type" content="article">
<meta property="og:title" content="kafka API使用方法">
<meta property="og:url" content="http://example.com/2022/06/12/kafka-API%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/index.html">
<meta property="og:site_name" content="aychao">
<meta property="og:description" content="Produce流程图 1.一个正常的生产逻辑需要具备以下几个步骤(1)配置生产者客户端参数及创建相应的生产者实例(2)构建待发送的消息(3)发送消息(4)关闭生产者实例Producer java api首先,引入 maven 依赖    org.apache.kafka    kafka-clients    2.0.0采用默认分区方式将消息散列的发送到各个分区当中import org.apach">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/6.png">
<meta property="article:published_time" content="2022-06-12T09:47:51.000Z">
<meta property="article:modified_time" content="2022-06-20T22:00:17.672Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="kafka">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/6.png">
    

    
        <link rel="alternate" href="/atom.xml" title="aychao" type="application/atom+xml" />
    

    
        <link rel="icon" href="/css/images/favicon.ico" />
    

    
<link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">

    
<link rel="stylesheet" href="/libs/open-sans/styles.css">

    
<link rel="stylesheet" href="/libs/source-code-pro/styles.css">


    
<link rel="stylesheet" href="/css/style.css">

    
<script src="/libs/jquery/2.1.3/jquery.min.js"></script>

    
<script src="/libs/jquery/plugins/cookie/1.4.1/jquery.cookie.js"></script>

    
    
        
<link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">

    
    
        
<link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">

    
    
    
    


    
        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    
<meta name="generator" content="Hexo 6.2.0"></head>

<body>
    <div id="container">
        <header id="header">
    <div id="header-main" class="header-inner">
        <div class="outer">
            <a href="/" id="logo">
                <i class="logo"></i>
                <span class="site-title">aychao</span>
            </a>
            <nav id="main-nav">
                
                    <a class="main-nav-link" href="/">首页</a>
                
                    <a class="main-nav-link" href="/archives">归档</a>
                
                    <a class="main-nav-link" href="/categories">分类</a>
                
                    <a class="main-nav-link" href="/tags">标签</a>
                
                    <a class="main-nav-link" href="/about">关于</a>
                
            </nav>
            
            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="搜索" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="想要查找什么..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(未命名)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>

<script src="/js/insight.js"></script>


</div>
        </div>
    </div>
    <div id="main-nav-mobile" class="header-sub header-inner">
        <table class="menu outer">
            <tr>
                
                    <td><a class="main-nav-link" href="/">首页</a></td>
                
                    <td><a class="main-nav-link" href="/archives">归档</a></td>
                
                    <td><a class="main-nav-link" href="/categories">分类</a></td>
                
                    <td><a class="main-nav-link" href="/tags">标签</a></td>
                
                    <td><a class="main-nav-link" href="/about">关于</a></td>
                
                <td>
                    
    <div class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="搜索" />
    </div>

                </td>
            </tr>
        </table>
    </div>
</header>

        <div class="outer">
            
            
                <aside id="sidebar">
   
        
    
    <div id="toTop" class="fa fa-angle-up"></div>
</aside>
            
            <section id="main"><article id="post-kafka-API使用方法" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
                    <div class="article-meta">
                        
                        
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link-link" href="/tags/kafka/" rel="tag">kafka</a>
    </div>

                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/2022/06/12/kafka-API%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/">
            <time datetime="2022-06-12T09:47:51.000Z" itemprop="datePublished">2022-06-12</time>
        </a>
    </div>


                        
                            <i class="fa fa-bar-chart"></i>
                            <span id="busuanzi_container_site_pv"><span id="busuanzi_value_page_pv"></span></span>    
                        
                        
                            <div class="article-meta-button">
                                <a target="_blank" rel="noopener" href='https://github.com/aychao/blog/raw/master/source/_posts/kafka-API使用方法.md'> Source </a>
                            </div>
                            <div class="article-meta-button">
                                <a target="_blank" rel="noopener" href='https://github.com/aychao/blog/edit/master/source/_posts/kafka-API使用方法.md'> Edit </a>
                            </div>
                            <div class="article-meta-button">
                                <a target="_blank" rel="noopener" href='https://github.com/aychao/blog/commits/master/source/_posts/kafka-API使用方法.md'> History </a>
                            </div>
                        
                    </div>
                
                
    
        <h1 class="article-title" itemprop="name">
            kafka API使用方法
        </h1>
    

            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
        
            
        
        
            <p>Produce流程图<br> <img src="/../img/6.png" alt="6.png"><br>1.一个正常的生产逻辑需要具备以下几个步骤<br>(1)配置生产者客户端参数及创建相应的生产者实例<br>(2)构建待发送的消息<br>(3)发送消息<br>(4)关闭生产者实例<br>Producer java api<br>首先,引入 maven 依赖<br><dependency><br>    <groupId>org.apache.kafka</groupId><br>    <artifactId>kafka-clients</artifactId><br>    <version>2.0.0</version><br></dependency><br>采用默认分区方式将消息散列的发送到各个分区当中<br>import org.apache.kafka.clients.producer.KafkaProducer;<br>import org.apache.kafka.clients.producer.Producer;<br>import org.apache.kafka.clients.producer.ProducerRecord;<br>import java.util.Properties;<br>public class MyProducer {<br>public static void main(String[ ] args) throws InterruptedException {<br>Properties props &#x3D; new Properties();<br>&#x2F;&#x2F;设置 kafka 集群的地址<br>props.put(“bootstrap.servers”, “node1:9092,node2:9092,node3:9092”);<br>&#x2F;&#x2F;ack 模式,取值有 0,1,-1(all) , all 是最慢但最安全的，<br>0不等响应就继续发（可靠性低），1leader会写到本地日志后，然后给响应，producer拿到响应才继续发（follwer还没同步）<br>props.put(“acks”, “all”);<br>props.put(“retries”, 3); &#x2F;&#x2F;失败重试次数-&gt;失败会自动重试（可恢复&#x2F;不可恢复）–&gt;(有可能会造成数据的乱序)<br>props.put(“batch.size”, 10); &#x2F;&#x2F;数据发送的批次大小提高效率&#x2F;吞吐量太大会数据延迟<br>props.put(“linger.ms”, 10000); &#x2F;&#x2F;消息在缓冲区保留的时间,超过设置的值就会被提交到服务端<br>props.put(“max.request.size”,10); &#x2F;&#x2F;数据发送请求的最大缓存数<br>props.put(“buffer.memory”, 10240); &#x2F;&#x2F;整个 Producer 用到总内存的大小,如果缓冲区满了会提交数据到服务端<br>&#x2F;&#x2F;buffer.memory 要大于 batch.size,否则会报申请内存不足的错误降低阻塞的可能性<br>在创建真正的生产者实例前需要配置相应的参数,比如需要连接的 Kafka 集群地址。在 Kafka 生产者客户端 KatkaProducer 中有 3 个参数是必填的。<br>bootstrap.servers<br>key.serializer<br>value.serializer<br>为了防止参数名字符串书写错误,可以使用如下方式进行设置: props.setProperty(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG,ProducerInterceptorPrefix.class.getName());<br>props.setProperty(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,”node1:9092,node2:9092”);<br>props.setProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,StringSerializer.class.getName());<br>produceDemo代码如下：<br>import org.apache.kafka.clients.producer.KafkaProducer;<br>import org.apache.kafka.clients.producer.Producer;<br>import org.apache.kafka.clients.producer.ProducerConfig;<br>import org.apache.kafka.clients.producer.ProducerRecord;<br>import org.apache.kafka.common.serialization.StringSerializer;<br>import org.apache.commons.lang3.RandomStringUtils;<br>import java.util.Properties;</p>
<p>public class ProducerDemo {<br>    private static final String SERVERS&#x3D;”node1:9092,node2:9092,node3:9090”;<br>    public static void main(String[] args) {<br>        Properties props &#x3D; new Properties();<br>        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, SERVERS);<br>        props.put(ProducerConfig.ACKS_CONFIG, “all”);<br>&#x2F;&#x2F;        props.put(ProducerConfig.RETRIES_CONFIG, 3);<br>&#x2F;&#x2F;        props.put(ProducerConfig.BATCH_SIZE_CONFIG, 10);<br>&#x2F;&#x2F;        props.put(ProducerConfig.LINGER_MS_CONFIG, 10000);<br>&#x2F;&#x2F;        props.put(ProducerConfig.MAX_REQUEST_SIZE_CONFIG, 10);<br>&#x2F;&#x2F;        props.put(ProducerConfig.BUFFER_MEMORY_CONFIG, 10240);<br>        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, “org.apache.kafka.common.serialization.StringSerializer”);<br>        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());<br>        props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, “false”);</p>
<pre><code>    KafkaProducer&lt;String, String&gt; producer = new KafkaProducer(props);
    for (int i = 0;i&lt;10;i++) &#123;
        ProducerRecord&lt;String, String&gt; msg = new ProducerRecord&lt;&gt;(&quot;tpc_2&quot;, &quot;name&quot;+i, &quot;0 &quot;+i );
        producer.send(msg);
    &#125;
    producer.close();
&#125;
</code></pre>
<p>2.生产者api参数发送方式（发后即忘）<br>发后即忘,它只管往 Kafka 发送,并不关心消息是否正确到达。<br>在大多数情况下,这种发送方式没有问题;<br>不过在某些时候(比如发生不可重试异常时)会造成消息的丢失。<br>这种发送方式的性能最高,可靠性最差。<br>Future<RecordMetadata> send &#x3D; producer.send(rcd);<br>3.同步发送(sync )<br>try {<br>    producer.send(rcd).get();<br>} catch (Exception e) {<br>    e.printStackTrace();<br> }<br>0.8.x 前,有一个参数 producer.type&#x3D;sycn|asycn 来决定生产者的发送模式;现已失效(新版中,producer 在底层只有异步)<br>4.异步发送(async )<br>回调函数会在 producer 收到 ack 时调用,为异步调用,该方法有两个参数,分别是 RecordMetadata 和Exception,如果 Exception 为 null,说明消息发送成功,如果 Exception 不为 null,说明消息发送失败。<br>注意:消息发送失败会自动重试,不需要我们在回调函数中手动重试。<br>消费者API<br>1.一个正常的消费逻辑需要具备以下几个步骤:<br>(1)配置消费者客户端参数<br>(2)创建相应的消费者实例;<br>(3)订阅主题;<br>(4)拉取消息并消费;<br>(5)提交消费位移 offset;<br>(6)关闭消费者实例<br>代码如下:<br>import org.apache.kafka.clients.consumer.ConsumerConfig;<br>import org.apache.kafka.clients.consumer.ConsumerRecord;<br>import org.apache.kafka.clients.consumer.ConsumerRecords;<br>import org.apache.kafka.clients.consumer.KafkaConsumer;<br>import org.apache.kafka.common.serialization.StringDeserializer;<br>import org.apache.kafka.common.serialization.StringSerializer;<br>import java.time.Duration;<br>import java.util.Arrays;<br>import java.util.Properties;<br>import java.util.concurrent.atomic.AtomicBoolean;<br>public class ConsumerDemo {<br>    private static final String SERVERS &#x3D; “node1:9092,node2:9092,node3:9092”;</p>
<pre><code>public static void main(String[] args) throws InterruptedException &#123;
    //定义一个AtomicBoolean类型的isRunning来控制消费者拉取消息
    AtomicBoolean isRunning = new AtomicBoolean(true);
    //1.参数配置
    Properties props = new Properties();
    //key的反序列化器
   props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
    //value的反序列化器
  props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,StringDeserializer.class.getName());
    //服务器地址
props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,SERVERS);
    //设置自动读取的起始offset（偏移量），值可以是：earliest，latest，none     props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG,&quot;earliest&quot;);
    //设置自动提交offset（偏移量）  props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG,true);
    //设置消费者组
    props.put(ConsumerConfig.GROUP_ID_CONFIG,&quot;b1&quot;);
    //2.构建consumer实例
    KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;String, String&gt;(props);
    //3.订阅主题
    consumer.subscribe(Arrays.asList(&quot;tpc_1&quot;));
    //4.拉取消息
    Thread thread = new Thread(new Runnable() &#123;
        @Override
        public void run() &#123;
            while (isRunning.get())&#123;
                ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofMillis(Long.MAX_VALUE));
                for (ConsumerRecord&lt;String, String&gt; record : records) &#123;
                    //do some process做一些处理
                    System.out.println(record.key()+&quot;,&quot;
                            +record.value()+&quot;,&quot;
                            +record.topic()+&quot;,&quot;
                            +record.partition()+&quot;,&quot;
                            +record.offset());
                    System.out.println(&quot;------------------------分割线---------------------------&quot;);
                &#125;
            &#125;
        &#125;
    &#125;);
    thread.start();
    //主线程可以去休眠60s
    Thread.sleep(60000);
    //修改isRunning的值为false
    isRunning.set(false);
    //5.关闭consumer实例
    consumer.close();
&#125;
</code></pre>
<p>}<br>五、Topic管理API<br>一般情况下,我们都习惯使用 kafka-topic.sh 本来管理主题,如果希望将管理类的功能集成到公司内部的系统中,打造集管理、监控、运维、告警为一体的生态平台,那么就需要以程序调用 API 方式去实现。这种调用 API 方式实现管理主要利用 KafkaAdminClient 工具类KafkaAdminClient 不仅可以用来管理 broker、配置和 ACL (Access Control List),还可用来管理主题)它提供了以下方法:</p>
<p>1.列出主题<br>ListTopicsResult listTopicsResult &#x3D; adminClient.listTopics();<br>Set<String> topics &#x3D; listTopicsResult.names().get();<br>System.out.println(topics);<br>2.查看主题信息<br>DescribeTopicsResultdescribeTopicsResult&#x3D; &#x3D; adminClient.describeTopics(Arrays.asList(“tpc_3”, “tpc_4”));<br>Map&lt;String, TopicDescription&gt; res &#x3D; describeTopicsResult.all().get();<br>Set<String> ksets &#x3D; res.keySet();<br>for (String k : ksets) {<br>    System.out.println(res.get(k));<br>}<br>3.创建主题<br>代码示例:<br>&#x2F;&#x2F; 参数配置<br>Properties props &#x3D; new Properties();<br>props.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG,”node1:9092,node2:9092,node3:9092”);<br>props.put(AdminClientConfig.REQUEST_TIMEOUT_MS_CONFIG,3000);<br>&#x2F;&#x2F; 创建 admin client 对象<br>AdminClient adminClient &#x3D; KafkaAdminClient.create(props);<br>&#x2F;&#x2F; 由服务端 controller 自行分配分区及副本所在 broker<br>NewTopic tpc_3 &#x3D; new NewTopic(“tpc_3”, 2, (short) 1);<br>&#x2F;&#x2F; 手动指定分区及副本的 broker 分配<br>HashMap&lt;Integer, List<Integer>&gt; replicaAssignments &#x3D; new HashMap&lt;&gt;();<br>&#x2F;&#x2F;分区0分配到broker0,broker1 replicaAssignments.put(0,Arrays.asList(0,1));<br>&#x2F;&#x2F; 分区 1,分配到 broker0,broker2<br>replicaAssignments.put(0,Arrays.asList(0,1));<br>NewTopic tpc_4 &#x3D; new NewTopic(“tpc_4”, replicaAssignments);<br>CreateTopicsResultresult&#x3D; &#x3D; adminClient.createTopics(Arrays.asList(tpc_3,tpc_4));<br>&#x2F;&#x2F; 从 future 中等待服务端返回<br>try {<br>    result.all().get();<br>} catch (Exception e) {<br>e.printStackTrace();<br>}<br>adminClient.close();<br>4.删除主题<br>代码示例:<br>DeleteTopicsResultdeleteTopicsResult&#x3D; &#x3D; adminClient.deleteTopics(Arrays.asList(“tpc_1”, “tpc_1”));<br>Map&lt;String, KafkaFuture<Void>&gt; values &#x3D; deleteTopicsResult.values();<br> System.out.println(values);<br>5.除了进行 topic 管理之外,KafkaAdminClient 也可以进行诸如动态参数管理,分区管理等各类管理操作;</p>

            </div>
        
        <footer class="article-footer">
        </footer>
    </div>
</article>


    
<nav id="article-nav">
    
    
        <a href="/2022/06/12/Kafka%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%93%8D%E4%BD%9C/" id="article-nav-older" class="article-nav-link-wrap">
            <strong class="article-nav-caption">下一篇</strong>
            <div class="article-nav-title">Kafka命令行操作</div>
        </a>
    
</nav>





    
    




<!-- baidu url auto push script -->
<script type="text/javascript">
    !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=window.location.href,o=document.referrer;if(!e.test(r)){var n="//api.share.baidu.com/s.gif";o?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var t=new Image;t.src=n}}(window);
</script>     
</section>
        </div>
        <footer id="footer">
    <div class="outer">
        <div id="footer-info" class="inner">
            John Doe &copy; 2022 
            <a rel="license noopener" target="_blank" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-nd/4.0/80x15.png" /></a>
            <br> Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>. Theme - <a target="_blank" rel="noopener" href="https://github.com/zthxxx/hexo-theme-Wikitten">wikitten</a>
            
                <br>
                <span id="busuanzi_container_site_pv"><i class="fa fa-eye"></i> <span id="busuanzi_value_site_pv"></span></span>
                &nbsp;|&nbsp;
                <span id="busuanzi_container_site_pv"><i class="fa fa-user"></i> <span id="busuanzi_value_site_uv"></span></span>
            
        </div>
    </div>
</footer>

        

    
        
<script src="/libs/lightgallery/js/lightgallery.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-pager.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-zoom.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-hash.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-share.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-video.min.js"></script>

    
    
        
<script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>

    
    
        <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true,
            TeX: {
                equationNumbers: {
                  autoNumber: 'AMS'
                }
            }
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    



<!-- Custom Scripts -->

<script src="/js/main.js"></script>


    </div>
</body>
</html>