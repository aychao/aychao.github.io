<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>aychao</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2023-02-28T13:47:16.533Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>John Doe</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title></title>
    <link href="http://example.com/2023/02/28/Web%E5%89%8D%E7%AB%AF%E5%9F%BA%E7%A1%80/"/>
    <id>http://example.com/2023/02/28/Web%E5%89%8D%E7%AB%AF%E5%9F%BA%E7%A1%80/</id>
    <published>2023-02-28T13:57:59.283Z</published>
    <updated>2023-02-28T13:47:16.533Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Web前端基础"><a href="#Web前端基础" class="headerlink" title="Web前端基础"></a>Web前端基础</h1><ul><li><p>HTML:  学习如何搭建页面  (盖房子,毛坯房)</p></li><li><p>CSS:  学习如何美化页面 (装修)    </p></li><li><p>JavaScript: 学习如何给页面添加动态效果</p></li></ul><h1 id="HTML"><a href="#HTML" class="headerlink" title="HTML"></a>HTML</h1><ul><li><p>Hypertext Markup Language:  超文本标记语言  </p></li><li><p>标记语言的格式:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;开始标签 属性名=&quot;属性值&quot; 属性名=&quot;属性值&quot;&gt;标签体&lt;/结束标签&gt;</span><br></pre></td></tr></table></figure></li><li><p>学习HTML 主要学习的就是有哪些标签,以及标签的使用方式</p></li></ul><h3 id="常用快捷键"><a href="#常用快捷键" class="headerlink" title="常用快捷键"></a>常用快捷键</h3><ul><li><p>Alt+Insert 新建文件</p></li><li><p>Ctrl+D 复制整行并粘贴到下一行</p></li><li><p>Shift+回车  切换到下一行</p></li><li><p>Ctrl+Alt+L 代码格式化  </p></li><li><p>Ctrl+X   剪切  (可以用做删除)</p></li><li><p>Ctrl+Z   撤销  </p></li><li><p>Ctrl+Shift+Z  恢复</p></li><li><p>Ctrl+Shift+&#x2F;   注释</p></li></ul><h3 id="文本相关标签"><a href="#文本相关标签" class="headerlink" title="文本相关标签"></a>文本相关标签</h3><ul><li><p>内容标题h1-h6</p><p>字体加粗, 独占一行, 自带上下的间距</p></li><li><p>水平分割线 hr</p></li><li><p>段落标签 p</p><p>独占一行, 自带上下间距</p></li><li><p>换行br</p></li><li><p>加粗b</p></li><li><p>斜体i</p></li><li><p>下划线u</p></li><li><p>删除线s</p></li><li><p>无序列表:   ul和li</p></li><li><p>有序列表:  ol和li</p></li><li><p>列表嵌套:  有序和无序列表可以任意无限嵌套</p></li></ul><h3 id="图片标签img"><a href="#图片标签img" class="headerlink" title="图片标签img"></a>图片标签img</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">src设置资源路径:</span><br><span class="line">            相对路径:访问站内资源时使用</span><br><span class="line">                1. 资源和页面在同级目录:  直接写图片名</span><br><span class="line">                2. 资源在页面的上级目录:  ../图片名</span><br><span class="line">                3. 资源在页面的下级目录:  文件夹名/图片名</span><br><span class="line">            绝对路径:访问站外资源时使用,称为图片盗链, 有找不到图片的风险</span><br><span class="line">alt:当图片不能正常显示时显示的文本</span><br><span class="line">title: 鼠标悬停时显示的文本</span><br><span class="line">width/height:设置宽高  两种赋值方式:1.像素 2.百分比</span><br><span class="line">            只设置宽度 高度会自动等比例缩放</span><br></pre></td></tr></table></figure><h3 id="超链接a"><a href="#超链接a" class="headerlink" title="超链接a"></a>超链接a</h3><ul><li>href: 设置请求的资源路径,作用类似图片标签的src属性</li><li>图片超链接: 用a标签包裹文本为文本超链接, 包裹图片为图片超链接</li><li>页面内部跳转:  在目的地元素里面添加id属性,  然后在超链接href&#x3D;”#id”,这样就能跳转到指定元素的位置</li></ul><h3 id="表格标签table"><a href="#表格标签table" class="headerlink" title="表格标签table"></a>表格标签table</h3><ul><li>相关标签:    table   tr表示行   td表示列   th表头     caption表格标题  </li><li>相关属性:   border边框    colspan跨列     rowspan跨行</li></ul><h3 id="表单form"><a href="#表单form" class="headerlink" title="表单form"></a>表单form</h3><ul><li>作用:  获取用户输入的各种信息 并提交给服务器 </li><li>学习form表单就是学习有哪些控件, 控件包括: 文本框,密码框,单选,多选,下拉选等</li></ul><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--action设置请求地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">form</span> <span class="attr">action</span>=<span class="string">&quot;http://www.tmooc.cn&quot;</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--文本框, name属性是所有控件必须添加的属性 否则提交时不会传递此内容 placeholder占位文本</span></span><br><span class="line"><span class="comment">  maxlength设置最大字符长度  value设置默认值  readonly只读 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span> <span class="attr">name</span>=<span class="string">&quot;username&quot;</span> <span class="attr">maxlength</span>=<span class="string">&quot;5&quot;</span> <span class="attr">value</span>=<span class="string">&quot;abc&quot;</span> <span class="attr">readonly</span> <span class="attr">placeholder</span>=<span class="string">&quot;用户名&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--密码框--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;password&quot;</span> <span class="attr">name</span>=<span class="string">&quot;password&quot;</span> <span class="attr">placeholder</span>=<span class="string">&quot;密码&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--value设置提交的内容,如果不设置提交的是on checked设置默认选中 --&gt;</span></span><br><span class="line">  性别:</span><br><span class="line">  <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;radio&quot;</span> <span class="attr">name</span>=<span class="string">&quot;gender&quot;</span> <span class="attr">value</span>=<span class="string">&quot;m&quot;</span> <span class="attr">id</span>=<span class="string">&quot;r1&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">&quot;r1&quot;</span>&gt;</span>男<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;radio&quot;</span> <span class="attr">name</span>=<span class="string">&quot;gender&quot;</span> <span class="attr">value</span>=<span class="string">&quot;w&quot;</span> <span class="attr">checked</span> <span class="attr">id</span>=<span class="string">&quot;r2&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">&quot;r2&quot;</span>&gt;</span>女<span class="tag">&lt;/<span class="name">label</span>&gt;</span> <span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">  兴趣爱好:</span><br><span class="line">  <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;checkbox&quot;</span> <span class="attr">name</span>=<span class="string">&quot;hobby&quot;</span> <span class="attr">value</span>=<span class="string">&quot;cy&quot;</span>&gt;</span>抽烟</span><br><span class="line">  <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;checkbox&quot;</span> <span class="attr">name</span>=<span class="string">&quot;hobby&quot;</span> <span class="attr">value</span>=<span class="string">&quot;hj&quot;</span>&gt;</span>喝酒</span><br><span class="line">  <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;checkbox&quot;</span> <span class="attr">name</span>=<span class="string">&quot;hobby&quot;</span> <span class="attr">value</span>=<span class="string">&quot;tt&quot;</span> <span class="attr">checked</span>&gt;</span>烫头<span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">  所在地:</span><br><span class="line">  <span class="tag">&lt;<span class="name">select</span> <span class="attr">name</span>=<span class="string">&quot;city&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">&quot;bj&quot;</span>&gt;</span>北京<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">&quot;sh&quot;</span> <span class="attr">selected</span>&gt;</span>上海<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">&quot;gz&quot;</span>&gt;</span>广州<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">select</span>&gt;</span><span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">  靓照:</span><br><span class="line">  <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;file&quot;</span> <span class="attr">name</span>=<span class="string">&quot;pic&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">  生日:</span><br><span class="line">  <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;date&quot;</span> <span class="attr">name</span>=<span class="string">&quot;birthday&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--提交按钮--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;submit&quot;</span> <span class="attr">value</span>=<span class="string">&quot;注册&quot;</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;reset&quot;</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;button&quot;</span> <span class="attr">value</span>=<span class="string">&quot;自定义&quot;</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">hr</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">button</span> <span class="attr">type</span>=<span class="string">&quot;submit&quot;</span>&gt;</span>注册<span class="tag">&lt;/<span class="name">button</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">button</span> <span class="attr">type</span>=<span class="string">&quot;reset&quot;</span>&gt;</span>重置<span class="tag">&lt;/<span class="name">button</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">button</span> <span class="attr">type</span>=<span class="string">&quot;button&quot;</span>&gt;</span>自定义<span class="tag">&lt;/<span class="name">button</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="分区标签"><a href="#分区标签" class="headerlink" title="分区标签"></a>分区标签</h3><ul><li>分区标签可以理解为一个容器, 将多个有相关性的标签添加到一个分区标签里面, 便于统一管理</li><li>常见的分区标签:<ul><li>div:  独占一行 </li><li>span: 共占一行</li></ul></li><li>HTML5.0版本增加的分区标签 ,这些标签的作用和div 一样, 为了提高代码的可读性  <ul><li>header 头</li><li>footer  脚</li><li>main   主体</li><li>nav    导航</li><li>section   区域</li></ul></li></ul><h1 id="CSS-层叠样式表"><a href="#CSS-层叠样式表" class="headerlink" title="CSS 层叠样式表"></a>CSS 层叠样式表</h1><ul><li>作用: 负责美化页面 (相当于装修)</li></ul><h3 id="如何在html页面中添加css样式代码"><a href="#如何在html页面中添加css样式代码" class="headerlink" title="如何在html页面中添加css样式代码"></a>如何在html页面中添加css样式代码</h3><ul><li>三种引入方式:<ul><li>内联: 在标签的style属性中添加样式代码,  不能复用</li><li>内部: 在head标签里面添加style标签, 在标签体内添加样式代码, 可以当前页面复用 不能多页面复用</li><li>外部: 在单独css文件中添加样式代码, 在html页面中的head标签里面添加link标签 把css引入到html页面中, 支持多页面复用</li></ul></li></ul><h3 id="CSS选择器"><a href="#CSS选择器" class="headerlink" title="CSS选择器"></a>CSS选择器</h3><ul><li>作用: 用来查找页面中的元素</li></ul><ol><li><p>标签名选择器: 匹配页面中所有同名标签 </p><p>格式:   标签名{样式代码}</p></li><li><p>id选择器:    当需要选择页面中某一个标签时使用  </p><p>格式:  #id{样式代码}</p></li><li><p>类选择器: 当需要选择页面中多个不相关的元素时,给多个元素添加相同的class值划分为同一类</p><p>格式: .class{样式代码}</p></li><li><p>分组选择器: 将多个选择器划分为同一组进行统一管理</p><p>格式: div,#id,.class{样式代码}</p></li><li><p>属性选择器: 通过元素的属性匹配元素</p><p>格式: 标签名[属性名&#x3D;’值’]{样式代码}</p></li><li><p>后代选择器: 通过元素和元素之间的层级关系元素元素,选择的范围更广</p><p>格式: body div div p{样式代码}  匹配的是body里面的div里面的div里面的所有p(包含后代)</p></li><li><p>子元素选择器: 通过元素和元素之间的层级关系元素元素, 选择的范围更精准 </p><p>格式: body&gt;div&gt;div&gt;p{样式代码} 匹配的是body里面的div里面的div里面的所有p子元素(不包含后代)</p></li><li><p>伪类选择器:  选择元素的状态     包括: 未访问&#x2F;访问过&#x2F;悬停&#x2F;激活</p><p>格式: a:link&#x2F;visited&#x2F;hover&#x2F;active{样式代码}</p></li></ol><h3 id="颜色赋值方式"><a href="#颜色赋值方式" class="headerlink" title="颜色赋值方式"></a>颜色赋值方式</h3><ul><li>三原色: RGB   Red Green Blue   ,  每一种颜色的取值范围0-255 </li><li>五种赋值方式:<ul><li>颜色单词赋值:   red&#x2F;blue&#x2F;yellow&#x2F;green….</li><li>6位16进制赋值:  #ff0000    </li><li>3位16进制赋值:  #f00</li><li>3位10进制赋值:  rgb(255,0,0)</li><li>4位10进制赋值:  rgba(255,0,0,0-1)    a&#x3D;alpha 透明度 值越小越透明</li></ul></li></ul><h3 id="背景图片相关"><a href="#背景图片相关" class="headerlink" title="背景图片相关"></a>背景图片相关</h3><ul><li>background-image:url(“路径”)  设置背景图片</li><li>background-size:200px 300px;  设置背景图片尺寸</li><li>background-repeat:no-repeat; 禁止重复</li><li>background-position: 100px 200px;  设置背景图片的位置 </li><li>background-position: 50% 50%;  设置背景图片的位置</li></ul><h3 id="文本和字体相关样式"><a href="#文本和字体相关样式" class="headerlink" title="文本和字体相关样式"></a>文本和字体相关样式</h3><ul><li>text-align:right&#x2F;center;  水平对齐方式</li><li>text-decoration:overline上划线&#x2F;underline下划线&#x2F;line-through删除线&#x2F;none去掉修饰</li><li>line-height:20px; 设置行高, 单行可以实现垂直居中, 多行可以控制行间距</li><li>text-shadow:颜色 x偏移值 y偏移值 浓度(值越小越清晰);</li><li>font-size:20px; 字体大小</li><li>font-weight:bold加粗&#x2F;normal去掉加粗;</li><li>font-style:italic; 设置斜体</li><li>font-family:xxxx,xxx,xxx;  设置字体</li><li>font: 20px  xxx,xxx,xxx; 设置字体大小+字体</li></ul><h3 id="元素的显示方式display"><a href="#元素的显示方式display" class="headerlink" title="元素的显示方式display"></a>元素的显示方式display</h3><ul><li>block: 块级元素的默认值, 显示特点: 独占一行,可以修改元素的宽高.  包括: h1-h6,p,div</li><li>inline: 行内元素的默认值, 显示特点: 共占一行, 不能修改元素的宽高.  包括: span,b,i,s,u,a</li><li>inline-block: 行内块元素的默认值, 显示特点: 共占一行, 并且可以修改元素宽高. 包括: input,img</li><li>none:   隐藏元素</li></ul><h3 id="盒子模型"><a href="#盒子模型" class="headerlink" title="盒子模型"></a>盒子模型</h3><ul><li>通过盒子模型相关的样式控制元素的显示效果</li><li>盒子模型包括: content内容+border边框+margin外边距+padding内边距</li><li>content内容:用来控制元素的显示大小</li><li>border边框: 用来控制边框的效果</li><li>margin外边距: 用来控制元素的显示位置</li><li>padding内边距: 用来控制元素内容的位置</li></ul><h3 id="盒子模型之Content内容"><a href="#盒子模型之Content内容" class="headerlink" title="盒子模型之Content内容"></a>盒子模型之Content内容</h3><ul><li>控制元素的显示大小</li><li>相关样式:  width&#x2F;height    赋值方式:1. 像素   2. 上级元素的百分比  </li><li>行内元素是不能修改宽高的, 如果必须要修改, 需要将元素的显示方式改成块级block或行内块inline-block</li></ul><h3 id="盒子模型之margin外边距"><a href="#盒子模型之margin外边距" class="headerlink" title="盒子模型之margin外边距"></a>盒子模型之margin外边距</h3><ul><li><p>控制元素的显示位置</p></li><li><p>赋值方式:</p><ul><li>margin-left&#x2F;right&#x2F;top&#x2F;bottom:10px; 单独某一个方向赋值</li><li>margin:10px;  四个方向赋值</li><li>margin:10px 20px; 上下10  左右20</li><li>margin:10px 20px 30px 40px;   上右下左赋值   顺时针</li></ul></li><li><p>行内元素上下外边距无效  </p></li><li><p>左右相邻彼此添加外边距 两者相加</p></li><li><p>外边距塌陷:</p><ul><li>兄弟元素上下相邻, 彼此添加外边距 取最大值</li><li>父子元素上边缘重叠时, 添加外边距取最大值,会导致父子元素粘连在一起,给父元素添加overflow:hidden样式解决.</li></ul></li></ul><h3 id="盒子模型之边框border"><a href="#盒子模型之边框border" class="headerlink" title="盒子模型之边框border"></a>盒子模型之边框border</h3><ul><li><p>赋值方式:</p><ul><li>border-left&#x2F;right&#x2F;top&#x2F;bottom:粗细 样式 颜色;  单独某一个方向添加边框</li><li>border:粗细 样式 颜色;  四个方向添加边框</li></ul></li><li><p>border-radius:10px ;  设置圆角 值越大越圆</p></li></ul><h3 id="盒子模型之内边距padding"><a href="#盒子模型之内边距padding" class="headerlink" title="盒子模型之内边距padding"></a>盒子模型之内边距padding</h3><ul><li>控制元素内容的位置 </li><li>赋值方式:    和外边距类似<ul><li>padding-left&#x2F;right&#x2F;top&#x2F;bottom:10px;  单独某一个方向添加</li><li>padding:10px;  四个方向添加</li><li>padding: 10px 20px; 上下10 左右20</li><li>padding: 10px 20px 30px 40px;  上右下左 顺时针赋值</li></ul></li><li>给元素添加内边距默认情况下会影响元素的显示范围,给元素添加box-sizing:border-box; 后则不再影响</li></ul><h3 id="部分标签会带盒子模型中的某些样式"><a href="#部分标签会带盒子模型中的某些样式" class="headerlink" title="部分标签会带盒子模型中的某些样式"></a>部分标签会带盒子模型中的某些样式</h3><ul><li><p>body 自带8个像素的外边距</p></li><li><p>段落标签p, 列表标签和内容标题h1-h6  自带上下的外边距</p></li><li><p>文本框自带边框和内边距 </p></li><li><p>列表标签自带外边距和内边距</p></li></ul><h3 id="CSS三大特性"><a href="#CSS三大特性" class="headerlink" title="CSS三大特性"></a>CSS三大特性</h3><p>&#x3D;&#x3D;继承性:&#x3D;&#x3D; 指元素可以继承上级元素文本和字体相关的样式, 部分标签自带的效果不受继承影响, 比如超链接的字体颜色<br>&#x3D;&#x3D;层叠性:&#x3D;&#x3D; 指一个元素可以层叠很多不同的样式,  多个选择器有可能选择到同一个元素, 如果添加的样式不同,则样式全部层叠生效,如果添加的样式相同则由选择器的优先级决定哪个生效<br>&#x3D;&#x3D;优先级:&#x3D;&#x3D; 作用范围越小 优先级越高.       !important&gt;id&gt;class&gt;标签名&gt;继承(属于间接选中)</p><h3 id="居中相关"><a href="#居中相关" class="headerlink" title="居中相关"></a>居中相关</h3><ul><li>元素自身居中:<ul><li>块级元素:  通过外边距  margin:0 auto;  </li><li>行内或行内块元素:   在上级元素中添加text-align:center;</li></ul></li><li>元素内容居中:  只能通过text-align:center;</li></ul><h3 id="定位"><a href="#定位" class="headerlink" title="定位"></a>定位</h3><ul><li>静态定位</li><li>相对定位</li><li>绝对定位</li><li>固定定位</li><li>浮动定位</li></ul><h3 id="静态定位"><a href="#静态定位" class="headerlink" title="静态定位"></a>静态定位</h3><ul><li><p>position:static;</p></li><li><p>默认的定位方式,又称为文档流定位 </p></li><li><p>特点: 块级元素从上往下依次排列, 行内元素从左向右依次排列,通过外边距控制元素的位置.</p></li><li><p>默认情况下无法实现元素层叠效果</p></li></ul><h3 id="相对定位"><a href="#相对定位" class="headerlink" title="相对定位"></a>相对定位</h3><ul><li>position:relative;</li><li>特点: 元素不脱离文档流(不管元素显示到什么位置,仍然占着原来的位置,后面的元素不会顶上来),元素通过left&#x2F;right&#x2F;top&#x2F;bottom样式 相对于初始位置做偏移.</li><li>应用场景: 当元素需要层叠显示时, 静态定位是无法实现的,  通过相对于定位可以实现层叠, 当需要对某一个元素的显示位置进行微调时使用.</li></ul><h3 id="绝对定位"><a href="#绝对定位" class="headerlink" title="绝对定位"></a>绝对定位</h3><ul><li>position:absolute;</li><li>特点: 元素脱离文档流(不占原来的位置, 后面的元素会顶上来), 通过left&#x2F;right&#x2F;top&#x2F;bottom相对于窗口(默认)或某一个上级元素做偏移.</li><li>应用场景: 当需要层叠显示,并且需要让元素相对于某个上级元素做位置偏移时使用</li></ul><h3 id="固定定位"><a href="#固定定位" class="headerlink" title="固定定位"></a>固定定位</h3><ul><li><p>position:fixed;</p></li><li><p>特点: 元素脱离文档流,  通过left&#x2F;right&#x2F;top&#x2F;bottom相对于窗口做位置偏移.</p></li><li><p>应用场景: 当需要将元素固定在窗口的某个位置时使用</p></li></ul><h3 id="浮动定位"><a href="#浮动定位" class="headerlink" title="浮动定位"></a>浮动定位</h3><ul><li>float:left&#x2F;right</li><li>特点: 元素脱离文档流, 从当前所在行向左或向右浮动,当撞到上级元素边缘或其它浮动元素时停止.</li><li>多个浮动元素一行装不下时会自动折行, 折行时有可能被卡主</li><li>当元素的所有子元素全部浮动时, 自动识别的内容高度为0, 会导致后面的元素顶上来 出现显示异常, 给元素添加overflow:hidden 解决此问题.</li><li>应用场景:  将纵向排列的多个元素 改成横向排列时使用.</li></ul><h3 id="表设计面试题"><a href="#表设计面试题" class="headerlink" title="表设计面试题"></a>表设计面试题</h3><p>2021年过年时小明在这些天都收到了许多亲戚\朋友还有同事的红包,也发出了一些红包,有的是微信,有的是支付宝也有现金,请参考下面的题目帮小明设计表格保存红包的信息</p><ol><li><p>设计表保存红包信息 (至少包含一张流水表)</p><ul><li><p>列出需要保存的数据有哪些:</p><p>人物关系,红包金额,红包类型,时间,性别,名字</p><p>流水表: id,金额,时间,红包类型,人物id</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">CREATE DATABASE mydb CHARSET=UTF8;</span><br><span class="line">USE mydb;</span><br><span class="line">CREATE TABLE trade(id INT PRIMARY KEY AUTO_iNCREMENT,money INT,time DATE,type VARCHAR(10),p_id INT);</span><br></pre></td></tr></table></figure><p>人物表:id,名字,性别,关系</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE person(id INT PRIMARY KEY AUTO_iNCREMENT,name VARCHAR(20),gender CHAR(1),rel VARCHAR(10));</span><br></pre></td></tr></table></figure><p>插入数据:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">INSERT INTO person VALUES(NULL,&#x27;刘德华&#x27;,&#x27;男&#x27;,&#x27;亲戚&#x27;),</span><br><span class="line">(NULL,&#x27;杨幂&#x27;,&#x27;女&#x27;,&#x27;亲戚&#x27;),(NULL,&#x27;马云&#x27;,&#x27;男&#x27;,&#x27;同事&#x27;),(NULL,&#x27;特朗普&#x27;,&#x27;男&#x27;,&#x27;朋友&#x27;),(NULL,&#x27;貂蝉&#x27;,&#x27;女&#x27;,&#x27;朋友&#x27;);</span><br><span class="line">INSERT INTO trade VALUES(NULL,1000,&#x27;2021-3-20&#x27;,&#x27;微信&#x27;,1),</span><br><span class="line">(NULL,500,&#x27;2021-4-14&#x27;,&#x27;现金&#x27;,2),</span><br><span class="line">(NULL,-50,&#x27;2021-4-14&#x27;,&#x27;现金&#x27;,2),</span><br><span class="line">(NULL,20000,&#x27;2021-3-11&#x27;,&#x27;支付宝&#x27;,3),</span><br><span class="line">(NULL,-5,&#x27;2021-3-11&#x27;,&#x27;支付宝&#x27;,3),</span><br><span class="line">(NULL,2000,&#x27;2021-5-18&#x27;,&#x27;微信&#x27;,4),</span><br><span class="line">(NULL,-20000,&#x27;2021-7-22&#x27;,&#x27;微信&#x27;,5);</span><br></pre></td></tr></table></figure></li></ul></li><li><p>统计2021年3月15号到现在的所有红包收益    </p><p>SELECT SUM(money) FROM TRADE WHERE time&gt;’2021-3-15’;</p></li><li><p>查询2021年2月15号到现在 金额大于100 所有女性亲戚的名字和金额</p><p>SELECT name,money</p><p>FROM trade t JOIN person p ON t.p_id&#x3D;p.id</p><p>WHERE time&gt;’2021-2-15’ AND ABS(money)&gt;100 </p><p>AND gender&#x3D;’女’ AND rel&#x3D;’亲戚’;</p></li><li><p>查询三个平台(微信,支付宝,现金)分别收入的红包金额</p><p>SELECT type,SUM(money) FROM trade WHERE money&gt;0 GROUP BY type;</p></li></ol><h3 id="溢出设置overflow"><a href="#溢出设置overflow" class="headerlink" title="溢出设置overflow"></a>溢出设置overflow</h3><ul><li>hidden 隐藏</li><li>visible 显示</li><li>scroll 滚动显示</li></ul><h3 id="显示层级"><a href="#显示层级" class="headerlink" title="显示层级"></a>显示层级</h3><ul><li>当元素为非static 定位,出现层叠时, 可以通过z-index设置显示层级, 值越大显示越靠前</li></ul><h3 id="行内元素垂直对齐方式vertical-align"><a href="#行内元素垂直对齐方式vertical-align" class="headerlink" title="行内元素垂直对齐方式vertical-align"></a>行内元素垂直对齐方式vertical-align</h3><ul><li>top上对齐</li><li>middle中间对齐</li><li>bottom下对齐</li><li>baseline基线对齐</li></ul><h1 id="JavaScript"><a href="#JavaScript" class="headerlink" title="JavaScript"></a>JavaScript</h1><ul><li><p>作用: 给页面添加动态效果</p></li><li><p>语言特点: </p><ul><li>属于脚本语言, 不需要编译由浏览器解析执行.  </li><li>属于弱类型语言        int x &#x3D; 10;   String name&#x3D;”张三” ;     let x&#x3D;10;  let name&#x3D;”张三”;  </li><li>基于面向对象语言</li><li>安全性强:  因为JS语言是嵌入到html页面中运行在客户端的语言,所以对安全性要求较高 , JS语言只能获取浏览器内部的数据, 浏览器以外客户端电脑上面的数据是禁止访问的.  </li><li>交互性强: JS语言是嵌入到html页面中运行在客户端的语言, 和用户直接接触, 而像Java语言是运行在服务器的语言,需要通过网络进行交互,所以相对来说JS语言的交互性更强</li><li>JavaScript和Java语言没有任何关系 , 只是为了蹭热度 .</li></ul><p>变量 数据类型 运算符 各种语句 方法  面向对象</p></li></ul><h3 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h3><ul><li><p>JavaScript语言属于弱类型语言</p><ul><li>Java: int age&#x3D;18; String name&#x3D;”张三”;     name&#x3D;20; 报错</li><li>JS:   let age&#x3D;18; let name&#x3D;”李四”;     name&#x3D;20; 正常执行</li></ul></li><li><p>JavaScript语言中通过let或var声明变量 </p><ul><li><p>let声明的变量, 作用域和Java语言类似</p></li><li><p>var声明的变量, 不管在什么位置都相当于声明的是一个全局变量  </p></li><li><p>举例:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="title class_">Java</span>:</span><br><span class="line"><span class="keyword">for</span>(int i=<span class="number">0</span>;i&lt;<span class="number">10</span>;i++)&#123;</span><br><span class="line"> int j = i+<span class="number">1</span>;   </span><br><span class="line">&#125;</span><br><span class="line">int x = i+j;   <span class="comment">//报错   i和j超出了作用域 </span></span><br><span class="line"><span class="title class_">JavaScript</span>:   <span class="keyword">let</span></span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">let</span> i=<span class="number">0</span>;i&lt;<span class="number">10</span>;i++)&#123;</span><br><span class="line">    <span class="keyword">let</span> j=i+<span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">let</span> x = i+j;    <span class="comment">//不会报错 但是因为i和j超出了作用域,访问不到i和j</span></span><br><span class="line"><span class="title class_">JavaScript</span>:   <span class="keyword">var</span></span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">var</span> i=<span class="number">0</span>;i&lt;<span class="number">10</span>;i++)&#123;</span><br><span class="line">    <span class="keyword">var</span> j=i+<span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">var</span> x = i+j;   <span class="comment">//不会报错, 并且可以访问到i和j的值</span></span><br></pre></td></tr></table></figure></li></ul></li></ul><h3 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h3><ul><li>JavaScript语言中只有引用类型 </li><li>常见的对象类型：<ul><li>string字符串:   可以通过单引号或双引号进行修饰  </li><li>number数值:  相当于java中所有数值类型的总和</li><li>boolean布尔值:   true和false</li><li>undefined未定义:  当变量只声明不赋值时,变量的类型为未定义类型</li></ul></li><li>获取变量类型的方法:      typeof 变量;</li></ul><h3 id="运算符"><a href="#运算符" class="headerlink" title="运算符"></a>运算符</h3><ul><li>算术运算符: + -  * &#x2F;  % <ul><li>除法运算会自动根据结果转换整数或小数     <ul><li>java :   int x &#x3D; 5;  int y&#x3D;2;  int z &#x3D; x&#x2F;y;     z&#x3D;2</li><li>js :  let x &#x3D; 5; let y&#x3D;2;  let z &#x3D; x&#x2F;y;    z&#x3D;2.5        x&#x3D;6   z&#x3D;3</li></ul></li></ul></li><li>关系运算符: &gt;  &lt;    &gt;&#x3D;     &lt;&#x3D;    !&#x3D;    &#x3D;&#x3D;和&#x3D;&#x3D;&#x3D;<ul><li>&#x3D;&#x3D;:  先统一等号两边变量的类型, 再比较值   “666”&#x3D;&#x3D;666        true    </li><li>&#x3D;&#x3D;&#x3D;: 先比较类型,类型相同后再比较值     “666”&#x3D;&#x3D;&#x3D;666   false</li></ul></li><li>逻辑运算符:  &amp;&amp;   ||    !     只支持短路与和短路或  </li><li>赋值运算符:   &#x3D;     +&#x3D;   -&#x3D;   *&#x3D;   &#x2F;&#x3D;   %&#x3D;   </li><li>三目运算符:      条件?值1:值2</li></ul><h3 id="各种语句"><a href="#各种语句" class="headerlink" title="各种语句"></a>各种语句</h3><ul><li>if else</li><li>for  新循环  for(Person p : persons)       JS:    for(let p of persons)</li><li>while</li><li>switch case</li></ul><h3 id="如何在html页面中添加js代码"><a href="#如何在html页面中添加js代码" class="headerlink" title="如何在html页面中添加js代码"></a>如何在html页面中添加js代码</h3><ul><li>三种引入方式<ul><li>内联:在标签的事件属性中添加JS代码,当事件触发时执行.<ul><li>事件: 指系统提供的一系列时间点  .</li><li>点击事件:  当用户点击元素的时间点.</li></ul></li><li>内部: 在页面的任意位置可以添加script标签,在标签体内写js代码, 建议写在body结束标签的附近</li><li>外部: 在单独的js文件中写js代码, 在html页面中通过script标签的src属性引入, 如果script标签引入了js文件则不能在标签体内继续写js代码</li></ul></li></ul><h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><ul><li>Java:  public 返回值 方法名(参数列表){方法体}</li><li>JS:    function 方法名(参数列表){方法体}</li><li>三种定义方法的方式:<ul><li>function 方法名(参数列表){方法体}</li><li>let 方法名 &#x3D; function(参数列表){方法体}</li><li>let 方法名 &#x3D; new Function(“参数1”,”参数2”,”方法体”);</li></ul></li></ul><h3 id="和页面相关的方法"><a href="#和页面相关的方法" class="headerlink" title="和页面相关的方法"></a>和页面相关的方法</h3><ul><li><p>通过选择器获取页面中的元素对象    </p><p>let 元素对象 &#x3D; document.querySelector(“选择器”);</p></li><li><p>获取和修改控件的值  </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;input type=&#x27;text&#x27; value=&#x27;abc&#x27;&gt;</span><br></pre></td></tr></table></figure><p>input.value  获取</p><p>input.value&#x3D;”xxx”  修改</p></li><li><p>获取和修改元素的文本内容      <code>&lt;div&gt;abc&lt;/div&gt;   &lt;span&gt;abc&lt;/span&gt;</code></p></li></ul><h3 id="NaN"><a href="#NaN" class="headerlink" title="NaN"></a>NaN</h3><ul><li><p>Not a Number: 不是一个数, 任何数值和NaN进行任何运算得到的结果都是NaN </p></li><li><p>isNaN(变量) ,判断变量是否是NaN,   true代表是NaN(不是数), false代表不是NaN(是数)</p></li></ul><h3 id="JavaScript对象分类"><a href="#JavaScript对象分类" class="headerlink" title="JavaScript对象分类"></a>JavaScript对象分类</h3><ul><li>内置对象:  包括string,number,boolean等 </li><li>BOM: 浏览器对象模型,包含和浏览器相关的内容</li><li>DOM:文档对象模型,包含和页面相关的内容</li></ul><h3 id="BOM"><a href="#BOM" class="headerlink" title="BOM"></a>BOM</h3><ul><li><p>BrowserObject Model:  浏览器对象模型,包含和浏览器相关的内容</p></li><li><p>window对象, 此对象中的属性和方法可以称为全局属性和全局方法, 访问时可以省略掉window.</p><p>window.isNaN()   window.alert()    window.parseInt()</p></li><li><p>window对象中常见的方法:</p><ul><li>isNaN(变量)  判断变量是否是NaN</li><li>parseInt() 将字符串或小数转成整数</li><li>parseFloat() 将字符串转成小数  </li><li>alert(“xxx”) 弹出提示框</li><li>confirm(“xxx”)弹出确认框</li><li>prompt(“xxx”)弹出文本框</li><li>let timer &#x3D; setInterval(方法,时间间隔);  开启定时器</li><li>clearInterval(timer);  停止定时器</li><li>setTimeout(方法, 时间间隔);  开启只执行一次的定时器</li></ul></li><li><p>window对象中常见的属性</p><ul><li>location(位置)<ul><li>location.href   获取或修改浏览器的请求地址</li><li>location.reload()  刷新页面</li></ul></li><li>history(历史)<ul><li>history.length 历史页面的数量</li><li>history.back()  返回上一页面        后退</li><li>hisotry.forward()  前往下一页面    前进</li><li>history.go(n)      n正值代表前进   n负值代表后退     0代表刷新</li></ul></li></ul></li></ul><h3 id="DOM"><a href="#DOM" class="headerlink" title="DOM"></a>DOM</h3><ul><li><p>Document Object Model 文档对象模型, 包含和页面相关的内容</p></li><li><p>通过选择器获取页面中的元素对象    </p><p>let 元素对象 &#x3D; document.querySelector(“选择器”);</p></li><li><p>获取和修改控件的值  </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;input type=&#x27;text&#x27; value=&#x27;abc&#x27;&gt;</span><br></pre></td></tr></table></figure><p>input.value  获取</p><p>input.value&#x3D;”xxx”  修改</p></li><li><p>获取和修改元素的文本内容      <code>&lt;div&gt;abc&lt;/div&gt;   &lt;span&gt;abc&lt;/span&gt;</code></p><p>元素对象.innerText &#x3D; “xxx”;   修改</p><p>元素对象.innerText    获取</p></li><li><p>创建元素对象</p><p>let d &#x3D; document.createElement(“div”);</p></li><li><p>添加元素到某个元素里面</p><p>元素对象.append(新元素);</p></li></ul><h3 id="前端MVC设计模式"><a href="#前端MVC设计模式" class="headerlink" title="前端MVC设计模式"></a>前端MVC设计模式</h3><ul><li>MVC设计模式就是将实现前端业务的所有代码划分为三部分</li><li>M: model 模型 ,  对应数据相关代码</li><li>V: View  视图,   对应的是页面标签相关</li><li>C: Controller 控制器, 对应的是将数据显示到页面中的过程代码</li><li>前端MVC设计模式存在弊端:  在Controller控制器部分 需要频繁的进行DOM相关操作(遍历查找元素),比较浪费资源 , MVVM设计模式可以解决此问题</li></ul><h3 id="前端MVVM设计模式"><a href="#前端MVVM设计模式" class="headerlink" title="前端MVVM设计模式"></a>前端MVVM设计模式</h3><ul><li>MVVM设计模式也是将实现前端业务的所有代码划分为三部分</li><li>M: model 模型 ,  对应数据相关代码</li><li>V: View  视图,   对应的是页面标签相关</li><li>VM:视图模型, 视图模型负责将页面中可能发生改变的元素和某个变量在内存中进行绑定, 并对变量进行监听,当变量发生改变时,会从内存中找到和变量所对应的元素, 让元素进行改动. 这样就不用像MVC设计模式中通过遍历查找的方式查找元素了，从而提高执行的效率。</li></ul><h3 id="VUE"><a href="#VUE" class="headerlink" title="VUE"></a>VUE</h3><ul><li><p>此框架是基于MVVM设计模式的框架, 目前最流行的前端框架之一.</p></li><li><p>VUE框架两种用法: </p><ul><li>多页面应用: 在html页面中引入vue.js框架文件</li><li>单页面应用:通过脚手架的方式使用VUE框架(第四阶段开始接触)</li></ul></li><li><p>如何在html页面中引入vue.js </p><ul><li><p>从CDN服务器引入</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">&quot;https://cdn.staticfile.org/vue/2.2.2/vue.min.js&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>把框架文件下载到本地后引入</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">&quot;js/vue.min.js&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure></li></ul></li><li><p>VUE框架执行元素:  VUE对象就相当于是MVVM设计模式中的VM视图模型, 此对象负责将页面中发生改变的元素和data里面的变量在内存中绑定, 并且会不断监听变量值的改变, 当检测到变量值发生改变时,会自动从内存中找到与之对应的元素,并且让元素的内容跟着发生改变.</p></li></ul><h3 id="VUE相关指令"><a href="#VUE相关指令" class="headerlink" title="VUE相关指令"></a>VUE相关指令</h3><ul><li>: 插值, 让当前位置的文本内容和变量进行绑定</li><li>v-text&#x3D;”变量”  让元素的文本内容和变量进行绑定</li><li>v-html&#x3D;”变量”  让元素的标签内容和变量进行绑定</li><li>:属性名&#x3D;”变量” 让元素的某个属性的值和变量进行绑定</li><li>v-model&#x3D;”变量” 双向绑定,让控件的值和变量进行双向绑定, 当需要获取控件的值的时候使用</li><li>@事件名&#x3D;”方法” 给元素添加事件,  需要将事件触发的方法声明在methods里面.</li><li>v-for&#x3D;”(变量,下标) in 数组”  循环遍历指令, 遍历的同时会生成元素</li><li>v-if&#x3D;”变量”  让元素是否显示和变量进行绑定, true显示 false不显示(删除元素)</li><li>v-else   让元素的显示状态和v-if取反</li><li>v-show&#x3D;”变量”  让元素是否显示和变量进行绑定, true显示 false不显示(隐藏元素)</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Web前端基础&quot;&gt;&lt;a href=&quot;#Web前端基础&quot; class=&quot;headerlink&quot; title=&quot;Web前端基础&quot;&gt;&lt;/a&gt;Web前端基础&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;HTML:  学习如何搭建页面  (盖房子,毛坯房)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Eagle运维监控</title>
    <link href="http://example.com/2022/08/28/kafka%E9%9B%86%E7%BE%A4Eagle%E8%BF%90%E7%BB%B4%E7%9B%91%E6%8E%A7/"/>
    <id>http://example.com/2022/08/28/kafka%E9%9B%86%E7%BE%A4Eagle%E8%BF%90%E7%BB%B4%E7%9B%91%E6%8E%A7/</id>
    <published>2022-08-28T04:32:29.735Z</published>
    <updated>2023-02-16T14:09:37.516Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要使用Hexo与Github进行个人blog的搭建<br>Hexo官网：<a href="https://hexo.io/zh-cn/">Hexo</a><br>Github官网：<a href="https://github.com/">Github</a></p><h3 id="环境介绍"><a href="#环境介绍" class="headerlink" title="环境介绍"></a>环境介绍</h3><h2 id="本地环境为-Window10系统、Linux虚拟机"><a href="#本地环境为-Window10系统、Linux虚拟机" class="headerlink" title="本地环境为: Window10系统、Linux虚拟机"></a>本地环境为: Window10系统、Linux虚拟机</h2><h2 id="一、Eagle安装"><a href="#一、Eagle安装" class="headerlink" title="一、Eagle安装"></a>一、Eagle安装</h2><p>本文使用的 Eagle 是2.1.0版本<br><a href="http://download.kafka-eagle.org/">Eagle 3.2.0 安装包下载</a><br><strong>注意：下载要注意 Eagle 的版本，同时选择后缀为 .tar.gz的安装包</strong><br>**本文使用的安装包是 kafka-eagle-bin-2.1.0.tar.gz **</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#把本地下载好的 kafka-eagle-bin-2.1.0.tar.gz 安装包上传到 /export/server 并解压</span></span><br><span class="line">$ <span class="built_in">cd</span> /export/server/</span><br><span class="line">$ tar -zxvf kafka-eagle-bin-2.1.0.tar.gz -C /export/server/</span><br><span class="line"><span class="comment"># ls查看，出现kafka-eagle-bin-2.1.0意味着解压成功</span></span><br><span class="line"><span class="comment">#进入到kafka-eagle-bin-2.1.0</span></span><br><span class="line">$ <span class="built_in">cd</span> kafka-eagle-bin-2.1.0</span><br><span class="line"><span class="comment">#ls查看，看到efak-web-2.1.0.gz解压包，对其解压到/export/server/目录下</span></span><br><span class="line">$ tar -zxvf efak-web-2.1.0.gz /export/server/</span><br><span class="line"><span class="comment"># 进入到/export/server/目录下，ls查看，出现efak-web-2.1.0意味着解压成功</span></span><br><span class="line">$ <span class="built_in">cd</span> /export/server/ </span><br><span class="line"><span class="comment">#建立软连接</span></span><br><span class="line">$ <span class="built_in">ln</span> -s /export/server/efak-web-2.1.0 /export/server/kafka-eagle</span><br><span class="line"><span class="comment">#master 节点节点进入 /export/server/kafka-eagle/conf 修改以下配置文件</span></span><br><span class="line">$ <span class="built_in">cd</span> /export/server/kafka-eagle/conf</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="Eagle环境变量"><a href="#Eagle环境变量" class="headerlink" title="Eagle环境变量"></a>Eagle环境变量</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#配置 eagle 环境变量</span></span><br><span class="line">$ vim /etc/profile</span><br><span class="line"><span class="comment">#文件最后添加以下内容</span></span><br><span class="line"><span class="comment"># kafka 环境变量 </span></span><br><span class="line">$ <span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin</span><br><span class="line">$ <span class="built_in">export</span> KE_HOME=/export/server/kafka-eagle</span><br><span class="line">$ <span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$KE_HOME</span>/bin</span><br></pre></td></tr></table></figure><h4 id="启动-Eagle"><a href="#启动-Eagle" class="headerlink" title="启动 Eagle"></a>启动 Eagle</h4><p><strong>注意：启动 Eagle 需要启动 kafka、zookeeper</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#启动 kafka,三台机器同时执行</span></span><br><span class="line">$ kafka-server-start.sh -daemon /export/server/kafka/config/server.properties</span><br><span class="line"><span class="comment">#启动zookeeper,三台机器同时执行</span></span><br><span class="line">$ zkServer.sh start</span><br><span class="line"><span class="comment">#启动 Eagle</span></span><br><span class="line">$ /export/server/kafka-eagle/bin/ke.sh start</span><br><span class="line"><span class="comment">#启动完成后通过jps查看其状态</span></span><br></pre></td></tr></table></figure><h4 id="看到EFAK表明成功启动"><a href="#看到EFAK表明成功启动" class="headerlink" title="看到EFAK表明成功启动"></a>看到EFAK表明成功启动</h4><h4 id="进入到本地界面（http-192-168-88-151-8048），对Eagle进行部署"><a href="#进入到本地界面（http-192-168-88-151-8048），对Eagle进行部署" class="headerlink" title="进入到本地界面（http://192.168.88.151:8048），对Eagle进行部署"></a>进入到本地界面（<a href="http://192.168.88.151:8048），对Eagle进行部署">http://192.168.88.151:8048），对Eagle进行部署</a></h4><h2 id="二、Eagle各项功能"><a href="#二、Eagle各项功能" class="headerlink" title="二、Eagle各项功能"></a>二、Eagle各项功能</h2><h4 id="（1）Dashboard（仪表盘）"><a href="#（1）Dashboard（仪表盘）" class="headerlink" title="（1）Dashboard（仪表盘）"></a>（1）Dashboard（仪表盘）</h4><p>查看BROKERS、TOPICS、ZOOKEEPERS、Topic LogSize Top10等</p><h4 id="（2）BScreen-大屏"><a href="#（2）BScreen-大屏" class="headerlink" title="（2）BScreen(大屏)"></a>（2）BScreen(大屏)</h4><p>该模块包含展示消费者和生产者当日及最近7天趋势、Kafka集群读写速度、Kafka集群历史总记录等</p><h4 id="（3）Topics"><a href="#（3）Topics" class="headerlink" title="（3）Topics"></a>（3）Topics</h4><p>该模块包含主题创建、主题管理、主题预览、KSQL查询主题、主题数据写入、主题属性配置等。</p><h4 id="（4）Consumers（消费监控）"><a href="#（4）Consumers（消费监控）" class="headerlink" title="（4）Consumers（消费监控）"></a>（4）Consumers（消费监控）</h4><p>该模块包含监控不同消费者组中的Topic被消费的详情，例如LogSize、Offsets、以及Lag等。同时，支持查看Lag的历史趋势图</p><h4 id="（5）Cluster（集群管理）"><a href="#（5）Cluster（集群管理）" class="headerlink" title="（5）Cluster（集群管理）"></a>（5）Cluster（集群管理）</h4><p>该模块包含Kafka集群和Zookeeper集群的详情展示，例如Kafka的IP和端口、版本号、启动时间、Zookeeper的Leader和Follower。同时，还支持多Kafka集群切换，以及Zookeeper Client数据查看等功能。</p><h4 id="（6）Metrics（集群状态）"><a href="#（6）Metrics（集群状态）" class="headerlink" title="（6）Metrics（集群状态）"></a>（6）Metrics（集群状态）</h4><p>该模块包含监控Kafka集群和Zookeeper集群的核心指标，包含Kafka的消息发送趋势、消息大小接收与发送趋势、Zookeeper的连接数趋势等。同时，还支持查看Broker的瞬时指标数据。</p><h4 id="（7）Alarm（告警）"><a href="#（7）Alarm（告警）" class="headerlink" title="（7）Alarm（告警）"></a>（7）Alarm（告警）</h4><p>该模块包含告警集群异常和消费者应用Lag异常。同时，支持多种IM告警方式，例如邮件、钉钉、微信、Webhook等。</p><h4 id="（8）System（系统管理）"><a href="#（8）System（系统管理）" class="headerlink" title="（8）System（系统管理）"></a>（8）System（系统管理）</h4><p>该模块包含用户管理，例如创建用户、用户授权、资源管理等</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;本文主要使用Hexo与Github进行个人blog的搭建&lt;br&gt;Hexo官网：&lt;a href=&quot;https://hexo.io/zh-cn/&quot;&gt;Hexo&lt;/a&gt;&lt;br&gt;Github官网：&lt;a href=&quot;https://github.com/&quot;&gt;Github&lt;/a&gt;&lt;/p&gt;</summary>
      
    
    
    
    <category term="工具" scheme="http://example.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
    <category term="hexo" scheme="http://example.com/tags/hexo/"/>
    
    <category term="主题" scheme="http://example.com/tags/%E4%B8%BB%E9%A2%98/"/>
    
    <category term="搭建" scheme="http://example.com/tags/%E6%90%AD%E5%BB%BA/"/>
    
  </entry>
  
  <entry>
    <title>Kafka基础环境配置</title>
    <link href="http://example.com/2022/08/28/Kafka%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
    <id>http://example.com/2022/08/28/Kafka%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/</id>
    <published>2022-08-28T04:32:29.729Z</published>
    <updated>2022-08-11T13:03:44.794Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要使用Hexo与Github进行个人blog的搭建<br>Hexo官网：<a href="https://hexo.io/zh-cn/">Hexo</a><br>Github官网：<a href="https://github.com/">Github</a></p><h3 id="环境介绍"><a href="#环境介绍" class="headerlink" title="环境介绍"></a>环境介绍</h3><p>本地环境为: Window10系统、Linux虚拟机<br><strong>注意：本文配置与Spark基础环境配置相同，若Spark基础环境配置已配置，请直接观看下一文章</strong></p><hr><h1 id="开始搭建"><a href="#开始搭建" class="headerlink" title="开始搭建"></a>开始搭建</h1><h2 id="1-基础环境"><a href="#1-基础环境" class="headerlink" title="1.基础环境"></a>1.基础环境</h2><p>在开始配置前，需要检查虚拟机主机名、hosts映射、关闭防火墙、免密登录、同步时间等操作</p><h3 id="（1）编辑主机名（三台机器）"><a href="#（1）编辑主机名（三台机器）" class="headerlink" title="（1）编辑主机名（三台机器）"></a>（1）编辑主机名（三台机器）</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看系统主机名(三台主机)</span></span><br><span class="line">$ <span class="built_in">cat</span> /etc/hostname</span><br><span class="line"><span class="comment">#在三台主机上更改主机名</span></span><br><span class="line"><span class="comment">#在 master 主节点</span></span><br><span class="line">$ <span class="built_in">echo</span> <span class="string">&quot;master&quot;</span> &gt;/etc/hostname </span><br><span class="line"><span class="comment">#在 slave1 节点 </span></span><br><span class="line">$ <span class="built_in">echo</span> <span class="string">&quot;slave1&quot;</span> &gt;/etc/hostname </span><br><span class="line"><span class="comment">#在 slave2 节点</span></span><br><span class="line">$ <span class="built_in">echo</span> <span class="string">&quot;slave2&quot;</span> &gt;/etc/hostname</span><br></pre></td></tr></table></figure><h3 id="（2）hosts映射"><a href="#（2）hosts映射" class="headerlink" title="（2）hosts映射"></a>（2）hosts映射</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看系统映射</span></span><br><span class="line">$ <span class="built_in">cat</span> /etc/hosts</span><br><span class="line"><span class="comment">#编辑 /etc/hosts 文件</span></span><br><span class="line">$ vim /etc/hosts</span><br><span class="line"><span class="comment">#内容修改为 （三台主机内容一致）</span></span><br><span class="line">127.0.0.1 localhost localhost.localdomain localhost4 </span><br><span class="line">localhost4.localdomain4 </span><br><span class="line">::1 localhost localhost.localdomain localhost6 </span><br><span class="line">localhost6.localdomain6 </span><br><span class="line"></span><br><span class="line">192.168.88.135 master </span><br><span class="line">192.168.88.136 slave1 </span><br><span class="line">192.168.88.137 slave2</span><br></pre></td></tr></table></figure><h3 id="（3）关闭防火墙"><a href="#（3）关闭防火墙" class="headerlink" title="（3）关闭防火墙"></a>（3）关闭防火墙</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#关闭防火墙</span></span><br><span class="line">$ systemctl stop firewalld.service</span><br><span class="line"><span class="comment">#禁止防火墙开启自启</span></span><br><span class="line">$ systemctl <span class="built_in">disable</span> firewalld.service</span><br></pre></td></tr></table></figure><h3 id="（4）免密登录"><a href="#（4）免密登录" class="headerlink" title="（4）免密登录"></a>（4）免密登录</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#master 生成公钥私钥，四个回车即可</span></span><br><span class="line">$ ssh-keygen</span><br><span class="line"><span class="comment">#master 配置免密登录到master slave1 slave2三台主机</span></span><br><span class="line">$ ssh-copy-id master </span><br><span class="line">$ ssh-copy-id slave1 </span><br><span class="line">$ ssh-copy-id slave2</span><br></pre></td></tr></table></figure><h3 id="（5）时间同步"><a href="#（5）时间同步" class="headerlink" title="（5）时间同步"></a>（5）时间同步</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#安装 ntp</span></span><br><span class="line">$ yum install ntp -y </span><br><span class="line"><span class="comment">#设置 ntp 开机自启动</span></span><br><span class="line">$ systemctl <span class="built_in">enable</span> ntpd &amp;&amp; systemctl start ntpd</span><br><span class="line"><span class="comment">#三台主机分别运行以下命令</span></span><br><span class="line">$ ntpdate ntp4.aliyun.com</span><br></pre></td></tr></table></figure><hr><h2 id="2-JDK安装"><a href="#2-JDK安装" class="headerlink" title="2.JDK安装"></a>2.JDK安装</h2><p>###（1）下载安装包<br>本文使用的 JDK 是1.8版本<br><a href="https://www.oracle.com/java/technologies/downloads/#java8">jdk1.8安装包下载</a><br><strong>注意：下载的是后缀为 .tar.gz 的包</strong></p><h3 id="（2）在主机-master-上安装-JDK"><a href="#（2）在主机-master-上安装-JDK" class="headerlink" title="（2）在主机 master 上安装 JDK"></a>（2）在主机 master 上安装 JDK</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#编译环境软件安装目录</span></span><br><span class="line">$ <span class="built_in">mkdir</span> -p /export/server</span><br><span class="line"><span class="comment">#上传本地下载好的jdk-8u241-linux-x64.tar.gz上传到/export/server/目录下 并解压文件</span></span><br><span class="line">$ tar -zxvf jdk-8u241-linux-x64.tar.gz</span><br><span class="line"><span class="comment">#配置环境变量</span></span><br><span class="line">$ vim /etc/profile</span><br><span class="line"><span class="comment">#在文件内添加如下内容</span></span><br><span class="line"><span class="comment"># jdk 环境变量 </span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/export/server/jdk1.8.0_241 </span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin </span><br><span class="line"><span class="built_in">export</span> CLASSPATH=.:<span class="variable">$JAVA_HOME</span>/lib/dt.jar:<span class="variable">$JAVA_HOME</span>/lib/tools.ja</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#重新加载环境变量文件</span></span><br><span class="line">$ <span class="built_in">source</span> /etc/profile</span><br><span class="line"><span class="comment">#查看 java 版本号</span></span><br><span class="line">$ java -version</span><br><span class="line"><span class="comment">#出现 java version &quot;1.8.0_241&quot; 表示安装成功</span></span><br></pre></td></tr></table></figure><h3 id="（3）分发"><a href="#（3）分发" class="headerlink" title="（3）分发"></a>（3）分发</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#master 节点将 java 传输到 slave1 和 slave2</span></span><br><span class="line">$ <span class="built_in">cd</span> /export/server</span><br><span class="line">$ scp -r /export/server/jdk1.8.0_241/ root@slave1:/export/server/ </span><br><span class="line">$ scp -r /export/server/jdk1.8.0_241/ root@slave2:/export/server/</span><br><span class="line"><span class="comment">#配置 slave1 和 slave2 的 jdk 环境变量（注：和上方 master 的配置方法一样）</span></span><br><span class="line"><span class="comment">#配置完成后，在 master slave1 和slave2 三台主机创建软连接</span></span><br><span class="line">$ <span class="built_in">cd</span> /export/server </span><br><span class="line">$ <span class="built_in">ln</span> -s jdk1.8.0_241/ jdk</span><br><span class="line"><span class="comment">#重新加载环境变量文件</span></span><br><span class="line">$ <span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure><hr><h2 id="3-Hadoop安装"><a href="#3-Hadoop安装" class="headerlink" title="3.Hadoop安装"></a>3.Hadoop安装</h2><h3 id="（1）下载安装包"><a href="#（1）下载安装包" class="headerlink" title="（1）下载安装包"></a>（1）下载安装包</h3><p>本文使用的 hadoop 是3.3.0版本<br><a href="http://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-3.3.0/hadoop-3.3.0.tar.gz">hadoop3.3.0安装包下载</a><br><strong>注意：下载的是后缀为 .tar.gz的包</strong></p><h3 id="（2）在主机-master-上安装-hadoop"><a href="#（2）在主机-master-上安装-hadoop" class="headerlink" title="（2）在主机 master 上安装 hadoop"></a>（2）在主机 master 上安装 hadoop</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#上传本地下载好的 hadoop-3.3.0-Centos7-64-with-snappy.tar.gz 上传到 /export/server 并解压文件</span></span><br><span class="line">$ tar -zxvf hadoop-3.3.0-Centos7-64-with-snappy.tar.gz</span><br><span class="line"><span class="comment">#修改配置文件,进入到 hadoop 目录下</span></span><br><span class="line">$ <span class="built_in">cd</span> /export/server/hadoop-3.3.0/etc/hadoop</span><br><span class="line"></span><br><span class="line"><span class="comment">#编辑 hadoop-env.sh 文件</span></span><br><span class="line">$ vim hadoop-env.sh</span><br><span class="line"><span class="comment">#文件最后添加 </span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/export/server/jdk1.8.0_241 </span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> HDFS_NAMENODE_USER=root </span><br><span class="line"><span class="built_in">export</span> HDFS_DATANODE_USER=root </span><br><span class="line"><span class="built_in">export</span> HDFS_SECONDARYNAMENODE_USER=root </span><br><span class="line"><span class="built_in">export</span> YARN_RESOURCEMANAGER_USER=root </span><br><span class="line"><span class="built_in">export</span> YARN_NODEMANAGER_USER=root</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#修改 core-site.xml 文件  </span></span><br><span class="line">$ vim core-site.xml </span><br><span class="line"><span class="comment">#添加如下内容</span></span><br><span class="line">&lt;!-- 设置默认使用的文件系统 Hadoop支持file、HDFS、GFS、ali|Amazon云等文件系统 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">&lt;value&gt;hdfs://master:8020&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 设置Hadoop本地保存数据路径 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">&lt;value&gt;/export/data/hadoop-3.3.0&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 设置HDFS web UI用户身份 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;hadoop.http.staticuser.user&lt;/name&gt;</span><br><span class="line">&lt;value&gt;root&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 整合hive 用户代理设置 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;hadoop.proxyuser.root.hosts&lt;/name&gt;</span><br><span class="line">&lt;value&gt;*&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;hadoop.proxyuser.root.groups&lt;/name&gt;</span><br><span class="line">&lt;value&gt;*&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 文件系统垃圾桶保存时间 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;fs.trash.interval&lt;/name&gt;</span><br><span class="line">&lt;value&gt;1440&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#修改 hdfs-site.xml 文件  </span></span><br><span class="line">$ vim hdfs-site.xml </span><br><span class="line">&lt;!-- 设置SNN进程运行机器位置信息 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;</span><br><span class="line">&lt;value&gt;slave1:9868&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#修改 mapred-site.xml 文件</span></span><br><span class="line">$ vim mapred-site.xml</span><br><span class="line"><span class="comment">#添加如下内容</span></span><br><span class="line">&lt;!-- 设置MR程序默认运行模式： yarn集群模式 <span class="built_in">local</span>本地模式 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- MR程序历史服务地址 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;master:10020&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"> </span><br><span class="line">&lt;!-- MR程序历史服务器web端地址 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;master:19888&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;HADOOP_MAPRED_HOME=<span class="variable">$&#123;HADOOP_HOME&#125;</span>&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapreduce.map.env&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;HADOOP_MAPRED_HOME=<span class="variable">$&#123;HADOOP_HOME&#125;</span>&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapreduce.reduce.env&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;HADOOP_MAPRED_HOME=<span class="variable">$&#123;HADOOP_HOME&#125;</span>&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#修改 yarn-site.xml 文件</span></span><br><span class="line">$ vim yarn-site.xml</span><br><span class="line"><span class="comment">#添加如下内容</span></span><br><span class="line">&lt;!-- 设置YARN集群主角色运行机器位置 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;master&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;!-- 是否将对容器实施物理内存限制 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.nodemanager.pmem-check-enabled&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;<span class="literal">false</span>&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;!-- 是否将对容器实施虚拟内存限制。 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;<span class="literal">false</span>&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;!-- 开启日志聚集 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;<span class="literal">true</span>&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;!-- 设置yarn历史服务器地址 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.log.server.url&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;http://master:19888/jobhistory/logs&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;!-- 历史日志保存的时间 7天 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;604800&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#修改 workers 文件</span></span><br><span class="line">$ vim workers</span><br><span class="line"><span class="comment">#将 workers 里的 localhost 删除，添加如下内容</span></span><br><span class="line">master </span><br><span class="line">slave1 </span><br><span class="line">slave2</span><br></pre></td></tr></table></figure><h3 id="（3）分发-1"><a href="#（3）分发-1" class="headerlink" title="（3）分发"></a>（3）分发</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#master 节点将 hadoop 传输到 slave1 和 slave2</span></span><br><span class="line">$ <span class="built_in">cd</span> /export/server</span><br><span class="line">$ scp -r hadoop-3.3.0 root@slave1:<span class="variable">$PWD</span></span><br><span class="line">$ scp -r hadoop-3.3.0 root@slave2:<span class="variable">$PWD</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#将 hadoop 添加到环境变量</span></span><br><span class="line">vim /etc/profile</span><br><span class="line"><span class="comment">#在文件内添加如下内容</span></span><br><span class="line"><span class="comment"># hadoop 环境变量 </span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/export/server/hadoop-3.3.0</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/sbin</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#配置 slave1 和 slave2 的 hadoop 环境变量（注：和上方 master 的配置方法一样）</span></span><br><span class="line"><span class="comment">#配置完成后，在 master slave1 和slave2 三台主机创建软连接</span></span><br><span class="line">$ <span class="built_in">cd</span> /export/server </span><br><span class="line">$ <span class="built_in">ln</span> -s hadoop-3.3.0/ hadoop</span><br><span class="line"><span class="comment">#重新加载环境变量文件</span></span><br><span class="line">$ <span class="built_in">source</span> /etc/profile</span><br><span class="line"><span class="comment">#在 master 主节点进行 Hadoop 集群启动 格式化 namenode（只有首次启动需要格式化）</span></span><br><span class="line">$ hdfs namenode -format</span><br><span class="line"><span class="comment">#等待初始化完成后，使用脚本一键起动</span></span><br><span class="line">$ start-all.sh </span><br><span class="line"><span class="comment">#起动后，输入jps查看进程号</span></span><br><span class="line">$ jps</span><br><span class="line"><span class="comment">#进程查看完毕后可进入到 WEB 界面</span></span><br><span class="line"><span class="comment">#HDFS集群的界面网站是:http://master:9870/</span></span><br><span class="line"><span class="comment">#YARN集群的界面网站是:http://master:9870/</span></span><br></pre></td></tr></table></figure><hr><h2 id="4-安装zookeeper"><a href="#4-安装zookeeper" class="headerlink" title="4.安装zookeeper"></a>4.安装zookeeper</h2><h3 id="（1）下载安装包-1"><a href="#（1）下载安装包-1" class="headerlink" title="（1）下载安装包"></a>（1）下载安装包</h3><p>本文使用的 zookeeper 是3.7.0版本<br><a href="https://zookeeper.apache.org/releases.html#download">zookeeper3.7.0安装包下载</a><br><strong>注意：下载的是后缀为 .tar.gz 的包,安装包需要3.7版本网上，否者后续Kafka配置会出现问题</strong></p><h3 id="（2）在主机-master-上安装-zookeeper"><a href="#（2）在主机-master-上安装-zookeeper" class="headerlink" title="（2）在主机 master 上安装 zookeeper"></a>（2）在主机 master 上安装 zookeeper</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#上传本地下载好的 apache-zookeeper-3.7.0-bin.tar.gz 上传到 /export/server 并解压文件</span></span><br><span class="line">$ tar -zxvf apache-zookeeper-3.7.0-bin.tar.gz</span><br><span class="line"><span class="comment">#修改配置文件,进入到 /export/server 目录下</span></span><br><span class="line">$ <span class="built_in">cd</span> /export/server/</span><br><span class="line"><span class="comment">#在 /export/server 目录下创建 zookeeper 软连接</span></span><br><span class="line">$ <span class="built_in">ln</span> -s apache-zookeeper-3.7.0-bin/ zookeeper</span><br><span class="line"><span class="comment">#进入到 zookeeper 目录下</span></span><br><span class="line">$ <span class="built_in">cd</span> zookeeper</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#进入到 zookeeper 下的 conf 文件内</span></span><br><span class="line">$ <span class="built_in">cd</span> /export/server/zookeeper/conf/ </span><br><span class="line"><span class="comment">#将 zoo_sample.cfg 文件复制为新文件 zoo.cfg</span></span><br><span class="line">$ <span class="built_in">cp</span> zoo_sample.cfg zoo.cfg</span><br><span class="line"><span class="comment">#在 zoo.cfg 文件内添加如下内容</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Zookeeper的数据存放目录</span></span><br><span class="line">dataDir=/export/server/zookeeper/zkdatas</span><br><span class="line"><span class="comment"># 保留多少个快照</span></span><br><span class="line">autopurge.snapRetainCount=3</span><br><span class="line"><span class="comment"># 日志多少小时清理一次</span></span><br><span class="line">autopurge.purgeInterval=1</span><br><span class="line"><span class="comment"># 集群中服务器地址</span></span><br><span class="line">server.1=master:2888:3888 </span><br><span class="line">server.2=slave1:2888:3888 </span><br><span class="line">server.3=slave2:2888:3888</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#进入 /export/server/zookeeper/zkdatas 目录在此目录下创建 myid 文件,将 1 写入进去</span></span><br><span class="line">$ <span class="built_in">cd</span> /export/server/zookeeper/zkdata</span><br><span class="line">$ <span class="built_in">mkdir</span> myid</span><br><span class="line">$ <span class="built_in">echo</span> <span class="string">&#x27;1&#x27;</span> &gt; myid</span><br><span class="line"><span class="comment">#查看是否成功写入</span></span><br><span class="line">$ vim myid</span><br><span class="line"><span class="comment">#出现数字1即为成功</span></span><br></pre></td></tr></table></figure><h3 id="（3）分发-2"><a href="#（3）分发-2" class="headerlink" title="（3）分发"></a>（3）分发</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#master 节点将 zookeeper 传输到 slave1 和 slave2</span></span><br><span class="line">$ <span class="built_in">cd</span> /export/server</span><br><span class="line">$ scp -r /export/server/zookeeper/ slave1:<span class="variable">$PWD</span></span><br><span class="line">$ scp -r /export/server/zookeeper/ slave2:<span class="variable">$PWD</span></span><br><span class="line"><span class="comment">#推送完成后将 slave1 和 slave2 的 /export/server/zookeeper/zkdatas/ 文件夹下的 myid中的内容分别改为 2 和 3</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#在 slave1 节点上</span></span><br><span class="line">$ <span class="built_in">cd</span> /export/server/zookeeper/zkdatas/</span><br><span class="line">$ <span class="built_in">echo</span> <span class="string">&#x27;2&#x27;</span> &gt; myid</span><br><span class="line"><span class="comment">#查看是否成功写入</span></span><br><span class="line">$ vim myid</span><br><span class="line"><span class="comment">#出现数字2即为成功</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#在 slave2 节点上</span></span><br><span class="line">$ <span class="built_in">cd</span> /export/server/zookeeper/zkdatas/</span><br><span class="line">$ <span class="built_in">echo</span> <span class="string">&#x27;3&#x27;</span> &gt; myid</span><br><span class="line"><span class="comment">#查看是否成功写入</span></span><br><span class="line">$ vim myid</span><br><span class="line"><span class="comment">#出现数字3即为成功</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#将 zookeeper 添加到环境变量</span></span><br><span class="line">vim /etc/profile</span><br><span class="line"><span class="comment">#在文件内添加如下内容</span></span><br><span class="line"><span class="comment"># zookeeper 环境变量 </span></span><br><span class="line"><span class="built_in">export</span> ZOOKEEPER_HOME=/export/server/zookeeper </span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$ZOOKEEPER_HOME</span>/bin</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#配置 slave1 和 slave2 的 hadoop 环境变量（注：和上方 master 的配置方法一样）</span></span><br><span class="line"><span class="comment">#重新加载环境变量文件</span></span><br><span class="line">$ <span class="built_in">source</span> /etc/profile</span><br><span class="line"><span class="comment">#三台机器分别进入 /export/server/zookeeper/bin 目录下启动 zkServer.sh 脚本</span></span><br><span class="line">$ <span class="built_in">cd</span> /export/server/zookeeper/bin</span><br><span class="line">$ zkServer.sh start</span><br><span class="line"><span class="comment">#查看 zookeeper 的状态</span></span><br><span class="line">$ zkServer.sh status</span><br><span class="line"><span class="comment">#也可以通过jps查看zookeeper的进程</span></span><br><span class="line">$ jps</span><br></pre></td></tr></table></figure><h2 id="以上-就是Kafka基础环境的配置-接下来会带来-Kafka命令行操作"><a href="#以上-就是Kafka基础环境的配置-接下来会带来-Kafka命令行操作" class="headerlink" title="以上,就是Kafka基础环境的配置,接下来会带来 Kafka命令行操作"></a>以上,就是Kafka基础环境的配置,接下来会带来 Kafka命令行操作</h2>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;本文主要使用Hexo与Github进行个人blog的搭建&lt;br&gt;Hexo官网：&lt;a href=&quot;https://hexo.io/zh-cn/&quot;&gt;Hexo&lt;/a&gt;&lt;br&gt;Github官网：&lt;a href=&quot;https://github.com/&quot;&gt;Github&lt;/a&gt;&lt;/p&gt;</summary>
      
    
    
    
    <category term="工具" scheme="http://example.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
    <category term="hexo" scheme="http://example.com/tags/hexo/"/>
    
    <category term="主题" scheme="http://example.com/tags/%E4%B8%BB%E9%A2%98/"/>
    
    <category term="搭建" scheme="http://example.com/tags/%E6%90%AD%E5%BB%BA/"/>
    
  </entry>
  
  <entry>
    <title>Kafka命令行操作 </title>
    <link href="http://example.com/2022/08/28/Kafka%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%93%8D%E4%BD%9C/"/>
    <id>http://example.com/2022/08/28/Kafka%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%93%8D%E4%BD%9C/</id>
    <published>2022-08-28T04:32:29.726Z</published>
    <updated>2023-02-16T14:09:55.901Z</updated>
    
    <content type="html"><![CDATA[<p><strong>注意：以下操作需要完成 Kafka 基础环境配置。具体配置移步到<a href="../../15/Kafka%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE">Kafka基础环境配置</a></strong></p><h2 id="1-Kafka安装"><a href="#1-Kafka安装" class="headerlink" title="1.Kafka安装"></a>1.Kafka安装</h2><p>本文使用的 Kafka 是2.11-2.0.0版本<br><a href="https://kafka.apache.org/downloads">Kafka 3.2.0 安装包下载</a><br><strong>注意：下载要注意 Kafka 的版本，同时选择后缀为 .tar.gz的安装包</strong><br>**本文使用的安装包是 kafka_2.11-2.0.0.tgz **</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#把本地下载好的 kafka_2.11-2.0.0.tgz安装包上传到 /export/server 并解压</span></span><br><span class="line">$ <span class="built_in">cd</span> /export/server/</span><br><span class="line">$ tar -zxvf kafka_2.11-2.0.0.tgz -C /export/server/</span><br><span class="line"><span class="comment">#建立软连接</span></span><br><span class="line">$ <span class="built_in">ln</span> -s /export/server/kafka_2.11-2.0.0.tgz /export/server/kafka</span><br><span class="line"><span class="comment">#master 节点节点进入 /export/server/kafka/config 修改以下配置文件</span></span><br><span class="line">$ <span class="built_in">cd</span> /export/server/kafka/config</span><br></pre></td></tr></table></figure><h4 id="编辑文件-server-properties"><a href="#编辑文件-server-properties" class="headerlink" title="编辑文件 server.properties"></a>编辑文件 server.properties</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">$ vim server.properties</span><br><span class="line"><span class="comment">#21 行内容 broker.id=0 为依次增长的:0、1、2、3、4,集群中唯一 id 从0开始，每台不能重复</span></span><br><span class="line"><span class="comment">#（注：此处为master节点，不用修改）</span></span><br><span class="line"><span class="variable">$broker</span>.<span class="built_in">id</span>=0</span><br><span class="line"></span><br><span class="line"><span class="comment">#31 行内容 #listeners=PLAINTEXT://:9092 取消注释，内容改为</span></span><br><span class="line">$ listeners=PLAINTEXT://master:9092</span><br><span class="line"></span><br><span class="line"><span class="comment">#59 行内容 log.dirs=/tmp/kafka-logs 为默认日志文件存储的位置，改为</span></span><br><span class="line"><span class="variable">$log</span>.<span class="built_in">dirs</span>=/export/server/data/kafka-log</span><br><span class="line"></span><br><span class="line"><span class="comment">#63 行内容为 num.partitions=1 是默认分区数</span></span><br><span class="line">$ num.partitions=1</span><br><span class="line"></span><br><span class="line"><span class="comment">#121 行内容 zookeeper.connect=localhost:2181 修改为</span></span><br><span class="line"><span class="variable">$zookeeper</span>.connect=master:2181,slave1:2181,slave2:2181</span><br><span class="line"></span><br><span class="line"><span class="comment">#126 行内容 group.initial.rebalance.delay.ms=0 修改为</span></span><br><span class="line">$ group.initial.rebalance.delay.ms=3000</span><br></pre></td></tr></table></figure><h2 id="2-分发"><a href="#2-分发" class="headerlink" title="2.分发"></a>2.分发</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#master 节点分发 kafka 安装文件夹 到 slave1 和 slave2 上</span></span><br><span class="line">$ <span class="built_in">cd</span> /export/server</span><br><span class="line">$ scp -r /export/server/kafka_2.11-2.0.0.tgz/ slave1:<span class="variable">$PWD</span></span><br><span class="line">$ scp -r /export/server/kafka_2.11-2.0.0.tgz/ slave2:<span class="variable">$PWD</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#配置 kafka 环境变量，master、slave1、slave2都需要进行操作</span></span><br><span class="line">$ vim /etc/profile</span><br><span class="line"><span class="comment">#文件最后添加以下内容</span></span><br><span class="line"><span class="comment"># kafka 环境变量 </span></span><br><span class="line">$ <span class="built_in">export</span> KAFKA_HOME=/export/server/kafka </span><br><span class="line">$ <span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$KAFKA_HOME</span>/bin</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#三台机器操作完成重新加载环境变量</span></span><br><span class="line">$ <span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#在 slave1 节点上</span></span><br><span class="line">$ <span class="built_in">cd</span> /export/server</span><br><span class="line">$ <span class="built_in">ln</span> -s /export/server/kafka_2.11-2.0.0/ kafka</span><br><span class="line"><span class="comment">#进入 /export/server/kafka/config 修改以下配置文件</span></span><br><span class="line">$ <span class="built_in">cd</span> /export/server/kafka/config</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ vim server.properties</span><br><span class="line"><span class="comment">#将文件 server.properties 的第 21 行的 broker.id=0 修改为 </span></span><br><span class="line">$ broker.id=1 </span><br><span class="line"><span class="comment">#将文件 server.properties 的第 31 行的 listeners=PLAINTEXT://master:9092 修改为</span></span><br><span class="line">$ listeners=PLAINTEXT://slave1:9092</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#在 slave2 节点上</span></span><br><span class="line">$ <span class="built_in">cd</span> /export/server</span><br><span class="line">$ <span class="built_in">ln</span> -s /export/server/kafka_2.11-2.0.0/ kafka</span><br><span class="line"><span class="comment">#进入 /export/server/kafka/config 修改以下配置文件</span></span><br><span class="line">$ <span class="built_in">cd</span> /export/server/kafka/config</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ vim server.properties</span><br><span class="line"><span class="comment">#将文件 server.properties 的第 21 行的 broker.id=0 修改为 </span></span><br><span class="line">$ broker.id=2 </span><br><span class="line"><span class="comment">#将文件 server.properties 的第 31 行的 listeners=PLAINTEXT://master:9092 修改为</span></span><br><span class="line">$ listeners=PLAINTEXT://slave2:9092</span><br></pre></td></tr></table></figure><p><strong>以上操作完成回到 master 节点</strong></p><h4 id="启动-kafka"><a href="#启动-kafka" class="headerlink" title="启动 kafka"></a>启动 kafka</h4><p><strong>注意：启动 kafka 需要启动 zookeeper</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#启动 kafka,三台机器同时执行</span></span><br><span class="line">$ kafka-server-start.sh -daemon /export/server/kafka/config/server.properties</span><br><span class="line"><span class="comment">#启动完成后通过jps查看其状态</span></span><br></pre></td></tr></table></figure><h4 id="设置脚本便于启动三台机器"><a href="#设置脚本便于启动三台机器" class="headerlink" title="设置脚本便于启动三台机器"></a>设置脚本便于启动三台机器</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#进入到bin目录下</span></span><br><span class="line"><span class="variable">$cd</span> /root/bin</span><br><span class="line"><span class="comment"># 创建并编辑名为kafka-all.sh的脚本</span></span><br><span class="line">$ vim kafka-all.sh</span><br><span class="line"><span class="comment">#在文件内添加如下内容</span></span><br><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$#</span> -eq 0 ] ;</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;please input param:start stop&quot;</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$1</span> = start  ] ;<span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$&#123;1&#125;</span>ing master&quot;</span></span><br><span class="line">ssh master <span class="string">&quot;source /etc/profile;kafka-server-start.sh -daemon /export/server/kafka/config/server.properties&quot;</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> &#123;1..2&#125;</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$&#123;1&#125;</span>ing slave<span class="variable">$&#123;i&#125;</span>&quot;</span></span><br><span class="line">ssh slave<span class="variable">$&#123;i&#125;</span> <span class="string">&quot;source /etc/profile;kafka-server-start.sh -daemon /export/server/kafka/config/server.properties&quot;</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$1</span> = stop ];<span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$&#123;1&#125;</span>ping master &quot;</span></span><br><span class="line">ssh master <span class="string">&quot;source /etc/profile;kafka-server-stop.sh&quot;</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> &#123;1..2&#125;</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$&#123;1&#125;</span>ping slave<span class="variable">$&#123;i&#125;</span>&quot;</span></span><br><span class="line">ssh slave<span class="variable">$&#123;i&#125;</span> <span class="string">&quot;source /etc/profile;kafka-server-stop.sh&quot;</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure><h2 id="3-Kafka命令行操作"><a href="#3-Kafka命令行操作" class="headerlink" title="3.Kafka命令行操作"></a>3.Kafka命令行操作</h2><h4 id="（1）创建topic"><a href="#（1）创建topic" class="headerlink" title="（1）创建topic"></a>（1）创建topic</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kafka-configs.sh --create --topic tpc_1 --partitions 2 --replication-factor2 --zookeeper node1:2181</span><br></pre></td></tr></table></figure><h4 id="（2）删除topic"><a href="#（2）删除topic" class="headerlink" title="（2）删除topic"></a>（2）删除topic</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kafka-topics.sh  --delete --topic tpc_1 --zookeeper node1:2181</span><br></pre></td></tr></table></figure><h4 id="（3）查看topic"><a href="#（3）查看topic" class="headerlink" title="（3）查看topic"></a>（3）查看topic</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看当前系统中的所有topic</span></span><br><span class="line">$ kafka-topics.sh --zookeeper node1:2181-list</span><br><span class="line"><span class="comment">#查看topic详细信息</span></span><br><span class="line">$ kafka-configs.sh --create --topic tpc_1 --zookeeper node1:2181--replication-factor0:1</span><br></pre></td></tr></table></figure><h4 id="（4）增加分区数"><a href="#（4）增加分区数" class="headerlink" title="（4）增加分区数"></a>（4）增加分区数</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.sh --alter --topic tpc_1 --partitions 3 --zookeeper node1:2181</span><br></pre></td></tr></table></figure><h4 id="（5）动态配置topic参数"><a href="#（5）动态配置topic参数" class="headerlink" title="（5）动态配置topic参数"></a>（5）动态配置topic参数</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#通过管理命令，可以为已创建的topic增加，修改，删除 topic level 参数</span></span><br><span class="line"><span class="comment">#添加，修改配置参数</span></span><br><span class="line">$ kafka-configs.sh --zookeeper node1:2181 --entity-type topics --entity-name tpc_1 --alter --add-config compression.type=gzip</span><br><span class="line"><span class="comment">#删除配置参数</span></span><br><span class="line">$ kafka-configs.sh --zookeeper node1:2181 --entity-type topics --entity-name tpc_1 --alter --delete-config compression.type</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;注意：以下操作需要完成 Kafka 基础环境配置。具体配置移步到&lt;a href=&quot;../../15/Kafka%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE&quot;&gt;Kafka基础环境配置&lt;/a&gt;&lt;/s</summary>
      
    
    
    
    <category term="工具" scheme="http://example.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
    <category term="hexo" scheme="http://example.com/tags/hexo/"/>
    
    <category term="主题" scheme="http://example.com/tags/%E4%B8%BB%E9%A2%98/"/>
    
    <category term="搭建" scheme="http://example.com/tags/%E6%90%AD%E5%BB%BA/"/>
    
  </entry>
  
  <entry>
    <title>Kafka API使用方法</title>
    <link href="http://example.com/2022/08/28/Kafka%20API%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/"/>
    <id>http://example.com/2022/08/28/Kafka%20API%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/</id>
    <published>2022-08-28T04:32:29.715Z</published>
    <updated>2023-02-16T14:07:31.032Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-生产者API"><a href="#1-生产者API" class="headerlink" title="1.生产者API"></a>1.生产者API</h2><hr><h4 id="一个正常的生产逻辑需要具备以下几个步骤"><a href="#一个正常的生产逻辑需要具备以下几个步骤" class="headerlink" title="一个正常的生产逻辑需要具备以下几个步骤:"></a>一个正常的生产逻辑需要具备以下几个步骤:</h4><ul><li>配置生产者客户端参数及创建相应的生产者实例</li><li>构建待发送的消息</li><li>发送消息</li><li>关闭生产者实例</li></ul><hr><p>acks 模式：取值0,1，-1（all）；</p><ul><li>0：Producer往集群发送数据不需要等到集群的返回，不确保信息发送成功，安全性最低但是效率最高</li><li>1：Producer往集群发送数据只要Leader成功写入消息就能发送下一条，只确保Leader接收成功</li><li>-1（all）：确保Leader发送成功，所有的副本也发送成功，过程虽然缓慢但是安全性最高；</li></ul><hr><p>生产者API采用默认分区方式将消息散列的发送到各个分区当中；</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">$ Properties props = new Properties()</span><br><span class="line">配置生产者客户端参数</span><br><span class="line"></span><br><span class="line">$ props.put(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="string">&quot;node1:9092,node2:9092, node3:9092&quot;</span>)</span><br><span class="line">设置kafka集群的地址</span><br><span class="line"></span><br><span class="line"><span class="variable">$props</span>.put(“retries”, 3)</span><br><span class="line">失败重试次数，失败后会自动重试（可恢复/不可恢复）→(有可能会造成数据的乱序)</span><br><span class="line"></span><br><span class="line"><span class="variable">$props</span>.put(“batch.size”, 10)</span><br><span class="line">数据发送的批次大小，提高效率/吞吐量大会数据延迟</span><br><span class="line"></span><br><span class="line"><span class="variable">$props</span>.put(<span class="string">&quot;linger.ms&quot;</span>, 10000)</span><br><span class="line">消息在缓冲区保留的时间,超过设置的值就会被提交到服务端</span><br><span class="line"></span><br><span class="line"><span class="variable">$props</span>.put(<span class="string">&quot;max.request.size&quot;</span>,10)</span><br><span class="line">数据发送请求的最大缓存数</span><br><span class="line"></span><br><span class="line"><span class="variable">$props</span>.put(“buffer.memory”, 10240)</span><br><span class="line">整个 Producer 用到总内存的大小,如果缓冲区满了会提交数据到服务端//buffer.memory要大于batch.size,否则会报申请内存不足的错误降低阻塞的可能性</span><br><span class="line"></span><br><span class="line"><span class="variable">$props</span>.put(<span class="string">&quot;key.serializer&quot;</span>,<span class="string">&quot;org.apache.kafka.common. serialization.StringSerializer&quot;</span>)</span><br><span class="line">key-value序列化器</span><br><span class="line"></span><br><span class="line"><span class="variable">$props</span>.put(“value.serializer”, “org.apache.kafka.common. serialization.StringSerializer”)</span><br><span class="line">字符串最好</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="Kafka-生产者客户端-KatkaProducer-中的三个必要参数bootstrap-servers-、key-serializer-、value-serializer；"><a href="#Kafka-生产者客户端-KatkaProducer-中的三个必要参数bootstrap-servers-、key-serializer-、value-serializer；" class="headerlink" title="Kafka 生产者客户端 KatkaProducer 中的三个必要参数bootstrap.servers 、key.serializer 、value.serializer；"></a>Kafka 生产者客户端 KatkaProducer 中的三个必要参数bootstrap.servers 、key.serializer 、value.serializer；</h4><hr><p>生产者api参数发送方式（发后即忘）:</p><ul><li>发后即忘,它只管往 Kafka 发送,并不关心消息是否正确到达。</li><li>在大多数情况下,这种发送方式没有问题; </li><li>不过在某些时候(比如发生不可重试异常时)会造成消息的丢失;</li><li>这种发送方式的性能最高,可靠性最差。</li></ul><hr><p>生产者api参数发送方式（同步发送）:</p><ul><li>producer.send(rcd).get( ); &#x2F;&#x2F;一旦调用get方法，就会阻塞</li><li>Future  future &#x3D; Callable.run( )&#x2F;&#x2F;有返回值，future.get（）</li><li>runnable.run（）&#x2F;&#x2F;无返回值</li></ul><hr><p>生产者api参数发送方式（异步发送）；</p><ul><li>回调函数会在producer收到 ack 时调用,为异步调用,</li><li>该方法有两个参数,分别是RecordMetadata和Exception,如果Exception为null,说明消息发送成功,如果 Exception不为null,说明消息发送失败;</li><li>注意：消息发送失败会自动重试,不需要我们在回调函数中手动重试。</li></ul><h3 id="生产者原理"><a href="#生产者原理" class="headerlink" title="生产者原理:"></a>生产者原理:</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">（1）一个生产者客户端由两个线程协调运行,这两个线程分别为主线程和 Sender 线程；</span><br><span class="line">（2）在主线程中由kafkaProducer创建消息,然后通过可能的拦截器、序列化器和分区器的作用之后缓存到消息累加器(RecordAccumulator, 也称为消息收集器)中；</span><br><span class="line">（3）Sender线程负责从RecordAccumulator 获取消息并将其发送到Kafka中；</span><br><span class="line">（4）RecordAccumulator 主要用来缓存消息以便 Sender 线程可以批量发送, 进而减少网络传输的资源消耗以提升性能；</span><br><span class="line">（5）RecordAccumulator 缓存的大小可以通过生产者客户端参数 buffer.memory 配置, 默认值为 33554432B ,即 32M；</span><br><span class="line">（6）主线程中发送过来的消息都会被迫加到 RecordAccumulator 的某个双端队列( Deque )中, RecordAccumulator 内部为每个分区都维护了一个双端队列,即 Deque&lt;ProducerBatch&gt;。消息写入缓存时,追加到双端队列的尾部；</span><br><span class="line">（7）Sender 读取消息时,从双端队列的头部读取；</span><br><span class="line">（8）ProducerBatch是指一个消息批次; 与此同时,会将较小的 ProducerBatch凑成一个较大ProducerBatch ,也可以减少网络请求的次数以提升整体的吞吐量；</span><br><span class="line">（9）ProducerBatch大小和batch.size参数也有着密切的关系；</span><br><span class="line">（10）当一条消息(ProducerRecord ) 流入RecordAccumulator 时,会先寻找与消息分区所对应的双端队列(如果没有则新建),再从这个双端队列的尾部获取一个ProducerBatch (如果没有则新建),查看ProducerBatch 中是否还可以写入这个ProducerRecord,如果可以写入,如果不可以则需要创建一个新的 Producer Batch；</span><br><span class="line">（11）在新建ProducerBatch 时评估这条消息的大小是否超过batch.size 参数大小, 如果不超过, 那么就以batch.size参数的大小来创建ProducerBatch；</span><br><span class="line">（12）Sender 从 RecordAccumulator 获取缓存的消息之后,会进一步将&lt;分区,Deque&lt;Producer Batch&gt;&gt;的形式转变成&lt;Node,List&lt; ProducerBatch&gt;的形式,其中 Node 表示 Kafka 集群 broker 节点；</span><br><span class="line">（13）对于网络连接来说,生产者客户端是与具体 broker 节点建立的连接,也就是向具体的 broker 节点发送消息,而并不关心消息属于哪一个分区；</span><br><span class="line">（14）而对于 KafkaProducer 的应用逻辑而言,我们只关注向哪个分区中发送哪些消息,所以在这里需要做一个应用逻辑层面到网络 I/O 层面的转换；</span><br><span class="line">（15）在转换成&lt;Node, List&lt;ProducerBatch&gt;&gt;的形式之后, Sender 会进一步封装成&lt;Node,Request&gt; 的形式, 这样就可以将 Request 请求发往各个 Node 了,这里的 Request 是 Kafka 各种协议请求；</span><br><span class="line">（16）请求在从sender 线程发往 Kafka 之前还会保存到 InFlightRequests中,InFlightRequests 保存对象的具体形式为 Map&lt;Nodeld, Deque&lt;request&gt;&gt;,它的主要作用是缓存了已经发出去但还没有收到服务端响应的请求(Nodeld 是一个 String 类型,表示节点的 <span class="built_in">id</span> 编号)。</span><br></pre></td></tr></table></figure><h3 id="重要的生产者参数"><a href="#重要的生产者参数" class="headerlink" title="重要的生产者参数"></a>重要的生产者参数</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">（1）max.request.size：这个参数用来限制生产者客户端能发送的消息的最大值,默认值为 1048576B ,即 lMB 一般情况下,这个默认值就可以满足大多数的应用场景了。</span><br><span class="line">（2）compression.type：用来指定消息的压缩方式,默认值为“none <span class="string">&quot;,即默认情况下,消息不会被压缩还可以配置为 &quot;</span>gzip<span class="string">&quot;,&quot;</span>snappy<span class="string">&quot; 和 &quot;</span>lz4<span class="string">&quot;，服务端也有压缩参数，先解压，再压缩对消息进行压缩可以极大地减少网络传输、降低网络 I/O,从而提高整体的性能。</span></span><br><span class="line"><span class="string">（3）retries 和 retry.backoff.ms：retries 参数用来配置生产者重试的次数,默认值为 0,即在发生异常的时候不进行任何重试动作。重试还和另一个参数 retry.backoff.ms 有关,这个参数的默认值为 100,它用来设定两次重试之间的时间间隔,避免无效的频繁重试。</span></span><br><span class="line"><span class="string">（4）batch.size：每个 Batch 要存放 batch.size 大小的数据后,才可以发送出去。比如说 batch.size 默认值是 16KB,那么里面凑够 16KB 的数据才会发送。</span></span><br><span class="line"><span class="string">（5）linger.ms：用来指定生产者发送 ProducerBatch 之前等待更多消息( ProducerRecord )加入ProducerBatch 时间,默认值为 0。</span></span><br><span class="line"><span class="string">（6）enable.idempotence：是否开启幂等性功能,详见后续原理加强。</span></span><br><span class="line"><span class="string">（7）partitioner.classe：用来指定分区器,默认:org.apache.kafka. internals.DefaultPartitioner --》用hashcode分。</span></span><br></pre></td></tr></table></figure><h2 id="2-消费者API"><a href="#2-消费者API" class="headerlink" title="2.消费者API"></a>2.消费者API</h2><hr><p>一个正常的消费逻辑需要具备以下几个步骤：</p><ul><li>配置消费者客户端参数</li><li>创建相应的消费者实例</li><li>订阅主题</li><li>拉取消息并消费</li><li>提交消费位移offest</li><li>关闭消费者实例</li></ul><h3 id="subscribe重载方法："><a href="#subscribe重载方法：" class="headerlink" title="subscribe重载方法："></a>subscribe重载方法：</h3><ul><li>前面两种通过集合的方式订阅一到多个topic Public 、void、subscribe（collection<sting>、topics、ConsumerRebalanceListenerlistener） Public、void、subscribe(collection<Sting>topics)</li><li>后两种主要是采用正则的方式订阅一到多个topics</li><li>public voidSubscribe（Pattern pattern，ConsumerRebalancelistener listener）Publicviod void subscribe(Patternopattern)</li><li>正则方式订阅主题(只要是tpc数字的形式，三位数字以内如果消费者采用的是正则表达式的方式(subscribe(Pattern))订阅。在之后的过程中，如果有人又创建了新的主题，并且主题名字与正表达式相匹配那么这个消费者就可以消费到新添加的主题中的消息。如果应用程序需要消费多个主题，并可以处理不同的类型，那么这种订阅方式就很有效。利用正则表达式订阅主题，可实现动态订阅；</li></ul><h3 id="assign订阅主题"><a href="#assign订阅主题" class="headerlink" title="assign订阅主题"></a>assign订阅主题</h3><p>消费者不仅可以通过KafkaConsumersubscribe()方法订阅主题，还可直接订阅某些主题的指定分区:在KafkaConsumer中提供了assign方法来实现这些功能，此方法的具体定义如下:public void assign(Collection<TopicPartition>partitions);这个方法只接受参数partitions用来指定需要订阅的分区集合示例如下:consumer.assign(Arrays.asList(new TopicPartition (“tpc_1”,0),new TopicPartition(“tpc 2,1)));</p><h3 id="subscribe与assign的区别"><a href="#subscribe与assign的区别" class="headerlink" title="subscribe与assign的区别"></a>subscribe与assign的区别</h3><ul><li><p>通过subscribe0)方法订阅主题具有消费者自动再均衡功能:在多个消费者的情况下可以根据分区分配策略来自动分配各个消费者与分区的关系。当消费组的消费者增加或减少时，分区分配关系会自动调整以实现消费负载均衡及故障自动转移。</p></li><li><p>assign方法订阅分区时，是不具备消费者自动均衡的功能的;其实这一点从assign0方法参数可以看出端倪，两种类型subscribe都有 ConsumerRebalanceListener类型参数的方法。而assign()方法却没有。</p><h3 id="取消订阅"><a href="#取消订阅" class="headerlink" title="取消订阅"></a>取消订阅</h3></li><li><p>可以使用KafkaConsumer中的unsubscribe)方法采取消主题的订阅.这个方法既可以取消通过subscribe(Collection)方式实现的订阅;</p></li><li><p>也可以取消通过subscribe(Pattem)方式实现的订阅，还可以取消通过assign(Collection)方式实现的订阅。</p></li><li><p>如果将subscribe(Collection)或assign(Collection)集合参数设置为空集合，作用与unsubscribe0)方法相同。如下示例中三行代码的效果相同: consumer.unsubscribe0;consumer.subscribe(new ArrayList<String>O)consumer.assign(new ArrayList<TopicPartition>O)；</p></li></ul><h2 id="3-Topic管理API"><a href="#3-Topic管理API" class="headerlink" title="3.Topic管理API"></a>3.Topic管理API</h2><p>一般情况下，我们习惯用kafka-topic.sh来进行管理主题，如果需要将管理类的功能集成用到公司内部系统中，就需要用到以API进行实现。这种调用API方式实现管理主要利用KafkaAdminClient工具类。</p><h4 id="KafkaAdminClient不仅可以用来管理broker，配置和ACI（Access-Control-List，管理主题）它提供了以下方法："><a href="#KafkaAdminClient不仅可以用来管理broker，配置和ACI（Access-Control-List，管理主题）它提供了以下方法：" class="headerlink" title="KafkaAdminClient不仅可以用来管理broker，配置和ACI（Access Control List，管理主题）它提供了以下方法："></a>KafkaAdminClient不仅可以用来管理broker，配置和ACI（Access Control List，管理主题）它提供了以下方法：</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">创建主题：CreateTopics（Collecnoo&lt;New Topic&gt;）new topics)</span><br><span class="line">删除主题：DeleteTopicsResult delete Topres(Collecnoo&lt;String&gt;topics)</span><br><span class="line">列出所有可用主题：ListTopicsResult listTopics()</span><br><span class="line">查看主题的信息：DescribeTopicsRrsult(describeTopics(Collection&lt;String&gt;topicNames)</span><br><span class="line">查询配置信息：DescribeConfigsResult describeConfigs(Collection&lt;ConfigResource&gt;resources)</span><br><span class="line">修改配置信息：AlterConfigsResultalterConfigs(Map&lt;ConfigResource Config&gt;configs)</span><br><span class="line">增加分区：CreatePartionsResult createPartition(Map&lt;String.New[artitions&gt;new Partitions)</span><br><span class="line">构建一个KafkaAdminClient AdminClient adminClient=KafkaAdminClient.create(props)；</span><br></pre></td></tr></table></figure><h4 id="列出主题"><a href="#列出主题" class="headerlink" title="列出主题"></a>列出主题</h4><p>ListTopicsResult listTopicsResult&#x3D;adminClient.listTopics();<br>Set<String>topic&#x3D;listTopicsResult.names().get();<br>System.out.rintln(topics);</p><h4 id="查看主题信息"><a href="#查看主题信息" class="headerlink" title="查看主题信息"></a>查看主题信息</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">DescribeTopicsResult describeTopicsResult=adminClient.describeTopics(Arrays.asList(“tpc_4”,”tpc_3”));</span><br><span class="line">Map&lt;String, TopicDescription&gt;res=describeTopicsResult.all().get();</span><br><span class="line">Set&lt;String&gt;ksets=res.keySet();</span><br><span class="line"><span class="keyword">for</span>(String k : ksets)&#123;</span><br><span class="line">     System.out.[rintln(res.get(k));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="创建主题"><a href="#创建主题" class="headerlink" title="创建主题"></a>创建主题</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">//参数配置</span><br><span class="line">Properties props = new Properties();</span><br><span class="line">Props.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG,”node1:9092,node2:9092,node:9092);</span><br><span class="line">Props.put(AdminClientConfig.REQUEST_TIMEOUT_MS_CONFIG,3000);</span><br><span class="line">//创建admin client对象</span><br><span class="line">AdminClient adminClient=KafkaAdminClient.create(props）；</span><br><span class="line">//由服务端controller自行分配分区及副本所生broker</span><br><span class="line">NewTopic tpc_3=new NewTopic(“tpc_3”,2.(shot)1);</span><br><span class="line">//手动制定分区及副本的broker分配</span><br><span class="line">HashMap&lt;IInteger,List&lt;Integer&gt;&gt;replicaAssignments=new HashMap&lt;&gt;();</span><br><span class="line">//分区0，分配到broker（），broker1</span><br><span class="line">replicaAssignments.put(0,Arrays,asList(0,1));</span><br><span class="line">//分区1，分配到broker（），broker2</span><br><span class="line">replicaSssignments.put(0,Arrays.asList(0,1));</span><br><span class="line">NewTopic tpc_4=new NewTopic(“tpc_4”,re[licaAssignments);</span><br><span class="line">AdminClient adminClient=KafkaAdminClient.create(props);</span><br><span class="line">//由服务端controller 自行分配分区及副本所在broker</span><br><span class="line">N额外Topictpc_3=newNewTopic(“tpc3”,2,(shot)1);</span><br><span class="line">//手动指定分区及副本的broker分配</span><br><span class="line">HashMap&lt;Integer,List&lt;Integer&gt;&gt;replicaAssignments=new HashMap&lt;&gt;();</span><br><span class="line">//分区0，分配到broker（），broker1</span><br><span class="line">replicaAssignments.put(0,Arrays.asList(0,1));</span><br><span class="line">//分区1，分配到broker（）broker2</span><br><span class="line">replicaAssignments.put(0,Arrays.asList(0,1))</span><br><span class="line">NewTopic tpc_4=new NewTopic(“tpc_4”,replicaAssignments);</span><br><span class="line">CreateTo[icsResult result=adminClient.createTopics(Arrays.asList(tpc_3.tpc4));</span><br><span class="line">//从future中等待服务端返回</span><br><span class="line">try&#123;</span><br><span class="line">   result.all().get();</span><br><span class="line">&#125;catch(Exception e)&#123;</span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line">adminClient.close();</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-生产者API&quot;&gt;&lt;a href=&quot;#1-生产者API&quot; class=&quot;headerlink&quot; title=&quot;1.生产者API&quot;&gt;&lt;/a&gt;1.生产者API&lt;/h2&gt;&lt;hr&gt;
&lt;h4 id=&quot;一个正常的生产逻辑需要具备以下几个步骤&quot;&gt;&lt;a href=&quot;#一个正常的</summary>
      
    
    
    
    <category term="工具" scheme="http://example.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
    <category term="hexo" scheme="http://example.com/tags/hexo/"/>
    
    <category term="主题" scheme="http://example.com/tags/%E4%B8%BB%E9%A2%98/"/>
    
    <category term="搭建" scheme="http://example.com/tags/%E6%90%AD%E5%BB%BA/"/>
    
  </entry>
  
  <entry>
    <title>Spark HA &amp; Yarn配置</title>
    <link href="http://example.com/2022/05/22/Spark%20HA%20&amp;%20Yarn%E9%85%8D%E7%BD%AE/"/>
    <id>http://example.com/2022/05/22/Spark%20HA%20&amp;%20Yarn%E9%85%8D%E7%BD%AE/</id>
    <published>2022-05-22T03:06:37.000Z</published>
    <updated>2022-05-24T09:35:11.714Z</updated>
    
    <content type="html"><![CDATA[<h3 id="一、Spark-Standalone-HA模式"><a href="#一、Spark-Standalone-HA模式" class="headerlink" title="一、Spark-Standalone-HA模式"></a>一、Spark-Standalone-HA模式</h3><p>Spark Standalone集群是Master-Slaves架构的集群模式,和大部分的Master-Slaves结构集群一样,存在着Master 单点故障(SPOF)的问题。简单理解为，spark-Standalone 模式下为 master 节点控制其他节点，当 master 节点出现故障时，集群就不可用了。 spark-Standalone-HA 模式下master 节点不固定，当一个宕机时，立即换另一台为 master 保障不出现故障。</p><p>1.此处因为先前配置时的 zookeeper 版本和 spark 版本不太兼容，导致此模式有故障，需要重新下载配置新的版本的 zookeeper<br>2.配置之前需要删除三台主机的 旧版 zookeeper 以及 对应的软连接<br>3.在master节点上重新进行前面配置的 zookeeper 操作</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">上传apache-zookeeper-3.7.0-bin.tar.gz 到/export/server/目录下 并解压文件 </span><br><span class="line">在 /export/server 目录下创建软连接 </span><br><span class="line">进入 /export/server/zookeeper/conf/ 将 zoo_sample.cfg 文件复制为新文件 zoo.cfg </span><br><span class="line">接上步给 zoo.cfg 添加内容 </span><br><span class="line">进入 /export/server/zookeeper/zkdatas 目录在此目录下创建 myid 文件，将 1 写入进 去</span><br><span class="line">将 master 节点中 /export/server/zookeeper-3.7.0 路径下内容推送给slave1 和 slave2 </span><br><span class="line">推送成功后，分别在 slave1 和 slave2 上创建软连接 </span><br><span class="line">接上步推送完成后将 slave1 和 slave2 的 /export/server/zookeeper/zkdatas/文件夹 下的 myid 中的内容分别改为 2 和 3 </span><br><span class="line">配置环境变量： </span><br><span class="line">因先前配置 zookeeper 时候创建过软连接且以 ’zookeeper‘ 为路径，所以不用配置环境变量，此 处也是创建软连接的方便之处.</span><br></pre></td></tr></table></figure><p>4.进入 &#x2F;export&#x2F;server&#x2F;spark&#x2F;conf 文件夹 修改 spark-env.sh 文件内容</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /export/server/spark/conf </span><br><span class="line"></span><br><span class="line">vim spark-env.sh</span><br></pre></td></tr></table></figure><p>5.为 83 行内容加上注释，此部分原为指定 某台主机 做 master ，加上注释后即为 任何主机都可以做 master</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">结果显示： </span><br><span class="line">...... </span><br><span class="line">82 <span class="comment"># 告知Spark的master运行在哪个机器上 </span></span><br><span class="line">83 <span class="comment"># export SPARK_MASTER_HOST=master </span></span><br><span class="line">.........</span><br></pre></td></tr></table></figure><p> 文末添加内容</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SPARK_DAEMON_JAVA_OPTS=<span class="string">&quot;-Dspark.deploy.recoveryMode=ZOOKEEPER -  # spark.deploy.recoveryMode 指定HA模式 基于Zookeeper实现</span></span><br><span class="line"><span class="string">Dspark.deploy.zookeeper.url=master:2181,slave1:2181,slave2:2181 -  # 指定Zookeeper的连接地址</span></span><br><span class="line"><span class="string">Dspark.deploy.zookeeper.dir=/spark-ha&quot;</span>  <span class="comment"># 指定在Zookeeper中注册临时节点的路径</span></span><br></pre></td></tr></table></figure><p>6.分发 spark-env.sh 到 salve1 和 slave2 上</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scp spark-env.sh slave1:/export/server/spark/conf/ </span><br><span class="line"></span><br><span class="line">scp spark-env.sh slave2:/export/server/spark/conf/</span><br></pre></td></tr></table></figure><p>7.启动之前确保 Zookeeper 和 HDFS 均已经启动<br>  启动集群:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在 master 上 启动一个master 和全部worker </span></span><br><span class="line">/export/server/spark/sbin/start-all.sh </span><br><span class="line"></span><br><span class="line"><span class="comment"># 注意, 下面命令在 slave1 上执行 启动 slave1 上的 master 做备用 master </span></span><br><span class="line">/export/server/spark/sbin/start-master.sh</span><br><span class="line"></span><br><span class="line">jps  <span class="comment">#查看是否启动</span></span><br></pre></td></tr></table></figure><p>8.访问 WebUI 界面</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">http://master:8081/</span><br><span class="line"></span><br><span class="line">http://slave1:8082/</span><br></pre></td></tr></table></figure><p>9.此时 kill 掉 master 上的 master 假设 master 主机宕机掉</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># master主机 master 的进程号 </span></span><br><span class="line"><span class="built_in">kill</span> -9 41589</span><br></pre></td></tr></table></figure><p>10.访问 slave1 的 WebUI</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://slave1:8082/</span><br></pre></td></tr></table></figure><p>11.进行主备切换的测试  提交一个 spark 任务到当前 活跃的 master上 :</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">/export/server/spark/bin/spark-submit --master spark://master:7077 </span><br><span class="line"></span><br><span class="line">/export/server/spark/examples/src/main/python/pi.py 1000</span><br></pre></td></tr></table></figure><p>12.复制标签 kill 掉 master 的 进程号  再次访问 master 的 WebUI</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">http://master:8081/</span><br><span class="line"></span><br><span class="line">网页访问不了！</span><br></pre></td></tr></table></figure><p>13.再次访问 slave1 的 WebUI</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://slave1:8082/</span><br></pre></td></tr></table></figure><p>14.可以看到当前活跃的 master 提示信息</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">/export/server/spark/bin/spark-submit --master</span><br><span class="line"></span><br><span class="line">同样可以输出结果</span><br></pre></td></tr></table></figure><p>  当新的 master 接收集群后, 程序继续运行, 正常得到结果.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">结论 HA模式下, 主备切换 不会影响到正在运行的程序.</span><br><span class="line">最大的影响是 会让它中断大约30秒左右</span><br></pre></td></tr></table></figure><h3 id="二、Spark-On-YARN模式"><a href="#二、Spark-On-YARN模式" class="headerlink" title="二、Spark On YARN模式"></a>二、Spark On YARN模式</h3><p>在已有YARN集群的前提下在单独准备Spark StandAlone集群,对资源的利用就不高.Spark On YARN, 无需部署Spark集群, 只要找一台服务器, 充当Spark的客户端</p><p>1.保证 HADOOP_CONF_和 DIR_YARN_CONF_DIR 已经配置在 spark-env.sh 和环境变量中 （注: 前面配置spark-Standlone 时已经配置过此项了）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">spark-env.sh 文件部分显示：</span><br><span class="line">···</span><br><span class="line"> 77 <span class="comment">## HADOOP软件配置文件目录，读取HDFS上文件和运行YARN集群 </span></span><br><span class="line"> 78 HADOOP_CONF_DIR=/export/server/hadoop/etc/hadoop </span><br><span class="line"> 79 YARN_CONF_DIR=/export/server/hadoop/etc/hadoop</span><br><span class="line">····</span><br></pre></td></tr></table></figure><p>2.链接到 YARN 中（注: 交互式环境 pyspark 和 spark-shell 无法运行 cluster模式）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">bin/pyspark --master yarn --deploy-mode client|cluster</span><br><span class="line"><span class="comment"># --deploy-mode 选项是指定部署模式, 默认是 客户端模式 </span></span><br><span class="line"><span class="comment"># client就是客户端模式 </span></span><br><span class="line"><span class="comment"># cluster就是集群模式 </span></span><br><span class="line"><span class="comment"># --deploy-mode 仅可以用在YARN模式下</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-shell --master yarn --deploy-mode client|cluster</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-submit --master yarn --deploy-mode client|cluster /xxx/xxx/xxx.py 参数</span><br></pre></td></tr></table></figure><p>3.park-submit 和 spark-shell 和 pyspark的相关参数</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">- bin/pyspark: pyspark解释器spark环境 - bin/spark-shell: scala解释器spark环境 </span><br><span class="line">- bin/spark-submit: 提交jar包或Python文件执行的工具 </span><br><span class="line">- bin/spark-sql: sparksql客户端工具</span><br><span class="line"></span><br><span class="line">这4个客户端工具的参数基本通用.以spark-submit 为例: </span><br><span class="line">bin/spark-submit --master spark://master:7077 xxx.py</span><br></pre></td></tr></table></figure><p>4.启动 YARN 的历史服务器</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /export/server/hadoop-3.3.0/sbin </span><br><span class="line"></span><br><span class="line">./mr-jobhistory-daemon.sh start historyserver</span><br></pre></td></tr></table></figure><p>5.访问WebUI界面</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://master:19888/</span><br></pre></td></tr></table></figure><p> client 模式测试</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SPARK_HOME=/export/server/spark <span class="variable">$&#123;SPARK_HOME&#125;</span>/bin/spark-submit --master yarn --deploy-mode client --</span><br><span class="line">driver-memory 512m --executor-memory 512m --num-executors 1 --total- </span><br><span class="line">executor-cores 2 <span class="variable">$&#123;SPARK_HOME&#125;</span>/examples/src/main/python/pi.py 3</span><br></pre></td></tr></table></figure><p> cluster 模式测试</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SPARK_HOME=/export/server/spark <span class="variable">$&#123;SPARK_HOME&#125;</span>/bin/spark-submit --master yarn --deploy-mode cluster --driver- </span><br><span class="line">memory 512m --executor-memory 512m --num-executors 1 --total-executor-cores </span><br><span class="line">2 --conf <span class="string">&quot;spark.pyspark.driver.python=/root/anaconda3/bin/python3&quot;</span> --conf </span><br><span class="line"><span class="string">&quot;spark.pyspark.python=/root/anaconda3/bin/python3&quot;</span> </span><br><span class="line"><span class="variable">$&#123;SPARK_HOME&#125;</span>/examples/src/main/python/pi.py 3</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;一、Spark-Standalone-HA模式&quot;&gt;&lt;a href=&quot;#一、Spark-Standalone-HA模式&quot; class=&quot;headerlink&quot; title=&quot;一、Spark-Standalone-HA模式&quot;&gt;&lt;/a&gt;一、Spark-Standalon</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Spark-local&amp; stand-alone配置</title>
    <link href="http://example.com/2022/05/22/Spark%20local&amp;%20stand-alone%E9%85%8D%E7%BD%AE/"/>
    <id>http://example.com/2022/05/22/Spark%20local&amp;%20stand-alone%E9%85%8D%E7%BD%AE/</id>
    <published>2022-05-22T03:06:37.000Z</published>
    <updated>2022-05-23T09:48:11.092Z</updated>
    
    <content type="html"><![CDATA[<h3 id="一、Spark-local模式"><a href="#一、Spark-local模式" class="headerlink" title="一、Spark-local模式"></a>一、Spark-local模式</h3><p>本地模式(单机) 本地模式就是以一个独立的进程,通过其内部的多个线程来模拟整个Spark运行时环境</p><p>  Anaconda On Linux 安装 (单台服务器脚本安装)</p><p>  1.安装上传安装包: 资料中提供的Anaconda3-2021.05-Linux-x86_64.sh文件到Linux服务器上安装位置在 &#x2F;export&#x2F;server:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /export/server</span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行文件</span></span><br><span class="line">sh Anaconda3-2021.05-Linux-x86_64.sh</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">过程显示：</span><br><span class="line">···</span><br><span class="line"><span class="comment">#出现内容选 yes</span></span><br><span class="line">Please answer <span class="string">&#x27;yes&#x27;</span> or <span class="string">&#x27;no&#x27;</span>:<span class="string">&#x27; </span></span><br><span class="line"><span class="string">&gt;&gt;&gt; yes</span></span><br><span class="line"><span class="string">···</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 出现添加路径：/export/server/anaconda3</span></span><br><span class="line"><span class="string">···</span></span><br><span class="line"><span class="string">[/root/anaconda3] &gt;&gt;&gt; /export/server/anaconda3 </span></span><br><span class="line"><span class="string">PREFIX=/export/server/anaconda3</span></span><br><span class="line"><span class="string">···</span></span><br></pre></td></tr></table></figure><p>2.安装完成后, 退出终端， 重新进来:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">exit</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">结果显示： </span><br><span class="line"><span class="comment">#看到这个Base开头表明安装好了.base是默认的虚拟环境. </span></span><br><span class="line">Last login: Tue Mar 15 15:28:59 2022 from 192.168.88.1 </span><br><span class="line">(base) [root@master ~]<span class="comment">#</span></span><br></pre></td></tr></table></figure><p>3.在虚拟环境内安装包 （有WARNING不用管）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install pyhive pyspark jieba -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></table></figure><p>4.spark 安装<br>  将文件上传到 &#x2F;export&#x2F;server 里面 ，解压</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /export/server</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解压 </span></span><br><span class="line">tar -zxvf spark-3.2.0-bin-hadoop3.2.tgz -C /export/server/</span><br></pre></td></tr></table></figure><p>  建立软连接</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">ln</span> -s /export/server/spark-3.2.0-bin-hadoop3.2 /export/server/spark</span><br></pre></td></tr></table></figure><p>  添加环境变量<br>  SPARK_HOME: 表示Spark安装路径在哪里<br>  PYSPARK_PYTHON: 表示Spark想运行Python程序, 那么去哪里找python执行器<br>  JAVA_HOME: 告知Spark Java在哪里<br>  HADOOP_CONF_DIR: 告知Spark Hadoop的配置文件在哪里<br>  HADOOP_HOME: 告知Spark Hadoop安装在哪里</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/profile</span><br><span class="line"></span><br><span class="line">内容：</span><br><span class="line">···</span><br><span class="line">注：此部分之前配置过，此部分不需要在配置</span><br><span class="line"><span class="comment">#JAVA_HOME </span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/export/server/jdk1.8.0_241 </span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin </span><br><span class="line"><span class="built_in">export</span> CLASSPATH=.:<span class="variable">$JAVA_HOME</span>/lib/dt.jar:<span class="variable">$JAVA_HOME</span>/lib/tools.jar</span><br><span class="line"></span><br><span class="line"><span class="comment">#HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/export/server/hadoop-3.3.0 </span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/sbin</span><br><span class="line"></span><br><span class="line"><span class="comment">#ZOOKEEPER_HOME</span></span><br><span class="line"><span class="built_in">export</span> ZOOKEEPER_HOME=/export/server/zookeeper </span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$ZOOKEEPER_HOME</span>/bin</span><br><span class="line">·····</span><br><span class="line"><span class="comment">#将以下部分添加进去</span></span><br><span class="line"><span class="comment">#SPARK_HOME </span></span><br><span class="line"><span class="built_in">export</span> SPARK_HOME=/export/server/spark</span><br><span class="line"></span><br><span class="line"><span class="comment">#HADOOP_CONF_DIR export </span></span><br><span class="line">HADOOP_CONF_DIR=<span class="variable">$HADOOP_HOME</span>/etc/hadoop</span><br><span class="line"></span><br><span class="line"><span class="comment">#PYSPARK_PYTHON </span></span><br><span class="line"><span class="built_in">export</span> PYSPARK_PYTHON=/export/server/anaconda3/envs/pyspark/bin/python</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">vim .bashrc</span><br><span class="line"></span><br><span class="line">内容添加进去：</span><br><span class="line"><span class="comment">#JAVA_HOME </span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/export/server/jdk1.8.0_241</span><br><span class="line"><span class="comment">#PYSPARK_PYTHON </span></span><br><span class="line"><span class="built_in">export</span> PYSPARK_PYTHON=/export/server/anaconda3/envs/pyspark/bin/python</span><br></pre></td></tr></table></figure><p>5.重新加载环境变量文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> /etc/profile </span><br><span class="line"><span class="built_in">source</span> ~/.bashrc\</span><br></pre></td></tr></table></figure><p> 进入 &#x2F;export&#x2F;server&#x2F;anaconda3&#x2F;envs&#x2F;pyspark&#x2F;bin&#x2F; 文件夹</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /export/server/anaconda3/envs/pyspark/bin/</span><br></pre></td></tr></table></figure><p> 开启</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./pyspark</span><br></pre></td></tr></table></figure><p>6.查看WebUI界面</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#浏览器访问：</span></span><br><span class="line">http://master:4040/</span><br></pre></td></tr></table></figure><p> 退出</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda deactivate</span><br></pre></td></tr></table></figure><h3 id="二、Spark-Standalone模式"><a href="#二、Spark-Standalone模式" class="headerlink" title="二、Spark-Standalone模式"></a>二、Spark-Standalone模式</h3><p>Standalone模式(集群) Spark中的各个角色以独立进程的形式存在,并组成Spark集群环境<br>Anaconda On Linux 安装 (单台服务器脚本安装 注：在 slave1 和 slave2 上部署)<br>1.安装上传安装包: 资料中提供的Anaconda3-2021.05-Linux-x86_64.sh文件到Linux服务器上安装位置在 &#x2F;export&#x2F;server:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /export/server</span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行文件 </span></span><br><span class="line">sh Anaconda3-2021.05-Linux-x86_64.sh</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">过程显示： </span><br><span class="line">... </span><br><span class="line"><span class="comment"># 出现内容选 yes </span></span><br><span class="line">Please answer <span class="string">&#x27;yes&#x27;</span> or <span class="string">&#x27;no&#x27;</span>:<span class="string">&#x27; </span></span><br><span class="line"><span class="string">&gt;&gt;&gt; yes</span></span><br><span class="line"><span class="string">···</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 出现添加路径：/export/server/anaconda3</span></span><br><span class="line"><span class="string">···</span></span><br><span class="line"><span class="string">[/root/anaconda3] &gt;&gt;&gt; /export/server/anaconda3 </span></span><br><span class="line"><span class="string">PREFIX=/export/server/anaconda3</span></span><br><span class="line"><span class="string">···</span></span><br></pre></td></tr></table></figure><p>2.安装完成后, 退出终端， 重新进来:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">exit</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">结果显示： </span><br><span class="line"><span class="comment"># 看到这个Base开头表明安装好了.base是默认的虚拟环境. </span></span><br><span class="line">Last login: Tue Mar 15 15:28:59 2022 from 192.168.88.1 </span><br><span class="line">(base) [root@master ~]<span class="comment">#</span></span><br></pre></td></tr></table></figure><p>3.在 node1节点上把 .&#x2F;bashrc 和 profile 分发给 node2 和 node3</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#分发 .bashrc : </span></span><br><span class="line">scp ~/.bashrc root@node2:~/ </span><br><span class="line">scp ~/.bashrc root@node3:~/</span><br><span class="line"></span><br><span class="line"><span class="comment">#分发 profile : </span></span><br><span class="line">scp /etc/profile/ root@node2:/etc/ </span><br><span class="line">scp /etc/profile/ root@node3:/etc/</span><br></pre></td></tr></table></figure><p>4.创建虚拟环境 pyspark 基于 python3.8</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create -n pyspark python=3.8</span><br></pre></td></tr></table></figure><p>5.切换到虚拟环境内</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">conda activate pyspark</span><br><span class="line"></span><br><span class="line">结果显示： </span><br><span class="line">(base) [root@master ~]<span class="comment"># conda activate pyspark </span></span><br><span class="line">(pyspark) [root@master ~]<span class="comment">#</span></span><br></pre></td></tr></table></figure><p>6.在虚拟环境内安装包 （有WARNING不用管）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install pyhive pyspark jieba -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></table></figure><p>7.master 节点节点进入 &#x2F;export&#x2F;server&#x2F;spark&#x2F;conf 修改以下配置文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /export/server/spark/conf</span><br></pre></td></tr></table></figure><p>8.将文件 workers.template 改名为 workers，并配置文件内容</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mv</span> workers.template workers</span><br><span class="line"></span><br><span class="line"><span class="comment"># localhost删除，内容追加文末：</span></span><br><span class="line">node1</span><br><span class="line">node2</span><br><span class="line">node3</span><br><span class="line"><span class="comment"># 功能: 这个文件就是指示了 当前SparkStandAlone环境下, 有哪些worker</span></span><br></pre></td></tr></table></figure><p>9.将文件 spark-env.sh.template 改名为 spark-env.sh，并配置相关内容</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mv</span> spark-env.sh.template spark-env.sh</span><br><span class="line"></span><br><span class="line">vim spark-env.sh</span><br><span class="line"></span><br><span class="line">文末追加内容：</span><br><span class="line"></span><br><span class="line"><span class="comment">##设置JAVA安装目录 </span></span><br><span class="line">JAVA_HOME=/export/server/jdk</span><br><span class="line"></span><br><span class="line"><span class="comment">## HADOOP软件配置文件目录，读取HDFS上文件和运行YARN集群 </span></span><br><span class="line">HADOOP_CONF_DIR=/export/server/hadoop/etc/hadoop </span><br><span class="line">YARN_CONF_DIR=/export/server/hadoop/etc/hadoop</span><br><span class="line"></span><br><span class="line"><span class="comment">## 指定spark老大Master的IP和提交任务的通信端口 </span></span><br><span class="line"><span class="comment"># 告知Spark的master运行在哪个机器上 </span></span><br><span class="line"><span class="built_in">export</span> SPARK_MASTER_HOST=master </span><br><span class="line"><span class="comment"># 告知sparkmaster的通讯端口 </span></span><br><span class="line"><span class="built_in">export</span> SPARK_MASTER_PORT=7077 </span><br><span class="line"><span class="comment"># 告知spark master的 webui端口 </span></span><br><span class="line">SPARK_MASTER_WEBUI_PORT=8080</span><br><span class="line"></span><br><span class="line"><span class="comment"># worker cpu可用核数 </span></span><br><span class="line">SPARK_WORKER_CORES=1 </span><br><span class="line"><span class="comment"># worker可用内存 </span></span><br><span class="line">SPARK_WORKER_MEMORY=1g </span><br><span class="line"><span class="comment"># worker的工作通讯地址 </span></span><br><span class="line">SPARK_WORKER_PORT=7078 </span><br><span class="line"><span class="comment"># worker的 webui地址 </span></span><br><span class="line">SPARK_WORKER_WEBUI_PORT=8081</span><br><span class="line"></span><br><span class="line"><span class="comment">## 设置历史服务器 </span></span><br><span class="line"><span class="comment"># 配置的意思是 将spark程序运行的历史日志 存到hdfs的/sparklog文件夹中 </span></span><br><span class="line">SPARK_HISTORY_OPTS=<span class="string">&quot;- </span></span><br><span class="line"><span class="string">Dspark.history.fs.logDirectory=hdfs://master:8020/sparklog/ - </span></span><br><span class="line"><span class="string">Dspark.history.fs.cleaner.enabled=true&quot;</span></span><br></pre></td></tr></table></figure><p>10.开启 hadoop 的 hdfs 和 yarn 集群</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">start-dfs.sh </span><br><span class="line"></span><br><span class="line">start-yarn.sh</span><br></pre></td></tr></table></figure><p>11.在HDFS上创建程序运行历史记录存放的文件夹，同样 conf 文件目录下:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -<span class="built_in">mkdir</span> /sparklog </span><br><span class="line"></span><br><span class="line">hadoop fs -<span class="built_in">chmod</span> 777 /sparklog</span><br></pre></td></tr></table></figure><p>12.将 spark-defaults.conf.template 改为 spark-defaults.conf 并做相关配置</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mv</span> spark-defaults.conf.template spark-defaults.conf </span><br><span class="line"></span><br><span class="line">vim spark-defaults.conf</span><br><span class="line"></span><br><span class="line">文末追加内容为： </span><br><span class="line"><span class="comment"># 开启spark的日期记录功能 </span></span><br><span class="line">spark.eventLog.enabled <span class="literal">true</span> </span><br><span class="line"><span class="comment"># 设置spark日志记录的路径 </span></span><br><span class="line">spark.eventLog.<span class="built_in">dir</span> hdfs://master:8020/sparklog/ </span><br><span class="line"><span class="comment"># 设置spark日志是否启动压缩 </span></span><br><span class="line">spark.eventLog.compress   <span class="literal">true</span></span><br></pre></td></tr></table></figure><p>13.配置 log4j.properties 文件 将文件第 19 行的 log4j.rootCategory&#x3D;INFO, console 改为<br>log4j.rootCategory&#x3D;WARN, console （即将INFO 改为 WARN 目的：输出日志, 设置级别为<br>WARN 只输出警告和错误日志，INFO 则为输出所有信息，多数为无用信息）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mv</span> log4j.properties.template log4j.properties </span><br><span class="line"></span><br><span class="line">vim log4j.properties</span><br><span class="line"></span><br><span class="line">结果显示： </span><br><span class="line">... </span><br><span class="line">18 <span class="comment"># Set everything to be logged to the console </span></span><br><span class="line">19 log4j.rootCategory=WARN, console </span><br><span class="line">....</span><br></pre></td></tr></table></figure><p>14.node1节点分发 spark安装文件夹到node2和node3上</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /export/server/</span><br><span class="line"></span><br><span class="line">scp -r /export/server/spark-3.2.0-bin-hadoop3.2/ node2:<span class="variable">$PWD</span> </span><br><span class="line"></span><br><span class="line">scp -r /export/server/spark-3.2.0-bin-hadoop3.2/ node3:<span class="variable">$PWD</span></span><br></pre></td></tr></table></figure><p>15.node 2和node3上做软连接</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">ln</span> -s /export/server/spark-3.2.0-bin-hadoop3.2 /export/server/spark</span><br></pre></td></tr></table></figure><p>16.重新加载环境变量</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> /etc/profile</span><br><span class="line"></span><br><span class="line">进入 /export/server/spark/sbin 文件目录下 启动 start-history-server.sh</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> /export/server/spark/sbin </span><br><span class="line"></span><br><span class="line">./start-history-server.sh</span><br></pre></td></tr></table></figure><p> 访问WebUI 界面</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">浏览器访问： </span><br><span class="line"></span><br><span class="line">http://master:18080/</span><br></pre></td></tr></table></figure><p>18.启动Spark的Master和Worker进程</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动全部master和worker </span></span><br><span class="line">sbin/start-all.sh </span><br><span class="line"><span class="comment"># 或者可以一个个启动: </span></span><br><span class="line"><span class="comment"># 启动当前机器的master </span></span><br><span class="line">sbin/start-master.sh </span><br><span class="line"><span class="comment"># 启动当前机器的worker </span></span><br><span class="line">sbin/start-worker.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 停止全部 </span></span><br><span class="line">sbin/stop-all.sh </span><br><span class="line"><span class="comment"># 停止当前机器的master </span></span><br><span class="line">sbin/stop-master.sh </span><br><span class="line"><span class="comment"># 停止当前机器的worker </span></span><br><span class="line">sbin/stop-worker.sh</span><br></pre></td></tr></table></figure><p> 访问WebUI界面</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">浏览器访问： </span><br><span class="line"></span><br><span class="line">http://master:8080/</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;一、Spark-local模式&quot;&gt;&lt;a href=&quot;#一、Spark-local模式&quot; class=&quot;headerlink&quot; title=&quot;一、Spark-local模式&quot;&gt;&lt;/a&gt;一、Spark-local模式&lt;/h3&gt;&lt;p&gt;本地模式(单机) 本地模式就是以一个</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>spark基础环境配置</title>
    <link href="http://example.com/2022/05/22/%E2%80%9Cspark%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E2%80%9D/"/>
    <id>http://example.com/2022/05/22/%E2%80%9Cspark%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E2%80%9D/</id>
    <published>2022-05-22T03:06:37.000Z</published>
    <updated>2022-05-23T03:02:50.295Z</updated>
    
    <content type="html"><![CDATA[<h3 id="一、基础环境配置"><a href="#一、基础环境配置" class="headerlink" title="一、基础环境配置"></a>一、基础环境配置</h3><p>1.编辑主机名（3台机器）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/hostname</span><br></pre></td></tr></table></figure><p>2.Hosts映射（3台主机）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/hosts</span><br></pre></td></tr></table></figure><p>3.关闭防火墙（3台机器）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld.service   <span class="comment">#关闭防火墙</span></span><br><span class="line">systemctl <span class="built_in">disable</span> firewalld.service <span class="comment">#禁止防火墙开启自启</span></span><br></pre></td></tr></table></figure><p>4.设置ssh免密登录（node1执行-&gt;node1|node2|node3）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen <span class="comment">#4个回车生成公钥、私钥</span></span><br><span class="line">ssh-copy-id node1、ssh-copy-id node2、ssh-copy-id node3</span><br></pre></td></tr></table></figure><p>5.集群时间同步（3台机器）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum-y install ntpdate</span><br><span class="line">ntpdate ntp4.aliyun.com</span><br></pre></td></tr></table></figure><p>6.创建统一工作目录（3台机器）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p /export/server/    <span class="comment">#软件安装路径</span></span><br><span class="line"><span class="built_in">mkdir</span> -p /export/data/      <span class="comment">#数据存储路径</span></span><br><span class="line"><span class="built_in">mkdir</span> -p /export/software/  <span class="comment">#安装包存放路径</span></span><br></pre></td></tr></table></figure><h3 id="二、JDK安装"><a href="#二、JDK安装" class="headerlink" title="二、JDK安装"></a>二、JDK安装</h3><p>1.编译环境软件安装目录</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir-p /export/server/</span><br></pre></td></tr></table></figure><p>2.JDK1.8安装上传jdk-8u241-linux-x64.tar.gz到&#x2F;export&#x2F;server&#x2F;目录下并解压</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir-p /export/server/</span><br></pre></td></tr></table></figure><p>3.配置环境变量</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/profile </span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/export/server/jdk1.8.0_241</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin</span><br><span class="line"><span class="built_in">export</span> CLASSPATH=<span class="variable">$JAVA_HOME</span>/lib/dt.jar:<span class="variable">$JAVA_HOME</span>/lib/tools.jar</span><br></pre></td></tr></table></figure><p>4.重新加载环境变量文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure><p>5.JDK配置后验证</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -version</span><br></pre></td></tr></table></figure><h3 id="三、Hadoop安装配置"><a href="#三、Hadoop安装配置" class="headerlink" title="三、Hadoop安装配置"></a>三、Hadoop安装配置</h3><p>1.解压上传文件（ hadoop-3.3.0-Centos7-64-with-snappy.tar.gz ）到&#x2F;export&#x2F;server&#x2F;目录下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf hadoop-3.3.0-Centos7-64-with-snappy.tar.gz</span><br></pre></td></tr></table></figure><p>2.修改配置文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#修改hadoop-env.sh</span></span><br><span class="line"><span class="built_in">cd</span> /export/server/hadoop-3.3.0/etc/hadoop</span><br><span class="line">vim hadoop-env.sh   <span class="comment">#进入文件</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/export/server/jdk1.8.0_241   <span class="comment">#文件最后添加</span></span><br><span class="line"><span class="built_in">export</span> HDFS_NAMENODE_USER=root</span><br><span class="line"><span class="built_in">export</span> HDFS_DATANODE_USER=root</span><br><span class="line"><span class="built_in">export</span> HDFS_SECONDARYNAMENODE_USER=root</span><br><span class="line"><span class="built_in">export</span> YARN_RESOURCEMANAGER_USER=root</span><br><span class="line"><span class="built_in">export</span> YARN_NODEMANAGER_USER=root</span><br><span class="line"></span><br><span class="line"><span class="comment">#修改core-site.xml</span></span><br><span class="line">&lt;设置默认使用的文件系统 Hadoop支持file、HDFS、GFS、ali|Amazon云等文件系统&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">&lt;value&gt;hdfs://node1:8020&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;设置Hadoop本地保存数据路径&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">&lt;value&gt;/export/data/hadoop-3.3.0&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;设置HDFS web UI用户身份&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;hadoop.http.staticuser.user&lt;/name&gt;</span><br><span class="line">&lt;value&gt;root&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;整合hive 用户代理设置&gt;</span><br><span class="line">hdfs-site.xml</span><br><span class="line">marpred-site.xml</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;hadoop.proxyuser.root.hosts&lt;/name&gt;</span><br><span class="line">&lt;value&gt;*&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;hadoop.proxyuser.root.groups&lt;/name&gt;</span><br><span class="line">&lt;value&gt;*&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;文件系统垃圾桶保存时间&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;fs.trash.interval&lt;/name&gt;</span><br><span class="line">&lt;value&gt;1440&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">#修改mapred-site.xml</span></span><br><span class="line">&lt; 设置MR程序默认运行模式： yarn集群模式 <span class="built_in">local</span>本地模式&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">&lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;MR程序历史服务地址&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;</span><br><span class="line">&lt;value&gt;node1:10020&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;MR程序历史服务器web端地址&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;node1:19888&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;HADOOP_MAPRED_HOME=<span class="variable">$&#123;HADOOP_HOME&#125;</span>&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapreduce.map.env&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;HADOOP_MAPRED_HOME=<span class="variable">$&#123;HADOOP_HOME&#125;</span>&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapreduce.reduce.env&lt;/name&gt;</span><br><span class="line">yarn-site.xml</span><br><span class="line">workers</span><br><span class="line">&lt;分发同步hadoop安装包&gt;</span><br><span class="line">  &lt;value&gt;HADOOP_MAPRED_HOME=<span class="variable">$&#123;HADOOP_HOME&#125;</span>&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">#修改yarn-site.xml</span></span><br><span class="line">&lt; 设置YARN集群主角色运行机器位置 &gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;node1&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;是否将对容器实施物理内存限制&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.nodemanager.pmem-check-enabled&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;<span class="literal">false</span>&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;是否将对容器实施虚拟内存限制&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;<span class="literal">false</span>&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;开启日志聚集&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;<span class="literal">true</span>&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;设置yarn历史服务器地址&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.log.server.url&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;http://node1:19888/jobhistory/logs&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;历史日志保存的时间 7天&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;604800&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">#修改workers</span></span><br><span class="line">localhost</span><br><span class="line">node1.itcast.cn</span><br><span class="line">node2.itcast.cn</span><br><span class="line">node3.itcast.cn</span><br><span class="line"></span><br><span class="line"><span class="comment">#分发同步hadoop安装包</span></span><br><span class="line"><span class="built_in">cd</span> /export/server</span><br><span class="line">scp -r hadoop-3.3.0 root@node2:<span class="variable">$PWD</span></span><br><span class="line">scp -r hadoop-3.3.0 root@node3:<span class="variable">$PWD</span></span><br></pre></td></tr></table></figure><p>3.将hadoop添加到环境变量</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/profile</span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/export/server/hadoop-3.3.0</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/sbin</span><br></pre></td></tr></table></figure><p>4.重新加载环境变量文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure><p>5.Hadoop集群启动 格式化namenode（只有首次启动需要格式化）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -forma</span><br></pre></td></tr></table></figure><p>6.脚本一键启动</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-all.sh</span><br></pre></td></tr></table></figure><p>7.查看WEB页面 </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">   HDFS集群 :http://node1:9870/</span><br><span class="line">YARN集群 :http://node1:8088/</span><br></pre></td></tr></table></figure><h3 id="四、Zookeeper安装配置"><a href="#四、Zookeeper安装配置" class="headerlink" title="四、Zookeeper安装配置"></a>四、Zookeeper安装配置</h3><p>1.配置主机名和IP的映射关系，修改 &#x2F;etc&#x2F;hosts 文件，添加 node1.root node2.root node3.root</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/hosts</span><br><span class="line"></span><br><span class="line"><span class="comment">#结果显示</span></span><br><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line">192.168.88.135 node1 node1.root</span><br><span class="line">192.168.88.136 node2 node2.root</span><br><span class="line">192.168.88.137 node3 node3.root</span><br></pre></td></tr></table></figure><p>2.zookeeper安装 上传 zookeeper-3.4.10.tar.gz到&#x2F;export&#x2F;server&#x2F;目录下 并解压文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /export/server/</span><br><span class="line">tar -zxvf zookeeper-3.4.10.tar.gz</span><br></pre></td></tr></table></figure><p>3.在 &#x2F;export&#x2F;server 目录下创建软连接</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /export/server</span><br><span class="line"><span class="built_in">ln</span> -s zookeeper-3.4.10/ zookeeper</span><br></pre></td></tr></table></figure><p>4.cd进入 &#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;conf&#x2F; 将 zoo_sample.cfg 文件复制为新文件 zoo.cfg</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /export/server/zookeeper/conf/ </span><br><span class="line"><span class="built_in">cp</span> zoo_sample.cfg zoo.cfg</span><br></pre></td></tr></table></figure><p>接上步给 zoo.cfg 添加内容</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Zookeeper的数据存放目录</span></span><br><span class="line">dataDir=/export/server/zookeeper/zkdatas</span><br><span class="line"><span class="comment"># 保留多少个快照</span></span><br><span class="line">autopurge.snapRetainCount=3</span><br><span class="line"><span class="comment"># 日志多少小时清理一次</span></span><br><span class="line">autopurge.purgeInterval=1</span><br><span class="line"><span class="comment"># 集群中服务器地址</span></span><br><span class="line">server.1=node1:2888:3888</span><br><span class="line">server.2=node2:2888:3888</span><br><span class="line">server.3=node3:2888:3888</span><br></pre></td></tr></table></figure><p>5.进入 &#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;zkdatas 目录在此目录下创建 myid 文件，将 1 写入进去</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /export/server/zookeeper/zkdata</span><br><span class="line"><span class="built_in">touch</span> myid</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;1&#x27;</span> &gt; myid</span><br></pre></td></tr></table></figure><p>6.将 node1 节点中 &#x2F;export&#x2F;server&#x2F;zookeeper-3.4.10 路径下内容推送给node2 和 node3</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp -r /export/server/zookeeper-3.4.10/ node2:<span class="variable">$PWD</span></span><br><span class="line">scp -r /export/server/zookeeper-3.4.10/ node3:<span class="variable">$PWD</span></span><br></pre></td></tr></table></figure><p>7.推送成功后，分别在 node2 和 node3 上创建软连接</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">ln</span> -s zookeeper-3.4.10/ zookeeper</span><br></pre></td></tr></table></figure><p>接上步推送完成后将 node2 和 node3 的 &#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;zkdatas&#x2F; 文件夹下的 myid 中的内容分别改为 2 和 3</p><p>8.配置zookeeper的环境变量（注：三台主机都需要配置）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/profile</span><br><span class="line"></span><br><span class="line"><span class="comment">#zookeeper 环境变量</span></span><br><span class="line"><span class="built_in">export</span> ZOOKEEPER_HOME=/export/server/zookeeper</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$ZOOKEEPER_HOME</span>/bin</span><br></pre></td></tr></table></figure><p>9.重新加载环境变量文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure><p>10.进入 &#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;bin&#x2F; 目录下启动 zkServer.sh 脚本 （注：三台都需要做）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /export/server/zookeeper/bin/ </span><br><span class="line">zkServer.sh start</span><br></pre></td></tr></table></figure><p>11.查看zookeeper是否开启</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jps</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;一、基础环境配置&quot;&gt;&lt;a href=&quot;#一、基础环境配置&quot; class=&quot;headerlink&quot; title=&quot;一、基础环境配置&quot;&gt;&lt;/a&gt;一、基础环境配置&lt;/h3&gt;&lt;p&gt;1.编辑主机名（3台机器）&lt;/p&gt;
&lt;figure class=&quot;highlight bas</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>我的第一篇博客文章</title>
    <link href="http://example.com/2022/05/21/%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2%E6%96%87%E7%AB%A0/"/>
    <id>http://example.com/2022/05/21/%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2%E6%96%87%E7%AB%A0/</id>
    <published>2022-05-21T06:57:06.000Z</published>
    <updated>2022-05-21T06:57:06.881Z</updated>
    
    
    
    
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://example.com/2022/05/21/hello-world/"/>
    <id>http://example.com/2022/05/21/hello-world/</id>
    <published>2022-05-21T06:51:11.881Z</published>
    <updated>2022-05-21T06:51:11.882Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot;&gt;documentation&lt;/a&gt; for</summary>
      
    
    
    
    
  </entry>
  
</feed>
