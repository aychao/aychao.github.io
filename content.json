{"meta":{"title":"aychao","subtitle":"","description":"","author":"John Doe","url":"http://example.com","root":"/"},"pages":[{"title":"Categories","date":"2023-02-16T14:53:24.646Z","updated":"2022-05-21T07:21:50.403Z","comments":true,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""},{"title":"About","date":"2023-02-08T14:42:13.647Z","updated":"2022-05-21T07:21:50.399Z","comments":true,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":""},{"title":"Tags","date":"2023-02-16T14:53:14.736Z","updated":"2022-05-21T07:21:50.412Z","comments":true,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"","slug":"Web前端基础","date":"2023-02-28T13:57:59.283Z","updated":"2023-02-28T13:47:16.533Z","comments":true,"path":"2023/02/28/Web前端基础/","link":"","permalink":"http://example.com/2023/02/28/Web%E5%89%8D%E7%AB%AF%E5%9F%BA%E7%A1%80/","excerpt":"","text":"Web前端基础 HTML: 学习如何搭建页面 (盖房子,毛坯房) CSS: 学习如何美化页面 (装修) JavaScript: 学习如何给页面添加动态效果 HTML Hypertext Markup Language: 超文本标记语言 标记语言的格式: 1&lt;开始标签 属性名=&quot;属性值&quot; 属性名=&quot;属性值&quot;&gt;标签体&lt;/结束标签&gt; 学习HTML 主要学习的就是有哪些标签,以及标签的使用方式 常用快捷键 Alt+Insert 新建文件 Ctrl+D 复制整行并粘贴到下一行 Shift+回车 切换到下一行 Ctrl+Alt+L 代码格式化 Ctrl+X 剪切 (可以用做删除) Ctrl+Z 撤销 Ctrl+Shift+Z 恢复 Ctrl+Shift+&#x2F; 注释 文本相关标签 内容标题h1-h6 字体加粗, 独占一行, 自带上下的间距 水平分割线 hr 段落标签 p 独占一行, 自带上下间距 换行br 加粗b 斜体i 下划线u 删除线s 无序列表: ul和li 有序列表: ol和li 列表嵌套: 有序和无序列表可以任意无限嵌套 图片标签img12345678910src设置资源路径: 相对路径:访问站内资源时使用 1. 资源和页面在同级目录: 直接写图片名 2. 资源在页面的上级目录: ../图片名 3. 资源在页面的下级目录: 文件夹名/图片名 绝对路径:访问站外资源时使用,称为图片盗链, 有找不到图片的风险alt:当图片不能正常显示时显示的文本title: 鼠标悬停时显示的文本width/height:设置宽高 两种赋值方式:1.像素 2.百分比 只设置宽度 高度会自动等比例缩放 超链接a href: 设置请求的资源路径,作用类似图片标签的src属性 图片超链接: 用a标签包裹文本为文本超链接, 包裹图片为图片超链接 页面内部跳转: 在目的地元素里面添加id属性, 然后在超链接href&#x3D;”#id”,这样就能跳转到指定元素的位置 表格标签table 相关标签: table tr表示行 td表示列 th表头 caption表格标题 相关属性: border边框 colspan跨列 rowspan跨行 表单form 作用: 获取用户输入的各种信息 并提交给服务器 学习form表单就是学习有哪些控件, 控件包括: 文本框,密码框,单选,多选,下拉选等 1234567891011121314151617181920212223242526272829303132333435&lt;!--action设置请求地址 --&gt;&lt;form action=&quot;http://www.tmooc.cn&quot;&gt; &lt;!--文本框, name属性是所有控件必须添加的属性 否则提交时不会传递此内容 placeholder占位文本 maxlength设置最大字符长度 value设置默认值 readonly只读 --&gt; &lt;input type=&quot;text&quot; name=&quot;username&quot; maxlength=&quot;5&quot; value=&quot;abc&quot; readonly placeholder=&quot;用户名&quot;&gt;&lt;br&gt; &lt;!--密码框--&gt; &lt;input type=&quot;password&quot; name=&quot;password&quot; placeholder=&quot;密码&quot;&gt;&lt;br&gt; &lt;!--value设置提交的内容,如果不设置提交的是on checked设置默认选中 --&gt; 性别: &lt;input type=&quot;radio&quot; name=&quot;gender&quot; value=&quot;m&quot; id=&quot;r1&quot;&gt;&lt;label for=&quot;r1&quot;&gt;男&lt;/label&gt; &lt;input type=&quot;radio&quot; name=&quot;gender&quot; value=&quot;w&quot; checked id=&quot;r2&quot;&gt;&lt;label for=&quot;r2&quot;&gt;女&lt;/label&gt; &lt;br&gt; 兴趣爱好: &lt;input type=&quot;checkbox&quot; name=&quot;hobby&quot; value=&quot;cy&quot;&gt;抽烟 &lt;input type=&quot;checkbox&quot; name=&quot;hobby&quot; value=&quot;hj&quot;&gt;喝酒 &lt;input type=&quot;checkbox&quot; name=&quot;hobby&quot; value=&quot;tt&quot; checked&gt;烫头&lt;br&gt; 所在地: &lt;select name=&quot;city&quot;&gt; &lt;option value=&quot;bj&quot;&gt;北京&lt;/option&gt; &lt;option value=&quot;sh&quot; selected&gt;上海&lt;/option&gt; &lt;option value=&quot;gz&quot;&gt;广州&lt;/option&gt; &lt;/select&gt;&lt;br&gt; 靓照: &lt;input type=&quot;file&quot; name=&quot;pic&quot;&gt;&lt;br&gt; 生日: &lt;input type=&quot;date&quot; name=&quot;birthday&quot;&gt;&lt;br&gt; &lt;!--提交按钮--&gt; &lt;input type=&quot;submit&quot; value=&quot;注册&quot;&gt; &lt;input type=&quot;reset&quot;&gt; &lt;input type=&quot;button&quot; value=&quot;自定义&quot;&gt; &lt;hr&gt; &lt;button type=&quot;submit&quot;&gt;注册&lt;/button&gt; &lt;button type=&quot;reset&quot;&gt;重置&lt;/button&gt; &lt;button type=&quot;button&quot;&gt;自定义&lt;/button&gt;&lt;/form&gt; 分区标签 分区标签可以理解为一个容器, 将多个有相关性的标签添加到一个分区标签里面, 便于统一管理 常见的分区标签: div: 独占一行 span: 共占一行 HTML5.0版本增加的分区标签 ,这些标签的作用和div 一样, 为了提高代码的可读性 header 头 footer 脚 main 主体 nav 导航 section 区域 CSS 层叠样式表 作用: 负责美化页面 (相当于装修) 如何在html页面中添加css样式代码 三种引入方式: 内联: 在标签的style属性中添加样式代码, 不能复用 内部: 在head标签里面添加style标签, 在标签体内添加样式代码, 可以当前页面复用 不能多页面复用 外部: 在单独css文件中添加样式代码, 在html页面中的head标签里面添加link标签 把css引入到html页面中, 支持多页面复用 CSS选择器 作用: 用来查找页面中的元素 标签名选择器: 匹配页面中所有同名标签 格式: 标签名{样式代码} id选择器: 当需要选择页面中某一个标签时使用 格式: #id{样式代码} 类选择器: 当需要选择页面中多个不相关的元素时,给多个元素添加相同的class值划分为同一类 格式: .class{样式代码} 分组选择器: 将多个选择器划分为同一组进行统一管理 格式: div,#id,.class{样式代码} 属性选择器: 通过元素的属性匹配元素 格式: 标签名[属性名&#x3D;’值’]{样式代码} 后代选择器: 通过元素和元素之间的层级关系元素元素,选择的范围更广 格式: body div div p{样式代码} 匹配的是body里面的div里面的div里面的所有p(包含后代) 子元素选择器: 通过元素和元素之间的层级关系元素元素, 选择的范围更精准 格式: body&gt;div&gt;div&gt;p{样式代码} 匹配的是body里面的div里面的div里面的所有p子元素(不包含后代) 伪类选择器: 选择元素的状态 包括: 未访问&#x2F;访问过&#x2F;悬停&#x2F;激活 格式: a:link&#x2F;visited&#x2F;hover&#x2F;active{样式代码} 颜色赋值方式 三原色: RGB Red Green Blue , 每一种颜色的取值范围0-255 五种赋值方式: 颜色单词赋值: red&#x2F;blue&#x2F;yellow&#x2F;green…. 6位16进制赋值: #ff0000 3位16进制赋值: #f00 3位10进制赋值: rgb(255,0,0) 4位10进制赋值: rgba(255,0,0,0-1) a&#x3D;alpha 透明度 值越小越透明 背景图片相关 background-image:url(“路径”) 设置背景图片 background-size:200px 300px; 设置背景图片尺寸 background-repeat:no-repeat; 禁止重复 background-position: 100px 200px; 设置背景图片的位置 background-position: 50% 50%; 设置背景图片的位置 文本和字体相关样式 text-align:right&#x2F;center; 水平对齐方式 text-decoration:overline上划线&#x2F;underline下划线&#x2F;line-through删除线&#x2F;none去掉修饰 line-height:20px; 设置行高, 单行可以实现垂直居中, 多行可以控制行间距 text-shadow:颜色 x偏移值 y偏移值 浓度(值越小越清晰); font-size:20px; 字体大小 font-weight:bold加粗&#x2F;normal去掉加粗; font-style:italic; 设置斜体 font-family:xxxx,xxx,xxx; 设置字体 font: 20px xxx,xxx,xxx; 设置字体大小+字体 元素的显示方式display block: 块级元素的默认值, 显示特点: 独占一行,可以修改元素的宽高. 包括: h1-h6,p,div inline: 行内元素的默认值, 显示特点: 共占一行, 不能修改元素的宽高. 包括: span,b,i,s,u,a inline-block: 行内块元素的默认值, 显示特点: 共占一行, 并且可以修改元素宽高. 包括: input,img none: 隐藏元素 盒子模型 通过盒子模型相关的样式控制元素的显示效果 盒子模型包括: content内容+border边框+margin外边距+padding内边距 content内容:用来控制元素的显示大小 border边框: 用来控制边框的效果 margin外边距: 用来控制元素的显示位置 padding内边距: 用来控制元素内容的位置 盒子模型之Content内容 控制元素的显示大小 相关样式: width&#x2F;height 赋值方式:1. 像素 2. 上级元素的百分比 行内元素是不能修改宽高的, 如果必须要修改, 需要将元素的显示方式改成块级block或行内块inline-block 盒子模型之margin外边距 控制元素的显示位置 赋值方式: margin-left&#x2F;right&#x2F;top&#x2F;bottom:10px; 单独某一个方向赋值 margin:10px; 四个方向赋值 margin:10px 20px; 上下10 左右20 margin:10px 20px 30px 40px; 上右下左赋值 顺时针 行内元素上下外边距无效 左右相邻彼此添加外边距 两者相加 外边距塌陷: 兄弟元素上下相邻, 彼此添加外边距 取最大值 父子元素上边缘重叠时, 添加外边距取最大值,会导致父子元素粘连在一起,给父元素添加overflow:hidden样式解决. 盒子模型之边框border 赋值方式: border-left&#x2F;right&#x2F;top&#x2F;bottom:粗细 样式 颜色; 单独某一个方向添加边框 border:粗细 样式 颜色; 四个方向添加边框 border-radius:10px ; 设置圆角 值越大越圆 盒子模型之内边距padding 控制元素内容的位置 赋值方式: 和外边距类似 padding-left&#x2F;right&#x2F;top&#x2F;bottom:10px; 单独某一个方向添加 padding:10px; 四个方向添加 padding: 10px 20px; 上下10 左右20 padding: 10px 20px 30px 40px; 上右下左 顺时针赋值 给元素添加内边距默认情况下会影响元素的显示范围,给元素添加box-sizing:border-box; 后则不再影响 部分标签会带盒子模型中的某些样式 body 自带8个像素的外边距 段落标签p, 列表标签和内容标题h1-h6 自带上下的外边距 文本框自带边框和内边距 列表标签自带外边距和内边距 CSS三大特性&#x3D;&#x3D;继承性:&#x3D;&#x3D; 指元素可以继承上级元素文本和字体相关的样式, 部分标签自带的效果不受继承影响, 比如超链接的字体颜色&#x3D;&#x3D;层叠性:&#x3D;&#x3D; 指一个元素可以层叠很多不同的样式, 多个选择器有可能选择到同一个元素, 如果添加的样式不同,则样式全部层叠生效,如果添加的样式相同则由选择器的优先级决定哪个生效&#x3D;&#x3D;优先级:&#x3D;&#x3D; 作用范围越小 优先级越高. !important&gt;id&gt;class&gt;标签名&gt;继承(属于间接选中) 居中相关 元素自身居中: 块级元素: 通过外边距 margin:0 auto; 行内或行内块元素: 在上级元素中添加text-align:center; 元素内容居中: 只能通过text-align:center; 定位 静态定位 相对定位 绝对定位 固定定位 浮动定位 静态定位 position:static; 默认的定位方式,又称为文档流定位 特点: 块级元素从上往下依次排列, 行内元素从左向右依次排列,通过外边距控制元素的位置. 默认情况下无法实现元素层叠效果 相对定位 position:relative; 特点: 元素不脱离文档流(不管元素显示到什么位置,仍然占着原来的位置,后面的元素不会顶上来),元素通过left&#x2F;right&#x2F;top&#x2F;bottom样式 相对于初始位置做偏移. 应用场景: 当元素需要层叠显示时, 静态定位是无法实现的, 通过相对于定位可以实现层叠, 当需要对某一个元素的显示位置进行微调时使用. 绝对定位 position:absolute; 特点: 元素脱离文档流(不占原来的位置, 后面的元素会顶上来), 通过left&#x2F;right&#x2F;top&#x2F;bottom相对于窗口(默认)或某一个上级元素做偏移. 应用场景: 当需要层叠显示,并且需要让元素相对于某个上级元素做位置偏移时使用 固定定位 position:fixed; 特点: 元素脱离文档流, 通过left&#x2F;right&#x2F;top&#x2F;bottom相对于窗口做位置偏移. 应用场景: 当需要将元素固定在窗口的某个位置时使用 浮动定位 float:left&#x2F;right 特点: 元素脱离文档流, 从当前所在行向左或向右浮动,当撞到上级元素边缘或其它浮动元素时停止. 多个浮动元素一行装不下时会自动折行, 折行时有可能被卡主 当元素的所有子元素全部浮动时, 自动识别的内容高度为0, 会导致后面的元素顶上来 出现显示异常, 给元素添加overflow:hidden 解决此问题. 应用场景: 将纵向排列的多个元素 改成横向排列时使用. 表设计面试题2021年过年时小明在这些天都收到了许多亲戚\\朋友还有同事的红包,也发出了一些红包,有的是微信,有的是支付宝也有现金,请参考下面的题目帮小明设计表格保存红包的信息 设计表保存红包信息 (至少包含一张流水表) 列出需要保存的数据有哪些: 人物关系,红包金额,红包类型,时间,性别,名字 流水表: id,金额,时间,红包类型,人物id 123CREATE DATABASE mydb CHARSET=UTF8;USE mydb;CREATE TABLE trade(id INT PRIMARY KEY AUTO_iNCREMENT,money INT,time DATE,type VARCHAR(10),p_id INT); 人物表:id,名字,性别,关系 1CREATE TABLE person(id INT PRIMARY KEY AUTO_iNCREMENT,name VARCHAR(20),gender CHAR(1),rel VARCHAR(10)); 插入数据: 123456789INSERT INTO person VALUES(NULL,&#x27;刘德华&#x27;,&#x27;男&#x27;,&#x27;亲戚&#x27;),(NULL,&#x27;杨幂&#x27;,&#x27;女&#x27;,&#x27;亲戚&#x27;),(NULL,&#x27;马云&#x27;,&#x27;男&#x27;,&#x27;同事&#x27;),(NULL,&#x27;特朗普&#x27;,&#x27;男&#x27;,&#x27;朋友&#x27;),(NULL,&#x27;貂蝉&#x27;,&#x27;女&#x27;,&#x27;朋友&#x27;);INSERT INTO trade VALUES(NULL,1000,&#x27;2021-3-20&#x27;,&#x27;微信&#x27;,1),(NULL,500,&#x27;2021-4-14&#x27;,&#x27;现金&#x27;,2),(NULL,-50,&#x27;2021-4-14&#x27;,&#x27;现金&#x27;,2),(NULL,20000,&#x27;2021-3-11&#x27;,&#x27;支付宝&#x27;,3),(NULL,-5,&#x27;2021-3-11&#x27;,&#x27;支付宝&#x27;,3),(NULL,2000,&#x27;2021-5-18&#x27;,&#x27;微信&#x27;,4),(NULL,-20000,&#x27;2021-7-22&#x27;,&#x27;微信&#x27;,5); 统计2021年3月15号到现在的所有红包收益 SELECT SUM(money) FROM TRADE WHERE time&gt;’2021-3-15’; 查询2021年2月15号到现在 金额大于100 所有女性亲戚的名字和金额 SELECT name,money FROM trade t JOIN person p ON t.p_id&#x3D;p.id WHERE time&gt;’2021-2-15’ AND ABS(money)&gt;100 AND gender&#x3D;’女’ AND rel&#x3D;’亲戚’; 查询三个平台(微信,支付宝,现金)分别收入的红包金额 SELECT type,SUM(money) FROM trade WHERE money&gt;0 GROUP BY type; 溢出设置overflow hidden 隐藏 visible 显示 scroll 滚动显示 显示层级 当元素为非static 定位,出现层叠时, 可以通过z-index设置显示层级, 值越大显示越靠前 行内元素垂直对齐方式vertical-align top上对齐 middle中间对齐 bottom下对齐 baseline基线对齐 JavaScript 作用: 给页面添加动态效果 语言特点: 属于脚本语言, 不需要编译由浏览器解析执行. 属于弱类型语言 int x &#x3D; 10; String name&#x3D;”张三” ; let x&#x3D;10; let name&#x3D;”张三”; 基于面向对象语言 安全性强: 因为JS语言是嵌入到html页面中运行在客户端的语言,所以对安全性要求较高 , JS语言只能获取浏览器内部的数据, 浏览器以外客户端电脑上面的数据是禁止访问的. 交互性强: JS语言是嵌入到html页面中运行在客户端的语言, 和用户直接接触, 而像Java语言是运行在服务器的语言,需要通过网络进行交互,所以相对来说JS语言的交互性更强 JavaScript和Java语言没有任何关系 , 只是为了蹭热度 . 变量 数据类型 运算符 各种语句 方法 面向对象 变量 JavaScript语言属于弱类型语言 Java: int age&#x3D;18; String name&#x3D;”张三”; name&#x3D;20; 报错 JS: let age&#x3D;18; let name&#x3D;”李四”; name&#x3D;20; 正常执行 JavaScript语言中通过let或var声明变量 let声明的变量, 作用域和Java语言类似 var声明的变量, 不管在什么位置都相当于声明的是一个全局变量 举例: 123456789101112131415Java:for(int i=0;i&lt;10;i++)&#123; int j = i+1; &#125;int x = i+j; //报错 i和j超出了作用域 JavaScript: letfor(let i=0;i&lt;10;i++)&#123; let j=i+1;&#125;let x = i+j; //不会报错 但是因为i和j超出了作用域,访问不到i和jJavaScript: varfor(var i=0;i&lt;10;i++)&#123; var j=i+1;&#125;var x = i+j; //不会报错, 并且可以访问到i和j的值 数据类型 JavaScript语言中只有引用类型 常见的对象类型： string字符串: 可以通过单引号或双引号进行修饰 number数值: 相当于java中所有数值类型的总和 boolean布尔值: true和false undefined未定义: 当变量只声明不赋值时,变量的类型为未定义类型 获取变量类型的方法: typeof 变量; 运算符 算术运算符: + - * &#x2F; % 除法运算会自动根据结果转换整数或小数 java : int x &#x3D; 5; int y&#x3D;2; int z &#x3D; x&#x2F;y; z&#x3D;2 js : let x &#x3D; 5; let y&#x3D;2; let z &#x3D; x&#x2F;y; z&#x3D;2.5 x&#x3D;6 z&#x3D;3 关系运算符: &gt; &lt; &gt;&#x3D; &lt;&#x3D; !&#x3D; &#x3D;&#x3D;和&#x3D;&#x3D;&#x3D; &#x3D;&#x3D;: 先统一等号两边变量的类型, 再比较值 “666”&#x3D;&#x3D;666 true &#x3D;&#x3D;&#x3D;: 先比较类型,类型相同后再比较值 “666”&#x3D;&#x3D;&#x3D;666 false 逻辑运算符: &amp;&amp; || ! 只支持短路与和短路或 赋值运算符: &#x3D; +&#x3D; -&#x3D; *&#x3D; &#x2F;&#x3D; %&#x3D; 三目运算符: 条件?值1:值2 各种语句 if else for 新循环 for(Person p : persons) JS: for(let p of persons) while switch case 如何在html页面中添加js代码 三种引入方式 内联:在标签的事件属性中添加JS代码,当事件触发时执行. 事件: 指系统提供的一系列时间点 . 点击事件: 当用户点击元素的时间点. 内部: 在页面的任意位置可以添加script标签,在标签体内写js代码, 建议写在body结束标签的附近 外部: 在单独的js文件中写js代码, 在html页面中通过script标签的src属性引入, 如果script标签引入了js文件则不能在标签体内继续写js代码 方法 Java: public 返回值 方法名(参数列表){方法体} JS: function 方法名(参数列表){方法体} 三种定义方法的方式: function 方法名(参数列表){方法体} let 方法名 &#x3D; function(参数列表){方法体} let 方法名 &#x3D; new Function(“参数1”,”参数2”,”方法体”); 和页面相关的方法 通过选择器获取页面中的元素对象 let 元素对象 &#x3D; document.querySelector(“选择器”); 获取和修改控件的值 1&lt;input type=&#x27;text&#x27; value=&#x27;abc&#x27;&gt; input.value 获取 input.value&#x3D;”xxx” 修改 获取和修改元素的文本内容 &lt;div&gt;abc&lt;/div&gt; &lt;span&gt;abc&lt;/span&gt; NaN Not a Number: 不是一个数, 任何数值和NaN进行任何运算得到的结果都是NaN isNaN(变量) ,判断变量是否是NaN, true代表是NaN(不是数), false代表不是NaN(是数) JavaScript对象分类 内置对象: 包括string,number,boolean等 BOM: 浏览器对象模型,包含和浏览器相关的内容 DOM:文档对象模型,包含和页面相关的内容 BOM BrowserObject Model: 浏览器对象模型,包含和浏览器相关的内容 window对象, 此对象中的属性和方法可以称为全局属性和全局方法, 访问时可以省略掉window. window.isNaN() window.alert() window.parseInt() window对象中常见的方法: isNaN(变量) 判断变量是否是NaN parseInt() 将字符串或小数转成整数 parseFloat() 将字符串转成小数 alert(“xxx”) 弹出提示框 confirm(“xxx”)弹出确认框 prompt(“xxx”)弹出文本框 let timer &#x3D; setInterval(方法,时间间隔); 开启定时器 clearInterval(timer); 停止定时器 setTimeout(方法, 时间间隔); 开启只执行一次的定时器 window对象中常见的属性 location(位置) location.href 获取或修改浏览器的请求地址 location.reload() 刷新页面 history(历史) history.length 历史页面的数量 history.back() 返回上一页面 后退 hisotry.forward() 前往下一页面 前进 history.go(n) n正值代表前进 n负值代表后退 0代表刷新 DOM Document Object Model 文档对象模型, 包含和页面相关的内容 通过选择器获取页面中的元素对象 let 元素对象 &#x3D; document.querySelector(“选择器”); 获取和修改控件的值 1&lt;input type=&#x27;text&#x27; value=&#x27;abc&#x27;&gt; input.value 获取 input.value&#x3D;”xxx” 修改 获取和修改元素的文本内容 &lt;div&gt;abc&lt;/div&gt; &lt;span&gt;abc&lt;/span&gt; 元素对象.innerText &#x3D; “xxx”; 修改 元素对象.innerText 获取 创建元素对象 let d &#x3D; document.createElement(“div”); 添加元素到某个元素里面 元素对象.append(新元素); 前端MVC设计模式 MVC设计模式就是将实现前端业务的所有代码划分为三部分 M: model 模型 , 对应数据相关代码 V: View 视图, 对应的是页面标签相关 C: Controller 控制器, 对应的是将数据显示到页面中的过程代码 前端MVC设计模式存在弊端: 在Controller控制器部分 需要频繁的进行DOM相关操作(遍历查找元素),比较浪费资源 , MVVM设计模式可以解决此问题 前端MVVM设计模式 MVVM设计模式也是将实现前端业务的所有代码划分为三部分 M: model 模型 , 对应数据相关代码 V: View 视图, 对应的是页面标签相关 VM:视图模型, 视图模型负责将页面中可能发生改变的元素和某个变量在内存中进行绑定, 并对变量进行监听,当变量发生改变时,会从内存中找到和变量所对应的元素, 让元素进行改动. 这样就不用像MVC设计模式中通过遍历查找的方式查找元素了，从而提高执行的效率。 VUE 此框架是基于MVVM设计模式的框架, 目前最流行的前端框架之一. VUE框架两种用法: 多页面应用: 在html页面中引入vue.js框架文件 单页面应用:通过脚手架的方式使用VUE框架(第四阶段开始接触) 如何在html页面中引入vue.js 从CDN服务器引入 1&lt;script src=&quot;https://cdn.staticfile.org/vue/2.2.2/vue.min.js&quot;&gt;&lt;/script&gt; 把框架文件下载到本地后引入 1&lt;script src=&quot;js/vue.min.js&quot;&gt;&lt;/script&gt; VUE框架执行元素: VUE对象就相当于是MVVM设计模式中的VM视图模型, 此对象负责将页面中发生改变的元素和data里面的变量在内存中绑定, 并且会不断监听变量值的改变, 当检测到变量值发生改变时,会自动从内存中找到与之对应的元素,并且让元素的内容跟着发生改变. VUE相关指令 : 插值, 让当前位置的文本内容和变量进行绑定 v-text&#x3D;”变量” 让元素的文本内容和变量进行绑定 v-html&#x3D;”变量” 让元素的标签内容和变量进行绑定 :属性名&#x3D;”变量” 让元素的某个属性的值和变量进行绑定 v-model&#x3D;”变量” 双向绑定,让控件的值和变量进行双向绑定, 当需要获取控件的值的时候使用 @事件名&#x3D;”方法” 给元素添加事件, 需要将事件触发的方法声明在methods里面. v-for&#x3D;”(变量,下标) in 数组” 循环遍历指令, 遍历的同时会生成元素 v-if&#x3D;”变量” 让元素是否显示和变量进行绑定, true显示 false不显示(删除元素) v-else 让元素的显示状态和v-if取反 v-show&#x3D;”变量” 让元素是否显示和变量进行绑定, true显示 false不显示(隐藏元素)","categories":[],"tags":[]},{"title":"Eagle运维监控","slug":"kafka集群Eagle运维监控","date":"2022-08-28T04:32:29.735Z","updated":"2023-02-16T14:09:37.516Z","comments":true,"path":"2022/08/28/kafka集群Eagle运维监控/","link":"","permalink":"http://example.com/2022/08/28/kafka%E9%9B%86%E7%BE%A4Eagle%E8%BF%90%E7%BB%B4%E7%9B%91%E6%8E%A7/","excerpt":"","text":"本文主要使用Hexo与Github进行个人blog的搭建Hexo官网：HexoGithub官网：Github 环境介绍本地环境为: Window10系统、Linux虚拟机一、Eagle安装本文使用的 Eagle 是2.1.0版本Eagle 3.2.0 安装包下载注意：下载要注意 Eagle 的版本，同时选择后缀为 .tar.gz的安装包**本文使用的安装包是 kafka-eagle-bin-2.1.0.tar.gz ** 123456789101112131415#把本地下载好的 kafka-eagle-bin-2.1.0.tar.gz 安装包上传到 /export/server 并解压$ cd /export/server/$ tar -zxvf kafka-eagle-bin-2.1.0.tar.gz -C /export/server/# ls查看，出现kafka-eagle-bin-2.1.0意味着解压成功#进入到kafka-eagle-bin-2.1.0$ cd kafka-eagle-bin-2.1.0#ls查看，看到efak-web-2.1.0.gz解压包，对其解压到/export/server/目录下$ tar -zxvf efak-web-2.1.0.gz /export/server/# 进入到/export/server/目录下，ls查看，出现efak-web-2.1.0意味着解压成功$ cd /export/server/ #建立软连接$ ln -s /export/server/efak-web-2.1.0 /export/server/kafka-eagle#master 节点节点进入 /export/server/kafka-eagle/conf 修改以下配置文件$ cd /export/server/kafka-eagle/conf Eagle环境变量1234567#配置 eagle 环境变量$ vim /etc/profile#文件最后添加以下内容# kafka 环境变量 $ export PATH=$PATH:$JAVA_HOME/bin$ export KE_HOME=/export/server/kafka-eagle$ export PATH=$PATH:$KE_HOME/bin 启动 Eagle注意：启动 Eagle 需要启动 kafka、zookeeper 1234567#启动 kafka,三台机器同时执行$ kafka-server-start.sh -daemon /export/server/kafka/config/server.properties#启动zookeeper,三台机器同时执行$ zkServer.sh start#启动 Eagle$ /export/server/kafka-eagle/bin/ke.sh start#启动完成后通过jps查看其状态 看到EFAK表明成功启动进入到本地界面（http://192.168.88.151:8048），对Eagle进行部署二、Eagle各项功能（1）Dashboard（仪表盘）查看BROKERS、TOPICS、ZOOKEEPERS、Topic LogSize Top10等 （2）BScreen(大屏)该模块包含展示消费者和生产者当日及最近7天趋势、Kafka集群读写速度、Kafka集群历史总记录等 （3）Topics该模块包含主题创建、主题管理、主题预览、KSQL查询主题、主题数据写入、主题属性配置等。 （4）Consumers（消费监控）该模块包含监控不同消费者组中的Topic被消费的详情，例如LogSize、Offsets、以及Lag等。同时，支持查看Lag的历史趋势图 （5）Cluster（集群管理）该模块包含Kafka集群和Zookeeper集群的详情展示，例如Kafka的IP和端口、版本号、启动时间、Zookeeper的Leader和Follower。同时，还支持多Kafka集群切换，以及Zookeeper Client数据查看等功能。 （6）Metrics（集群状态）该模块包含监控Kafka集群和Zookeeper集群的核心指标，包含Kafka的消息发送趋势、消息大小接收与发送趋势、Zookeeper的连接数趋势等。同时，还支持查看Broker的瞬时指标数据。 （7）Alarm（告警）该模块包含告警集群异常和消费者应用Lag异常。同时，支持多种IM告警方式，例如邮件、钉钉、微信、Webhook等。 （8）System（系统管理）该模块包含用户管理，例如创建用户、用户授权、资源管理等","categories":[{"name":"工具","slug":"工具","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://example.com/tags/hexo/"},{"name":"主题","slug":"主题","permalink":"http://example.com/tags/%E4%B8%BB%E9%A2%98/"},{"name":"搭建","slug":"搭建","permalink":"http://example.com/tags/%E6%90%AD%E5%BB%BA/"}]},{"title":"Kafka基础环境配置","slug":"Kafka基础环境配置","date":"2022-08-28T04:32:29.729Z","updated":"2022-08-11T13:03:44.794Z","comments":true,"path":"2022/08/28/Kafka基础环境配置/","link":"","permalink":"http://example.com/2022/08/28/Kafka%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/","excerpt":"","text":"本文主要使用Hexo与Github进行个人blog的搭建Hexo官网：HexoGithub官网：Github 环境介绍本地环境为: Window10系统、Linux虚拟机注意：本文配置与Spark基础环境配置相同，若Spark基础环境配置已配置，请直接观看下一文章 开始搭建1.基础环境在开始配置前，需要检查虚拟机主机名、hosts映射、关闭防火墙、免密登录、同步时间等操作 （1）编辑主机名（三台机器）123456789#查看系统主机名(三台主机)$ cat /etc/hostname#在三台主机上更改主机名#在 master 主节点$ echo &quot;master&quot; &gt;/etc/hostname #在 slave1 节点 $ echo &quot;slave1&quot; &gt;/etc/hostname #在 slave2 节点$ echo &quot;slave2&quot; &gt;/etc/hostname （2）hosts映射12345678910111213#查看系统映射$ cat /etc/hosts#编辑 /etc/hosts 文件$ vim /etc/hosts#内容修改为 （三台主机内容一致）127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 ::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 192.168.88.135 master 192.168.88.136 slave1 192.168.88.137 slave2 （3）关闭防火墙1234#关闭防火墙$ systemctl stop firewalld.service#禁止防火墙开启自启$ systemctl disable firewalld.service （4）免密登录123456#master 生成公钥私钥，四个回车即可$ ssh-keygen#master 配置免密登录到master slave1 slave2三台主机$ ssh-copy-id master $ ssh-copy-id slave1 $ ssh-copy-id slave2 （5）时间同步123456#安装 ntp$ yum install ntp -y #设置 ntp 开机自启动$ systemctl enable ntpd &amp;&amp; systemctl start ntpd#三台主机分别运行以下命令$ ntpdate ntp4.aliyun.com 2.JDK安装###（1）下载安装包本文使用的 JDK 是1.8版本jdk1.8安装包下载注意：下载的是后缀为 .tar.gz 的包 （2）在主机 master 上安装 JDK1234567891011#编译环境软件安装目录$ mkdir -p /export/server#上传本地下载好的jdk-8u241-linux-x64.tar.gz上传到/export/server/目录下 并解压文件$ tar -zxvf jdk-8u241-linux-x64.tar.gz#配置环境变量$ vim /etc/profile#在文件内添加如下内容# jdk 环境变量 export JAVA_HOME=/export/server/jdk1.8.0_241 export PATH=$PATH:$JAVA_HOME/bin export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.ja 12345#重新加载环境变量文件$ source /etc/profile#查看 java 版本号$ java -version#出现 java version &quot;1.8.0_241&quot; 表示安装成功 （3）分发12345678910#master 节点将 java 传输到 slave1 和 slave2$ cd /export/server$ scp -r /export/server/jdk1.8.0_241/ root@slave1:/export/server/ $ scp -r /export/server/jdk1.8.0_241/ root@slave2:/export/server/#配置 slave1 和 slave2 的 jdk 环境变量（注：和上方 master 的配置方法一样）#配置完成后，在 master slave1 和slave2 三台主机创建软连接$ cd /export/server $ ln -s jdk1.8.0_241/ jdk#重新加载环境变量文件$ source /etc/profile 3.Hadoop安装（1）下载安装包本文使用的 hadoop 是3.3.0版本hadoop3.3.0安装包下载注意：下载的是后缀为 .tar.gz的包 （2）在主机 master 上安装 hadoop123456789101112131415#上传本地下载好的 hadoop-3.3.0-Centos7-64-with-snappy.tar.gz 上传到 /export/server 并解压文件$ tar -zxvf hadoop-3.3.0-Centos7-64-with-snappy.tar.gz#修改配置文件,进入到 hadoop 目录下$ cd /export/server/hadoop-3.3.0/etc/hadoop#编辑 hadoop-env.sh 文件$ vim hadoop-env.sh#文件最后添加 export JAVA_HOME=/export/server/jdk1.8.0_241 export HDFS_NAMENODE_USER=root export HDFS_DATANODE_USER=root export HDFS_SECONDARYNAMENODE_USER=root export YARN_RESOURCEMANAGER_USER=root export YARN_NODEMANAGER_USER=root 12345678910111213141516171819202122232425262728293031323334353637#修改 core-site.xml 文件 $ vim core-site.xml #添加如下内容&lt;!-- 设置默认使用的文件系统 Hadoop支持file、HDFS、GFS、ali|Amazon云等文件系统 --&gt;&lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://master:8020&lt;/value&gt;&lt;/property&gt;&lt;!-- 设置Hadoop本地保存数据路径 --&gt;&lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/export/data/hadoop-3.3.0&lt;/value&gt;&lt;/property&gt;&lt;!-- 设置HDFS web UI用户身份 --&gt;&lt;property&gt; &lt;name&gt;hadoop.http.staticuser.user&lt;/name&gt; &lt;value&gt;root&lt;/value&gt;&lt;/property&gt;&lt;!-- 整合hive 用户代理设置 --&gt;&lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.hosts&lt;/name&gt; &lt;value&gt;*&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.groups&lt;/name&gt; &lt;value&gt;*&lt;/value&gt;&lt;/property&gt;&lt;!-- 文件系统垃圾桶保存时间 --&gt;&lt;property&gt; &lt;name&gt;fs.trash.interval&lt;/name&gt; &lt;value&gt;1440&lt;/value&gt;&lt;/property&gt; 1234567#修改 hdfs-site.xml 文件 $ vim hdfs-site.xml &lt;!-- 设置SNN进程运行机器位置信息 --&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;slave1:9868&lt;/value&gt;&lt;/property&gt; 1234567891011121314151617181920212223242526272829303132333435#修改 mapred-site.xml 文件$ vim mapred-site.xml#添加如下内容&lt;!-- 设置MR程序默认运行模式： yarn集群模式 local本地模式 --&gt;&lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt;&lt;/property&gt;&lt;!-- MR程序历史服务地址 --&gt;&lt;property&gt; &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; &lt;value&gt;master:10020&lt;/value&gt;&lt;/property&gt; &lt;!-- MR程序历史服务器web端地址 --&gt;&lt;property&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;master:19888&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt; &lt;value&gt;HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;mapreduce.map.env&lt;/name&gt; &lt;value&gt;HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;mapreduce.reduce.env&lt;/name&gt; &lt;value&gt;HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;&lt;/value&gt;&lt;/property&gt; 12345678910111213141516171819202122232425262728293031323334353637#修改 yarn-site.xml 文件$ vim yarn-site.xml#添加如下内容&lt;!-- 设置YARN集群主角色运行机器位置 --&gt;&lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;master&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt;&lt;/property&gt;&lt;!-- 是否将对容器实施物理内存限制 --&gt;&lt;property&gt; &lt;name&gt;yarn.nodemanager.pmem-check-enabled&lt;/name&gt; &lt;value&gt;false&lt;/value&gt;&lt;/property&gt;&lt;!-- 是否将对容器实施虚拟内存限制。 --&gt;&lt;property&gt; &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt; &lt;value&gt;false&lt;/value&gt;&lt;/property&gt;&lt;!-- 开启日志聚集 --&gt;&lt;property&gt; &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;!-- 设置yarn历史服务器地址 --&gt;&lt;property&gt; &lt;name&gt;yarn.log.server.url&lt;/name&gt; &lt;value&gt;http://master:19888/jobhistory/logs&lt;/value&gt;&lt;/property&gt;&lt;!-- 历史日志保存的时间 7天 --&gt;&lt;property&gt; &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt; &lt;value&gt;604800&lt;/value&gt;&lt;/property&gt; 123456#修改 workers 文件$ vim workers#将 workers 里的 localhost 删除，添加如下内容master slave1 slave2 （3）分发1234#master 节点将 hadoop 传输到 slave1 和 slave2$ cd /export/server$ scp -r hadoop-3.3.0 root@slave1:$PWD$ scp -r hadoop-3.3.0 root@slave2:$PWD 123456#将 hadoop 添加到环境变量vim /etc/profile#在文件内添加如下内容# hadoop 环境变量 export HADOOP_HOME=/export/server/hadoop-3.3.0export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin 123456789101112131415#配置 slave1 和 slave2 的 hadoop 环境变量（注：和上方 master 的配置方法一样）#配置完成后，在 master slave1 和slave2 三台主机创建软连接$ cd /export/server $ ln -s hadoop-3.3.0/ hadoop#重新加载环境变量文件$ source /etc/profile#在 master 主节点进行 Hadoop 集群启动 格式化 namenode（只有首次启动需要格式化）$ hdfs namenode -format#等待初始化完成后，使用脚本一键起动$ start-all.sh #起动后，输入jps查看进程号$ jps#进程查看完毕后可进入到 WEB 界面#HDFS集群的界面网站是:http://master:9870/#YARN集群的界面网站是:http://master:9870/ 4.安装zookeeper（1）下载安装包本文使用的 zookeeper 是3.7.0版本zookeeper3.7.0安装包下载注意：下载的是后缀为 .tar.gz 的包,安装包需要3.7版本网上，否者后续Kafka配置会出现问题 （2）在主机 master 上安装 zookeeper12345678#上传本地下载好的 apache-zookeeper-3.7.0-bin.tar.gz 上传到 /export/server 并解压文件$ tar -zxvf apache-zookeeper-3.7.0-bin.tar.gz#修改配置文件,进入到 /export/server 目录下$ cd /export/server/#在 /export/server 目录下创建 zookeeper 软连接$ ln -s apache-zookeeper-3.7.0-bin/ zookeeper#进入到 zookeeper 目录下$ cd zookeeper 12345678910111213141516#进入到 zookeeper 下的 conf 文件内$ cd /export/server/zookeeper/conf/ #将 zoo_sample.cfg 文件复制为新文件 zoo.cfg$ cp zoo_sample.cfg zoo.cfg#在 zoo.cfg 文件内添加如下内容#Zookeeper的数据存放目录dataDir=/export/server/zookeeper/zkdatas# 保留多少个快照autopurge.snapRetainCount=3# 日志多少小时清理一次autopurge.purgeInterval=1# 集群中服务器地址server.1=master:2888:3888 server.2=slave1:2888:3888 server.3=slave2:2888:3888 1234567#进入 /export/server/zookeeper/zkdatas 目录在此目录下创建 myid 文件,将 1 写入进去$ cd /export/server/zookeeper/zkdata$ mkdir myid$ echo &#x27;1&#x27; &gt; myid#查看是否成功写入$ vim myid#出现数字1即为成功 （3）分发12345#master 节点将 zookeeper 传输到 slave1 和 slave2$ cd /export/server$ scp -r /export/server/zookeeper/ slave1:$PWD$ scp -r /export/server/zookeeper/ slave2:$PWD#推送完成后将 slave1 和 slave2 的 /export/server/zookeeper/zkdatas/ 文件夹下的 myid中的内容分别改为 2 和 3 123456#在 slave1 节点上$ cd /export/server/zookeeper/zkdatas/$ echo &#x27;2&#x27; &gt; myid#查看是否成功写入$ vim myid#出现数字2即为成功 123456#在 slave2 节点上$ cd /export/server/zookeeper/zkdatas/$ echo &#x27;3&#x27; &gt; myid#查看是否成功写入$ vim myid#出现数字3即为成功 123456#将 zookeeper 添加到环境变量vim /etc/profile#在文件内添加如下内容# zookeeper 环境变量 export ZOOKEEPER_HOME=/export/server/zookeeper export PATH=$PATH:$ZOOKEEPER_HOME/bin 12345678910#配置 slave1 和 slave2 的 hadoop 环境变量（注：和上方 master 的配置方法一样）#重新加载环境变量文件$ source /etc/profile#三台机器分别进入 /export/server/zookeeper/bin 目录下启动 zkServer.sh 脚本$ cd /export/server/zookeeper/bin$ zkServer.sh start#查看 zookeeper 的状态$ zkServer.sh status#也可以通过jps查看zookeeper的进程$ jps 以上,就是Kafka基础环境的配置,接下来会带来 Kafka命令行操作","categories":[{"name":"工具","slug":"工具","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://example.com/tags/hexo/"},{"name":"主题","slug":"主题","permalink":"http://example.com/tags/%E4%B8%BB%E9%A2%98/"},{"name":"搭建","slug":"搭建","permalink":"http://example.com/tags/%E6%90%AD%E5%BB%BA/"}]},{"title":"Kafka命令行操作 ","slug":"Kafka命令行操作","date":"2022-08-28T04:32:29.726Z","updated":"2023-02-16T14:09:55.901Z","comments":true,"path":"2022/08/28/Kafka命令行操作/","link":"","permalink":"http://example.com/2022/08/28/Kafka%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%93%8D%E4%BD%9C/","excerpt":"","text":"注意：以下操作需要完成 Kafka 基础环境配置。具体配置移步到Kafka基础环境配置 1.Kafka安装本文使用的 Kafka 是2.11-2.0.0版本Kafka 3.2.0 安装包下载注意：下载要注意 Kafka 的版本，同时选择后缀为 .tar.gz的安装包**本文使用的安装包是 kafka_2.11-2.0.0.tgz ** 1234567#把本地下载好的 kafka_2.11-2.0.0.tgz安装包上传到 /export/server 并解压$ cd /export/server/$ tar -zxvf kafka_2.11-2.0.0.tgz -C /export/server/#建立软连接$ ln -s /export/server/kafka_2.11-2.0.0.tgz /export/server/kafka#master 节点节点进入 /export/server/kafka/config 修改以下配置文件$ cd /export/server/kafka/config 编辑文件 server.properties12345678910111213141516171819$ vim server.properties#21 行内容 broker.id=0 为依次增长的:0、1、2、3、4,集群中唯一 id 从0开始，每台不能重复#（注：此处为master节点，不用修改）$broker.id=0#31 行内容 #listeners=PLAINTEXT://:9092 取消注释，内容改为$ listeners=PLAINTEXT://master:9092#59 行内容 log.dirs=/tmp/kafka-logs 为默认日志文件存储的位置，改为$log.dirs=/export/server/data/kafka-log#63 行内容为 num.partitions=1 是默认分区数$ num.partitions=1#121 行内容 zookeeper.connect=localhost:2181 修改为$zookeeper.connect=master:2181,slave1:2181,slave2:2181#126 行内容 group.initial.rebalance.delay.ms=0 修改为$ group.initial.rebalance.delay.ms=3000 2.分发1234#master 节点分发 kafka 安装文件夹 到 slave1 和 slave2 上$ cd /export/server$ scp -r /export/server/kafka_2.11-2.0.0.tgz/ slave1:$PWD$ scp -r /export/server/kafka_2.11-2.0.0.tgz/ slave2:$PWD 123456#配置 kafka 环境变量，master、slave1、slave2都需要进行操作$ vim /etc/profile#文件最后添加以下内容# kafka 环境变量 $ export KAFKA_HOME=/export/server/kafka $ export PATH=$PATH:$KAFKA_HOME/bin 12#三台机器操作完成重新加载环境变量$ source /etc/profile 12345#在 slave1 节点上$ cd /export/server$ ln -s /export/server/kafka_2.11-2.0.0/ kafka#进入 /export/server/kafka/config 修改以下配置文件$ cd /export/server/kafka/config 12345$ vim server.properties#将文件 server.properties 的第 21 行的 broker.id=0 修改为 $ broker.id=1 #将文件 server.properties 的第 31 行的 listeners=PLAINTEXT://master:9092 修改为$ listeners=PLAINTEXT://slave1:9092 12345#在 slave2 节点上$ cd /export/server$ ln -s /export/server/kafka_2.11-2.0.0/ kafka#进入 /export/server/kafka/config 修改以下配置文件$ cd /export/server/kafka/config 12345$ vim server.properties#将文件 server.properties 的第 21 行的 broker.id=0 修改为 $ broker.id=2 #将文件 server.properties 的第 31 行的 listeners=PLAINTEXT://master:9092 修改为$ listeners=PLAINTEXT://slave2:9092 以上操作完成回到 master 节点 启动 kafka注意：启动 kafka 需要启动 zookeeper 123#启动 kafka,三台机器同时执行$ kafka-server-start.sh -daemon /export/server/kafka/config/server.properties#启动完成后通过jps查看其状态 设置脚本便于启动三台机器1234567891011121314151617181920212223242526272829#进入到bin目录下$cd /root/bin# 创建并编辑名为kafka-all.sh的脚本$ vim kafka-all.sh#在文件内添加如下内容#!/bin/bashif [ $# -eq 0 ] ;thenecho &quot;please input param:start stop&quot;elseif [ $1 = start ] ;then echo &quot;$&#123;1&#125;ing master&quot;ssh master &quot;source /etc/profile;kafka-server-start.sh -daemon /export/server/kafka/config/server.properties&quot;for i in &#123;1..2&#125;do echo &quot;$&#123;1&#125;ing slave$&#123;i&#125;&quot; ssh slave$&#123;i&#125; &quot;source /etc/profile;kafka-server-start.sh -daemon /export/server/kafka/config/server.properties&quot;donefiif [ $1 = stop ];thenecho &quot;$&#123;1&#125;ping master &quot;ssh master &quot;source /etc/profile;kafka-server-stop.sh&quot;for i in &#123;1..2&#125;do echo &quot;$&#123;1&#125;ping slave$&#123;i&#125;&quot; ssh slave$&#123;i&#125; &quot;source /etc/profile;kafka-server-stop.sh&quot;donefifi 3.Kafka命令行操作（1）创建topic1$ kafka-configs.sh --create --topic tpc_1 --partitions 2 --replication-factor2 --zookeeper node1:2181 （2）删除topic1$ kafka-topics.sh --delete --topic tpc_1 --zookeeper node1:2181 （3）查看topic1234#查看当前系统中的所有topic$ kafka-topics.sh --zookeeper node1:2181-list#查看topic详细信息$ kafka-configs.sh --create --topic tpc_1 --zookeeper node1:2181--replication-factor0:1 （4）增加分区数1kafka-topics.sh --alter --topic tpc_1 --partitions 3 --zookeeper node1:2181 （5）动态配置topic参数12345#通过管理命令，可以为已创建的topic增加，修改，删除 topic level 参数#添加，修改配置参数$ kafka-configs.sh --zookeeper node1:2181 --entity-type topics --entity-name tpc_1 --alter --add-config compression.type=gzip#删除配置参数$ kafka-configs.sh --zookeeper node1:2181 --entity-type topics --entity-name tpc_1 --alter --delete-config compression.type","categories":[{"name":"工具","slug":"工具","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://example.com/tags/hexo/"},{"name":"主题","slug":"主题","permalink":"http://example.com/tags/%E4%B8%BB%E9%A2%98/"},{"name":"搭建","slug":"搭建","permalink":"http://example.com/tags/%E6%90%AD%E5%BB%BA/"}]},{"title":"Kafka API使用方法","slug":"Kafka API使用方法","date":"2022-08-28T04:32:29.715Z","updated":"2023-02-16T14:07:31.032Z","comments":true,"path":"2022/08/28/Kafka API使用方法/","link":"","permalink":"http://example.com/2022/08/28/Kafka%20API%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/","excerpt":"","text":"1.生产者API 一个正常的生产逻辑需要具备以下几个步骤: 配置生产者客户端参数及创建相应的生产者实例 构建待发送的消息 发送消息 关闭生产者实例 acks 模式：取值0,1，-1（all）； 0：Producer往集群发送数据不需要等到集群的返回，不确保信息发送成功，安全性最低但是效率最高 1：Producer往集群发送数据只要Leader成功写入消息就能发送下一条，只确保Leader接收成功 -1（all）：确保Leader发送成功，所有的副本也发送成功，过程虽然缓慢但是安全性最高； 生产者API采用默认分区方式将消息散列的发送到各个分区当中； 123456789101112131415161718192021222324252627$ Properties props = new Properties()配置生产者客户端参数$ props.put(&quot;bootstrap.servers&quot;, &quot;node1:9092,node2:9092, node3:9092&quot;)设置kafka集群的地址$props.put(“retries”, 3)失败重试次数，失败后会自动重试（可恢复/不可恢复）→(有可能会造成数据的乱序)$props.put(“batch.size”, 10)数据发送的批次大小，提高效率/吞吐量大会数据延迟$props.put(&quot;linger.ms&quot;, 10000)消息在缓冲区保留的时间,超过设置的值就会被提交到服务端$props.put(&quot;max.request.size&quot;,10)数据发送请求的最大缓存数$props.put(“buffer.memory”, 10240)整个 Producer 用到总内存的大小,如果缓冲区满了会提交数据到服务端//buffer.memory要大于batch.size,否则会报申请内存不足的错误降低阻塞的可能性$props.put(&quot;key.serializer&quot;,&quot;org.apache.kafka.common. serialization.StringSerializer&quot;)key-value序列化器$props.put(“value.serializer”, “org.apache.kafka.common. serialization.StringSerializer”)字符串最好 Kafka 生产者客户端 KatkaProducer 中的三个必要参数bootstrap.servers 、key.serializer 、value.serializer； 生产者api参数发送方式（发后即忘）: 发后即忘,它只管往 Kafka 发送,并不关心消息是否正确到达。 在大多数情况下,这种发送方式没有问题; 不过在某些时候(比如发生不可重试异常时)会造成消息的丢失; 这种发送方式的性能最高,可靠性最差。 生产者api参数发送方式（同步发送）: producer.send(rcd).get( ); &#x2F;&#x2F;一旦调用get方法，就会阻塞 Future future &#x3D; Callable.run( )&#x2F;&#x2F;有返回值，future.get（） runnable.run（）&#x2F;&#x2F;无返回值 生产者api参数发送方式（异步发送）； 回调函数会在producer收到 ack 时调用,为异步调用, 该方法有两个参数,分别是RecordMetadata和Exception,如果Exception为null,说明消息发送成功,如果 Exception不为null,说明消息发送失败; 注意：消息发送失败会自动重试,不需要我们在回调函数中手动重试。 生产者原理:12345678910111213141516（1）一个生产者客户端由两个线程协调运行,这两个线程分别为主线程和 Sender 线程；（2）在主线程中由kafkaProducer创建消息,然后通过可能的拦截器、序列化器和分区器的作用之后缓存到消息累加器(RecordAccumulator, 也称为消息收集器)中；（3）Sender线程负责从RecordAccumulator 获取消息并将其发送到Kafka中；（4）RecordAccumulator 主要用来缓存消息以便 Sender 线程可以批量发送, 进而减少网络传输的资源消耗以提升性能；（5）RecordAccumulator 缓存的大小可以通过生产者客户端参数 buffer.memory 配置, 默认值为 33554432B ,即 32M；（6）主线程中发送过来的消息都会被迫加到 RecordAccumulator 的某个双端队列( Deque )中, RecordAccumulator 内部为每个分区都维护了一个双端队列,即 Deque&lt;ProducerBatch&gt;。消息写入缓存时,追加到双端队列的尾部；（7）Sender 读取消息时,从双端队列的头部读取；（8）ProducerBatch是指一个消息批次; 与此同时,会将较小的 ProducerBatch凑成一个较大ProducerBatch ,也可以减少网络请求的次数以提升整体的吞吐量；（9）ProducerBatch大小和batch.size参数也有着密切的关系；（10）当一条消息(ProducerRecord ) 流入RecordAccumulator 时,会先寻找与消息分区所对应的双端队列(如果没有则新建),再从这个双端队列的尾部获取一个ProducerBatch (如果没有则新建),查看ProducerBatch 中是否还可以写入这个ProducerRecord,如果可以写入,如果不可以则需要创建一个新的 Producer Batch；（11）在新建ProducerBatch 时评估这条消息的大小是否超过batch.size 参数大小, 如果不超过, 那么就以batch.size参数的大小来创建ProducerBatch；（12）Sender 从 RecordAccumulator 获取缓存的消息之后,会进一步将&lt;分区,Deque&lt;Producer Batch&gt;&gt;的形式转变成&lt;Node,List&lt; ProducerBatch&gt;的形式,其中 Node 表示 Kafka 集群 broker 节点；（13）对于网络连接来说,生产者客户端是与具体 broker 节点建立的连接,也就是向具体的 broker 节点发送消息,而并不关心消息属于哪一个分区；（14）而对于 KafkaProducer 的应用逻辑而言,我们只关注向哪个分区中发送哪些消息,所以在这里需要做一个应用逻辑层面到网络 I/O 层面的转换；（15）在转换成&lt;Node, List&lt;ProducerBatch&gt;&gt;的形式之后, Sender 会进一步封装成&lt;Node,Request&gt; 的形式, 这样就可以将 Request 请求发往各个 Node 了,这里的 Request 是 Kafka 各种协议请求；（16）请求在从sender 线程发往 Kafka 之前还会保存到 InFlightRequests中,InFlightRequests 保存对象的具体形式为 Map&lt;Nodeld, Deque&lt;request&gt;&gt;,它的主要作用是缓存了已经发出去但还没有收到服务端响应的请求(Nodeld 是一个 String 类型,表示节点的 id 编号)。 重要的生产者参数1234567（1）max.request.size：这个参数用来限制生产者客户端能发送的消息的最大值,默认值为 1048576B ,即 lMB 一般情况下,这个默认值就可以满足大多数的应用场景了。（2）compression.type：用来指定消息的压缩方式,默认值为“none &quot;,即默认情况下,消息不会被压缩还可以配置为 &quot;gzip&quot;,&quot;snappy&quot; 和 &quot;lz4&quot;，服务端也有压缩参数，先解压，再压缩对消息进行压缩可以极大地减少网络传输、降低网络 I/O,从而提高整体的性能。（3）retries 和 retry.backoff.ms：retries 参数用来配置生产者重试的次数,默认值为 0,即在发生异常的时候不进行任何重试动作。重试还和另一个参数 retry.backoff.ms 有关,这个参数的默认值为 100,它用来设定两次重试之间的时间间隔,避免无效的频繁重试。（4）batch.size：每个 Batch 要存放 batch.size 大小的数据后,才可以发送出去。比如说 batch.size 默认值是 16KB,那么里面凑够 16KB 的数据才会发送。（5）linger.ms：用来指定生产者发送 ProducerBatch 之前等待更多消息( ProducerRecord )加入ProducerBatch 时间,默认值为 0。（6）enable.idempotence：是否开启幂等性功能,详见后续原理加强。（7）partitioner.classe：用来指定分区器,默认:org.apache.kafka. internals.DefaultPartitioner --》用hashcode分。 2.消费者API 一个正常的消费逻辑需要具备以下几个步骤： 配置消费者客户端参数 创建相应的消费者实例 订阅主题 拉取消息并消费 提交消费位移offest 关闭消费者实例 subscribe重载方法： 前面两种通过集合的方式订阅一到多个topic Public 、void、subscribe（collection、topics、ConsumerRebalanceListenerlistener） Public、void、subscribe(collectiontopics) 后两种主要是采用正则的方式订阅一到多个topics public voidSubscribe（Pattern pattern，ConsumerRebalancelistener listener）Publicviod void subscribe(Patternopattern) 正则方式订阅主题(只要是tpc数字的形式，三位数字以内如果消费者采用的是正则表达式的方式(subscribe(Pattern))订阅。在之后的过程中，如果有人又创建了新的主题，并且主题名字与正表达式相匹配那么这个消费者就可以消费到新添加的主题中的消息。如果应用程序需要消费多个主题，并可以处理不同的类型，那么这种订阅方式就很有效。利用正则表达式订阅主题，可实现动态订阅； assign订阅主题消费者不仅可以通过KafkaConsumersubscribe()方法订阅主题，还可直接订阅某些主题的指定分区:在KafkaConsumer中提供了assign方法来实现这些功能，此方法的具体定义如下:public void assign(Collectionpartitions);这个方法只接受参数partitions用来指定需要订阅的分区集合示例如下:consumer.assign(Arrays.asList(new TopicPartition (“tpc_1”,0),new TopicPartition(“tpc 2,1))); subscribe与assign的区别 通过subscribe0)方法订阅主题具有消费者自动再均衡功能:在多个消费者的情况下可以根据分区分配策略来自动分配各个消费者与分区的关系。当消费组的消费者增加或减少时，分区分配关系会自动调整以实现消费负载均衡及故障自动转移。 assign方法订阅分区时，是不具备消费者自动均衡的功能的;其实这一点从assign0方法参数可以看出端倪，两种类型subscribe都有 ConsumerRebalanceListener类型参数的方法。而assign()方法却没有。 取消订阅 可以使用KafkaConsumer中的unsubscribe)方法采取消主题的订阅.这个方法既可以取消通过subscribe(Collection)方式实现的订阅; 也可以取消通过subscribe(Pattem)方式实现的订阅，还可以取消通过assign(Collection)方式实现的订阅。 如果将subscribe(Collection)或assign(Collection)集合参数设置为空集合，作用与unsubscribe0)方法相同。如下示例中三行代码的效果相同: consumer.unsubscribe0;consumer.subscribe(new ArrayListO)consumer.assign(new ArrayListO)； 3.Topic管理API一般情况下，我们习惯用kafka-topic.sh来进行管理主题，如果需要将管理类的功能集成用到公司内部系统中，就需要用到以API进行实现。这种调用API方式实现管理主要利用KafkaAdminClient工具类。 KafkaAdminClient不仅可以用来管理broker，配置和ACI（Access Control List，管理主题）它提供了以下方法：12345678创建主题：CreateTopics（Collecnoo&lt;New Topic&gt;）new topics)删除主题：DeleteTopicsResult delete Topres(Collecnoo&lt;String&gt;topics)列出所有可用主题：ListTopicsResult listTopics()查看主题的信息：DescribeTopicsRrsult(describeTopics(Collection&lt;String&gt;topicNames)查询配置信息：DescribeConfigsResult describeConfigs(Collection&lt;ConfigResource&gt;resources)修改配置信息：AlterConfigsResultalterConfigs(Map&lt;ConfigResource Config&gt;configs)增加分区：CreatePartionsResult createPartition(Map&lt;String.New[artitions&gt;new Partitions)构建一个KafkaAdminClient AdminClient adminClient=KafkaAdminClient.create(props)； 列出主题ListTopicsResult listTopicsResult&#x3D;adminClient.listTopics();Settopic&#x3D;listTopicsResult.names().get();System.out.rintln(topics); 查看主题信息123456DescribeTopicsResult describeTopicsResult=adminClient.describeTopics(Arrays.asList(“tpc_4”,”tpc_3”));Map&lt;String, TopicDescription&gt;res=describeTopicsResult.all().get();Set&lt;String&gt;ksets=res.keySet();for(String k : ksets)&#123; System.out.[rintln(res.get(k));&#125; 创建主题123456789101112131415161718192021222324252627282930313233//参数配置Properties props = new Properties();Props.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG,”node1:9092,node2:9092,node:9092);Props.put(AdminClientConfig.REQUEST_TIMEOUT_MS_CONFIG,3000);//创建admin client对象AdminClient adminClient=KafkaAdminClient.create(props）；//由服务端controller自行分配分区及副本所生brokerNewTopic tpc_3=new NewTopic(“tpc_3”,2.(shot)1);//手动制定分区及副本的broker分配HashMap&lt;IInteger,List&lt;Integer&gt;&gt;replicaAssignments=new HashMap&lt;&gt;();//分区0，分配到broker（），broker1replicaAssignments.put(0,Arrays,asList(0,1));//分区1，分配到broker（），broker2replicaSssignments.put(0,Arrays.asList(0,1));NewTopic tpc_4=new NewTopic(“tpc_4”,re[licaAssignments);AdminClient adminClient=KafkaAdminClient.create(props);//由服务端controller 自行分配分区及副本所在brokerN额外Topictpc_3=newNewTopic(“tpc3”,2,(shot)1);//手动指定分区及副本的broker分配HashMap&lt;Integer,List&lt;Integer&gt;&gt;replicaAssignments=new HashMap&lt;&gt;();//分区0，分配到broker（），broker1replicaAssignments.put(0,Arrays.asList(0,1));//分区1，分配到broker（）broker2replicaAssignments.put(0,Arrays.asList(0,1))NewTopic tpc_4=new NewTopic(“tpc_4”,replicaAssignments);CreateTo[icsResult result=adminClient.createTopics(Arrays.asList(tpc_3.tpc4));//从future中等待服务端返回try&#123; result.all().get();&#125;catch(Exception e)&#123;e.printStackTrace();&#125;adminClient.close();","categories":[{"name":"工具","slug":"工具","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://example.com/tags/hexo/"},{"name":"主题","slug":"主题","permalink":"http://example.com/tags/%E4%B8%BB%E9%A2%98/"},{"name":"搭建","slug":"搭建","permalink":"http://example.com/tags/%E6%90%AD%E5%BB%BA/"}]},{"title":"Spark HA & Yarn配置","slug":"Spark HA & Yarn配置","date":"2022-05-22T03:06:37.000Z","updated":"2022-05-24T09:35:11.714Z","comments":true,"path":"2022/05/22/Spark HA & Yarn配置/","link":"","permalink":"http://example.com/2022/05/22/Spark%20HA%20&%20Yarn%E9%85%8D%E7%BD%AE/","excerpt":"","text":"一、Spark-Standalone-HA模式Spark Standalone集群是Master-Slaves架构的集群模式,和大部分的Master-Slaves结构集群一样,存在着Master 单点故障(SPOF)的问题。简单理解为，spark-Standalone 模式下为 master 节点控制其他节点，当 master 节点出现故障时，集群就不可用了。 spark-Standalone-HA 模式下master 节点不固定，当一个宕机时，立即换另一台为 master 保障不出现故障。 1.此处因为先前配置时的 zookeeper 版本和 spark 版本不太兼容，导致此模式有故障，需要重新下载配置新的版本的 zookeeper2.配置之前需要删除三台主机的 旧版 zookeeper 以及 对应的软连接3.在master节点上重新进行前面配置的 zookeeper 操作 12345678910上传apache-zookeeper-3.7.0-bin.tar.gz 到/export/server/目录下 并解压文件 在 /export/server 目录下创建软连接 进入 /export/server/zookeeper/conf/ 将 zoo_sample.cfg 文件复制为新文件 zoo.cfg 接上步给 zoo.cfg 添加内容 进入 /export/server/zookeeper/zkdatas 目录在此目录下创建 myid 文件，将 1 写入进 去将 master 节点中 /export/server/zookeeper-3.7.0 路径下内容推送给slave1 和 slave2 推送成功后，分别在 slave1 和 slave2 上创建软连接 接上步推送完成后将 slave1 和 slave2 的 /export/server/zookeeper/zkdatas/文件夹 下的 myid 中的内容分别改为 2 和 3 配置环境变量： 因先前配置 zookeeper 时候创建过软连接且以 ’zookeeper‘ 为路径，所以不用配置环境变量，此 处也是创建软连接的方便之处. 4.进入 &#x2F;export&#x2F;server&#x2F;spark&#x2F;conf 文件夹 修改 spark-env.sh 文件内容 123cd /export/server/spark/conf vim spark-env.sh 5.为 83 行内容加上注释，此部分原为指定 某台主机 做 master ，加上注释后即为 任何主机都可以做 master 12345结果显示： ...... 82 # 告知Spark的master运行在哪个机器上 83 # export SPARK_MASTER_HOST=master ......... 文末添加内容 123SPARK_DAEMON_JAVA_OPTS=&quot;-Dspark.deploy.recoveryMode=ZOOKEEPER - # spark.deploy.recoveryMode 指定HA模式 基于Zookeeper实现Dspark.deploy.zookeeper.url=master:2181,slave1:2181,slave2:2181 - # 指定Zookeeper的连接地址Dspark.deploy.zookeeper.dir=/spark-ha&quot; # 指定在Zookeeper中注册临时节点的路径 6.分发 spark-env.sh 到 salve1 和 slave2 上 123scp spark-env.sh slave1:/export/server/spark/conf/ scp spark-env.sh slave2:/export/server/spark/conf/ 7.启动之前确保 Zookeeper 和 HDFS 均已经启动 启动集群: 1234567# 在 master 上 启动一个master 和全部worker /export/server/spark/sbin/start-all.sh # 注意, 下面命令在 slave1 上执行 启动 slave1 上的 master 做备用 master /export/server/spark/sbin/start-master.shjps #查看是否启动 8.访问 WebUI 界面 123http://master:8081/http://slave1:8082/ 9.此时 kill 掉 master 上的 master 假设 master 主机宕机掉 12# master主机 master 的进程号 kill -9 41589 10.访问 slave1 的 WebUI 1http://slave1:8082/ 11.进行主备切换的测试 提交一个 spark 任务到当前 活跃的 master上 : 123/export/server/spark/bin/spark-submit --master spark://master:7077 /export/server/spark/examples/src/main/python/pi.py 1000 12.复制标签 kill 掉 master 的 进程号 再次访问 master 的 WebUI 123http://master:8081/网页访问不了！ 13.再次访问 slave1 的 WebUI 1http://slave1:8082/ 14.可以看到当前活跃的 master 提示信息 123/export/server/spark/bin/spark-submit --master同样可以输出结果 当新的 master 接收集群后, 程序继续运行, 正常得到结果. 12结论 HA模式下, 主备切换 不会影响到正在运行的程序.最大的影响是 会让它中断大约30秒左右 二、Spark On YARN模式在已有YARN集群的前提下在单独准备Spark StandAlone集群,对资源的利用就不高.Spark On YARN, 无需部署Spark集群, 只要找一台服务器, 充当Spark的客户端 1.保证 HADOOP_CONF_和 DIR_YARN_CONF_DIR 已经配置在 spark-env.sh 和环境变量中 （注: 前面配置spark-Standlone 时已经配置过此项了） 123456spark-env.sh 文件部分显示：··· 77 ## HADOOP软件配置文件目录，读取HDFS上文件和运行YARN集群 78 HADOOP_CONF_DIR=/export/server/hadoop/etc/hadoop 79 YARN_CONF_DIR=/export/server/hadoop/etc/hadoop···· 2.链接到 YARN 中（注: 交互式环境 pyspark 和 spark-shell 无法运行 cluster模式） 12345bin/pyspark --master yarn --deploy-mode client|cluster# --deploy-mode 选项是指定部署模式, 默认是 客户端模式 # client就是客户端模式 # cluster就是集群模式 # --deploy-mode 仅可以用在YARN模式下 1bin/spark-shell --master yarn --deploy-mode client|cluster 1bin/spark-submit --master yarn --deploy-mode client|cluster /xxx/xxx/xxx.py 参数 3.park-submit 和 spark-shell 和 pyspark的相关参数 123456- bin/pyspark: pyspark解释器spark环境 - bin/spark-shell: scala解释器spark环境 - bin/spark-submit: 提交jar包或Python文件执行的工具 - bin/spark-sql: sparksql客户端工具这4个客户端工具的参数基本通用.以spark-submit 为例: bin/spark-submit --master spark://master:7077 xxx.py 4.启动 YARN 的历史服务器 123cd /export/server/hadoop-3.3.0/sbin ./mr-jobhistory-daemon.sh start historyserver 5.访问WebUI界面 1http://master:19888/ client 模式测试 123SPARK_HOME=/export/server/spark $&#123;SPARK_HOME&#125;/bin/spark-submit --master yarn --deploy-mode client --driver-memory 512m --executor-memory 512m --num-executors 1 --total- executor-cores 2 $&#123;SPARK_HOME&#125;/examples/src/main/python/pi.py 3 cluster 模式测试 12345SPARK_HOME=/export/server/spark $&#123;SPARK_HOME&#125;/bin/spark-submit --master yarn --deploy-mode cluster --driver- memory 512m --executor-memory 512m --num-executors 1 --total-executor-cores 2 --conf &quot;spark.pyspark.driver.python=/root/anaconda3/bin/python3&quot; --conf &quot;spark.pyspark.python=/root/anaconda3/bin/python3&quot; $&#123;SPARK_HOME&#125;/examples/src/main/python/pi.py 3","categories":[],"tags":[]},{"title":"Spark-local& stand-alone配置","slug":"Spark local& stand-alone配置","date":"2022-05-22T03:06:37.000Z","updated":"2022-05-23T09:48:11.092Z","comments":true,"path":"2022/05/22/Spark local& stand-alone配置/","link":"","permalink":"http://example.com/2022/05/22/Spark%20local&%20stand-alone%E9%85%8D%E7%BD%AE/","excerpt":"","text":"一、Spark-local模式本地模式(单机) 本地模式就是以一个独立的进程,通过其内部的多个线程来模拟整个Spark运行时环境 Anaconda On Linux 安装 (单台服务器脚本安装) 1.安装上传安装包: 资料中提供的Anaconda3-2021.05-Linux-x86_64.sh文件到Linux服务器上安装位置在 &#x2F;export&#x2F;server: 1234cd /export/server# 运行文件sh Anaconda3-2021.05-Linux-x86_64.sh 123456789101112过程显示：···#出现内容选 yesPlease answer &#x27;yes&#x27; or &#x27;no&#x27;:&#x27; &gt;&gt;&gt; yes···# 出现添加路径：/export/server/anaconda3···[/root/anaconda3] &gt;&gt;&gt; /export/server/anaconda3 PREFIX=/export/server/anaconda3··· 2.安装完成后, 退出终端， 重新进来: 1exit 1234结果显示： #看到这个Base开头表明安装好了.base是默认的虚拟环境. Last login: Tue Mar 15 15:28:59 2022 from 192.168.88.1 (base) [root@master ~]# 3.在虚拟环境内安装包 （有WARNING不用管） 1pip install pyhive pyspark jieba -i https://pypi.tuna.tsinghua.edu.cn/simple 4.spark 安装 将文件上传到 &#x2F;export&#x2F;server 里面 ，解压 1234cd /export/server# 解压 tar -zxvf spark-3.2.0-bin-hadoop3.2.tgz -C /export/server/ 建立软连接 1ln -s /export/server/spark-3.2.0-bin-hadoop3.2 /export/server/spark 添加环境变量 SPARK_HOME: 表示Spark安装路径在哪里 PYSPARK_PYTHON: 表示Spark想运行Python程序, 那么去哪里找python执行器 JAVA_HOME: 告知Spark Java在哪里 HADOOP_CONF_DIR: 告知Spark Hadoop的配置文件在哪里 HADOOP_HOME: 告知Spark Hadoop安装在哪里 123456789101112131415161718192021222324252627vim /etc/profile内容：···注：此部分之前配置过，此部分不需要在配置#JAVA_HOME export JAVA_HOME=/export/server/jdk1.8.0_241 export PATH=$PATH:$JAVA_HOME/bin export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar#HADOOP_HOMEexport HADOOP_HOME=/export/server/hadoop-3.3.0 export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin#ZOOKEEPER_HOMEexport ZOOKEEPER_HOME=/export/server/zookeeper export PATH=$PATH:$ZOOKEEPER_HOME/bin·····#将以下部分添加进去#SPARK_HOME export SPARK_HOME=/export/server/spark#HADOOP_CONF_DIR export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop#PYSPARK_PYTHON export PYSPARK_PYTHON=/export/server/anaconda3/envs/pyspark/bin/python 1234567vim .bashrc内容添加进去：#JAVA_HOME export JAVA_HOME=/export/server/jdk1.8.0_241#PYSPARK_PYTHON export PYSPARK_PYTHON=/export/server/anaconda3/envs/pyspark/bin/python 5.重新加载环境变量文件 12source /etc/profile source ~/.bashrc\\ 进入 &#x2F;export&#x2F;server&#x2F;anaconda3&#x2F;envs&#x2F;pyspark&#x2F;bin&#x2F; 文件夹 1cd /export/server/anaconda3/envs/pyspark/bin/ 开启 1./pyspark 6.查看WebUI界面 12#浏览器访问：http://master:4040/ 退出 1conda deactivate 二、Spark-Standalone模式Standalone模式(集群) Spark中的各个角色以独立进程的形式存在,并组成Spark集群环境Anaconda On Linux 安装 (单台服务器脚本安装 注：在 slave1 和 slave2 上部署)1.安装上传安装包: 资料中提供的Anaconda3-2021.05-Linux-x86_64.sh文件到Linux服务器上安装位置在 &#x2F;export&#x2F;server: 1234cd /export/server# 运行文件 sh Anaconda3-2021.05-Linux-x86_64.sh 123456789101112过程显示： ... # 出现内容选 yes Please answer &#x27;yes&#x27; or &#x27;no&#x27;:&#x27; &gt;&gt;&gt; yes···# 出现添加路径：/export/server/anaconda3···[/root/anaconda3] &gt;&gt;&gt; /export/server/anaconda3 PREFIX=/export/server/anaconda3··· 2.安装完成后, 退出终端， 重新进来: 1exit 1234结果显示： # 看到这个Base开头表明安装好了.base是默认的虚拟环境. Last login: Tue Mar 15 15:28:59 2022 from 192.168.88.1 (base) [root@master ~]# 3.在 node1节点上把 .&#x2F;bashrc 和 profile 分发给 node2 和 node3 1234567#分发 .bashrc : scp ~/.bashrc root@node2:~/ scp ~/.bashrc root@node3:~/#分发 profile : scp /etc/profile/ root@node2:/etc/ scp /etc/profile/ root@node3:/etc/ 4.创建虚拟环境 pyspark 基于 python3.8 1conda create -n pyspark python=3.8 5.切换到虚拟环境内 12345conda activate pyspark结果显示： (base) [root@master ~]# conda activate pyspark (pyspark) [root@master ~]# 6.在虚拟环境内安装包 （有WARNING不用管） 1pip install pyhive pyspark jieba -i https://pypi.tuna.tsinghua.edu.cn/simple 7.master 节点节点进入 &#x2F;export&#x2F;server&#x2F;spark&#x2F;conf 修改以下配置文件 1cd /export/server/spark/conf 8.将文件 workers.template 改名为 workers，并配置文件内容 1234567mv workers.template workers# localhost删除，内容追加文末：node1node2node3# 功能: 这个文件就是指示了 当前SparkStandAlone环境下, 有哪些worker 9.将文件 spark-env.sh.template 改名为 spark-env.sh，并配置相关内容 1234567891011121314151617181920212223242526272829303132333435mv spark-env.sh.template spark-env.shvim spark-env.sh文末追加内容：##设置JAVA安装目录 JAVA_HOME=/export/server/jdk## HADOOP软件配置文件目录，读取HDFS上文件和运行YARN集群 HADOOP_CONF_DIR=/export/server/hadoop/etc/hadoop YARN_CONF_DIR=/export/server/hadoop/etc/hadoop## 指定spark老大Master的IP和提交任务的通信端口 # 告知Spark的master运行在哪个机器上 export SPARK_MASTER_HOST=master # 告知sparkmaster的通讯端口 export SPARK_MASTER_PORT=7077 # 告知spark master的 webui端口 SPARK_MASTER_WEBUI_PORT=8080# worker cpu可用核数 SPARK_WORKER_CORES=1 # worker可用内存 SPARK_WORKER_MEMORY=1g # worker的工作通讯地址 SPARK_WORKER_PORT=7078 # worker的 webui地址 SPARK_WORKER_WEBUI_PORT=8081## 设置历史服务器 # 配置的意思是 将spark程序运行的历史日志 存到hdfs的/sparklog文件夹中 SPARK_HISTORY_OPTS=&quot;- Dspark.history.fs.logDirectory=hdfs://master:8020/sparklog/ - Dspark.history.fs.cleaner.enabled=true&quot; 10.开启 hadoop 的 hdfs 和 yarn 集群 123start-dfs.sh start-yarn.sh 11.在HDFS上创建程序运行历史记录存放的文件夹，同样 conf 文件目录下: 123hadoop fs -mkdir /sparklog hadoop fs -chmod 777 /sparklog 12.将 spark-defaults.conf.template 改为 spark-defaults.conf 并做相关配置 1234567891011mv spark-defaults.conf.template spark-defaults.conf vim spark-defaults.conf文末追加内容为： # 开启spark的日期记录功能 spark.eventLog.enabled true # 设置spark日志记录的路径 spark.eventLog.dir hdfs://master:8020/sparklog/ # 设置spark日志是否启动压缩 spark.eventLog.compress true 13.配置 log4j.properties 文件 将文件第 19 行的 log4j.rootCategory&#x3D;INFO, console 改为log4j.rootCategory&#x3D;WARN, console （即将INFO 改为 WARN 目的：输出日志, 设置级别为WARN 只输出警告和错误日志，INFO 则为输出所有信息，多数为无用信息） 123456789mv log4j.properties.template log4j.properties vim log4j.properties结果显示： ... 18 # Set everything to be logged to the console 19 log4j.rootCategory=WARN, console .... 14.node1节点分发 spark安装文件夹到node2和node3上 12345cd /export/server/scp -r /export/server/spark-3.2.0-bin-hadoop3.2/ node2:$PWD scp -r /export/server/spark-3.2.0-bin-hadoop3.2/ node3:$PWD 15.node 2和node3上做软连接 1ln -s /export/server/spark-3.2.0-bin-hadoop3.2 /export/server/spark 16.重新加载环境变量 1234567source /etc/profile进入 /export/server/spark/sbin 文件目录下 启动 start-history-server.shcd /export/server/spark/sbin ./start-history-server.sh 访问WebUI 界面 123浏览器访问： http://master:18080/ 18.启动Spark的Master和Worker进程 1234567891011121314# 启动全部master和worker sbin/start-all.sh # 或者可以一个个启动: # 启动当前机器的master sbin/start-master.sh # 启动当前机器的worker sbin/start-worker.sh# 停止全部 sbin/stop-all.sh # 停止当前机器的master sbin/stop-master.sh # 停止当前机器的worker sbin/stop-worker.sh 访问WebUI界面 123浏览器访问： http://master:8080/","categories":[],"tags":[]},{"title":"spark基础环境配置","slug":"“spark基础环境配置”","date":"2022-05-22T03:06:37.000Z","updated":"2022-05-23T03:02:50.295Z","comments":true,"path":"2022/05/22/“spark基础环境配置”/","link":"","permalink":"http://example.com/2022/05/22/%E2%80%9Cspark%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E2%80%9D/","excerpt":"","text":"一、基础环境配置1.编辑主机名（3台机器） 1vim /etc/hostname 2.Hosts映射（3台主机） 1vim /etc/hosts 3.关闭防火墙（3台机器） 12systemctl stop firewalld.service #关闭防火墙systemctl disable firewalld.service #禁止防火墙开启自启 4.设置ssh免密登录（node1执行-&gt;node1|node2|node3） 12ssh-keygen #4个回车生成公钥、私钥ssh-copy-id node1、ssh-copy-id node2、ssh-copy-id node3 5.集群时间同步（3台机器） 12yum-y install ntpdatentpdate ntp4.aliyun.com 6.创建统一工作目录（3台机器） 123mkdir -p /export/server/ #软件安装路径mkdir -p /export/data/ #数据存储路径mkdir -p /export/software/ #安装包存放路径 二、JDK安装1.编译环境软件安装目录 1mkdir-p /export/server/ 2.JDK1.8安装上传jdk-8u241-linux-x64.tar.gz到&#x2F;export&#x2F;server&#x2F;目录下并解压 1mkdir-p /export/server/ 3.配置环境变量 1234vim /etc/profile export JAVA_HOME=/export/server/jdk1.8.0_241export PATH=$PATH:$JAVA_HOME/binexport CLASSPATH=$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar 4.重新加载环境变量文件 1source /etc/profile 5.JDK配置后验证 1java -version 三、Hadoop安装配置1.解压上传文件（ hadoop-3.3.0-Centos7-64-with-snappy.tar.gz ）到&#x2F;export&#x2F;server&#x2F;目录下 1tar -zxvf hadoop-3.3.0-Centos7-64-with-snappy.tar.gz 2.修改配置文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122#修改hadoop-env.shcd /export/server/hadoop-3.3.0/etc/hadoopvim hadoop-env.sh #进入文件export JAVA_HOME=/export/server/jdk1.8.0_241 #文件最后添加export HDFS_NAMENODE_USER=rootexport HDFS_DATANODE_USER=rootexport HDFS_SECONDARYNAMENODE_USER=rootexport YARN_RESOURCEMANAGER_USER=rootexport YARN_NODEMANAGER_USER=root#修改core-site.xml&lt;设置默认使用的文件系统 Hadoop支持file、HDFS、GFS、ali|Amazon云等文件系统&gt;&lt;property&gt;&lt;name&gt;fs.defaultFS&lt;/name&gt;&lt;value&gt;hdfs://node1:8020&lt;/value&gt;&lt;/property&gt;&lt;设置Hadoop本地保存数据路径&gt;&lt;property&gt;&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;&lt;value&gt;/export/data/hadoop-3.3.0&lt;/value&gt;&lt;/property&gt;&lt;设置HDFS web UI用户身份&gt;&lt;property&gt;&lt;name&gt;hadoop.http.staticuser.user&lt;/name&gt;&lt;value&gt;root&lt;/value&gt;&lt;/property&gt;&lt;整合hive 用户代理设置&gt;hdfs-site.xmlmarpred-site.xml&lt;property&gt;&lt;name&gt;hadoop.proxyuser.root.hosts&lt;/name&gt;&lt;value&gt;*&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;hadoop.proxyuser.root.groups&lt;/name&gt;&lt;value&gt;*&lt;/value&gt;&lt;/property&gt;&lt;文件系统垃圾桶保存时间&gt;&lt;property&gt;&lt;name&gt;fs.trash.interval&lt;/name&gt;&lt;value&gt;1440&lt;/value&gt;&lt;/property&gt;#修改mapred-site.xml&lt; 设置MR程序默认运行模式： yarn集群模式 local本地模式&gt;&lt;property&gt;&lt;name&gt;mapreduce.framework.name&lt;/name&gt;&lt;value&gt;yarn&lt;/value&gt;&lt;/property&gt;&lt;MR程序历史服务地址&gt;&lt;property&gt;&lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;&lt;value&gt;node1:10020&lt;/value&gt;&lt;/property&gt;&lt;MR程序历史服务器web端地址&gt;&lt;property&gt;&lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;node1:19888&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt; &lt;value&gt;HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;mapreduce.map.env&lt;/name&gt; &lt;value&gt;HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;mapreduce.reduce.env&lt;/name&gt;yarn-site.xmlworkers&lt;分发同步hadoop安装包&gt; &lt;value&gt;HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;&lt;/value&gt;&lt;/property&gt;#修改yarn-site.xml&lt; 设置YARN集群主角色运行机器位置 &gt;&lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;node1&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt;&lt;/property&gt;&lt;是否将对容器实施物理内存限制&gt;&lt;property&gt; &lt;name&gt;yarn.nodemanager.pmem-check-enabled&lt;/name&gt; &lt;value&gt;false&lt;/value&gt;&lt;/property&gt;&lt;是否将对容器实施虚拟内存限制&gt;&lt;property&gt; &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt; &lt;value&gt;false&lt;/value&gt;&lt;/property&gt;&lt;开启日志聚集&gt;&lt;property&gt; &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;设置yarn历史服务器地址&gt;&lt;property&gt; &lt;name&gt;yarn.log.server.url&lt;/name&gt; &lt;value&gt;http://node1:19888/jobhistory/logs&lt;/value&gt;&lt;/property&gt;&lt;历史日志保存的时间 7天&gt;&lt;property&gt; &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt; &lt;value&gt;604800&lt;/value&gt;&lt;/property&gt;#修改workerslocalhostnode1.itcast.cnnode2.itcast.cnnode3.itcast.cn#分发同步hadoop安装包cd /export/serverscp -r hadoop-3.3.0 root@node2:$PWDscp -r hadoop-3.3.0 root@node3:$PWD 3.将hadoop添加到环境变量 123vim /etc/profileexport HADOOP_HOME=/export/server/hadoop-3.3.0export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin 4.重新加载环境变量文件 1source /etc/profile 5.Hadoop集群启动 格式化namenode（只有首次启动需要格式化） 1hdfs namenode -forma 6.脚本一键启动 1start-all.sh 7.查看WEB页面 12 HDFS集群 :http://node1:9870/YARN集群 :http://node1:8088/ 四、Zookeeper安装配置1.配置主机名和IP的映射关系，修改 &#x2F;etc&#x2F;hosts 文件，添加 node1.root node2.root node3.root 12345678vim /etc/hosts#结果显示127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain6192.168.88.135 node1 node1.root192.168.88.136 node2 node2.root192.168.88.137 node3 node3.root 2.zookeeper安装 上传 zookeeper-3.4.10.tar.gz到&#x2F;export&#x2F;server&#x2F;目录下 并解压文件 12cd /export/server/tar -zxvf zookeeper-3.4.10.tar.gz 3.在 &#x2F;export&#x2F;server 目录下创建软连接 12cd /export/serverln -s zookeeper-3.4.10/ zookeeper 4.cd进入 &#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;conf&#x2F; 将 zoo_sample.cfg 文件复制为新文件 zoo.cfg 12cd /export/server/zookeeper/conf/ cp zoo_sample.cfg zoo.cfg 接上步给 zoo.cfg 添加内容 12345678910#Zookeeper的数据存放目录dataDir=/export/server/zookeeper/zkdatas# 保留多少个快照autopurge.snapRetainCount=3# 日志多少小时清理一次autopurge.purgeInterval=1# 集群中服务器地址server.1=node1:2888:3888server.2=node2:2888:3888server.3=node3:2888:3888 5.进入 &#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;zkdatas 目录在此目录下创建 myid 文件，将 1 写入进去 123cd /export/server/zookeeper/zkdatatouch myidecho &#x27;1&#x27; &gt; myid 6.将 node1 节点中 &#x2F;export&#x2F;server&#x2F;zookeeper-3.4.10 路径下内容推送给node2 和 node3 12scp -r /export/server/zookeeper-3.4.10/ node2:$PWDscp -r /export/server/zookeeper-3.4.10/ node3:$PWD 7.推送成功后，分别在 node2 和 node3 上创建软连接 1ln -s zookeeper-3.4.10/ zookeeper 接上步推送完成后将 node2 和 node3 的 &#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;zkdatas&#x2F; 文件夹下的 myid 中的内容分别改为 2 和 3 8.配置zookeeper的环境变量（注：三台主机都需要配置） 12345vim /etc/profile#zookeeper 环境变量export ZOOKEEPER_HOME=/export/server/zookeeperexport PATH=$PATH:$ZOOKEEPER_HOME/bin 9.重新加载环境变量文件 1source /etc/profile 10.进入 &#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;bin&#x2F; 目录下启动 zkServer.sh 脚本 （注：三台都需要做） 12cd /export/server/zookeeper/bin/ zkServer.sh start 11.查看zookeeper是否开启 1jps","categories":[],"tags":[]},{"title":"我的第一篇博客文章","slug":"我的第一篇博客文章","date":"2022-05-21T06:57:06.000Z","updated":"2022-05-21T06:57:06.881Z","comments":true,"path":"2022/05/21/我的第一篇博客文章/","link":"","permalink":"http://example.com/2022/05/21/%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2%E6%96%87%E7%AB%A0/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"Hello World","slug":"hello-world","date":"2022-05-21T06:51:11.881Z","updated":"2022-05-21T06:51:11.882Z","comments":true,"path":"2022/05/21/hello-world/","link":"","permalink":"http://example.com/2022/05/21/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[{"name":"工具","slug":"工具","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://example.com/tags/hexo/"},{"name":"主题","slug":"主题","permalink":"http://example.com/tags/%E4%B8%BB%E9%A2%98/"},{"name":"搭建","slug":"搭建","permalink":"http://example.com/tags/%E6%90%AD%E5%BB%BA/"}]}